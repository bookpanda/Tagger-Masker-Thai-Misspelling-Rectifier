{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35914,"status":"ok","timestamp":1660925860550,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"PpEJQHrF5Byi","outputId":"a649540c-481e-4307-9d7d-7530ee9bfbf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 8.9 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 56.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 11.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=96ea1821b589c94c6bba94b7fa100bd3df235887491dd101142bacadbe1ac746\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.10.3 transformers-4.15.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets==1.17.0\n","  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 62.2 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (6.0.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.8.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.12.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2.23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 72.5 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.3.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.17.0) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (3.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.3.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (22.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.17.0) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.17.0) (1.15.0)\n","Installing collected packages: fsspec, xxhash, multiprocess, datasets\n","Successfully installed datasets-1.17.0 fsspec-2022.7.1 multiprocess-0.70.13 xxhash-3.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.7.2-py3-none-any.whl (705 kB)\n","\u001b[K     |████████████████████████████████| 705 kB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.7.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Collecting tensorboard>=2.9.1\n","  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.1+cu113)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 73.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.47.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n","Installing collected packages: torchmetrics, tensorboard, pyDeprecate, pytorch-lightning\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n","Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.7.2 tensorboard-2.10.0 torchmetrics-0.9.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 9.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 65.1 MB/s \n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 39.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 75.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 74.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 78.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 69.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 76.0 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=0a24f823f7e4416dfa40aafac50102aa783cdd453f821a0f0de914f88a6890c5\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.1\n"]}],"source":["!pip install transformers==4.15.0 sentencepiece\n","!pip install datasets==1.17.0 \n","!pip install pytorch-lightning \n","# !pip install wandb\n","%pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4660,"status":"ok","timestamp":1659498238096,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ESLntqHM1izO","outputId":"1ddae4d3-0d61-4136-a649-ef92a50fa587"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18213,"status":"ok","timestamp":1660925878751,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"zHFzMIqvsJxU","outputId":"e47d97c6-13ad-45fb-fe9f-35c376463717"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGkmLjsmINUK"},"outputs":[],"source":["from transformers import (\n","    MT5ForConditionalGeneration,\n","    MT5TokenizerFast,\n",")\n","from transformers import AutoTokenizer, BertForTokenClassification\n","import pandas as pd\n","import wandb\n","from datasets import load_dataset, load_metric, Dataset, DatasetDict\n","import torch\n","import pickle\n","from tqdm import tqdm\n","import os\n","import numpy as np\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.loggers import WandbLogger\n","from typing import Optional"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqNVrjz0uRD0"},"outputs":[],"source":["df = pickle.load(open('drive/MyDrive/AIBuilders/json/mlm_json_15k.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660925891382,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"2HxIRXMCGqjx","outputId":"fc2311c3-6483-4386-f281-f97af4fee6eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               input_ids  \\\n","0      [5, 10, 25004, 25004, 25004, 1147, 118, 19105,...   \n","1      [5, 2169, 25088, 10, 10022, 10, 234, 112, 234,...   \n","2      [5, 10, 3919, 77, 10, 25004, 25004, 25004, 10,...   \n","3      [5, 10, 16369, 12, 2105, 19319, 10, 300, 25004...   \n","4      [5, 10, 2638, 22683, 3927, 716, 1491, 2552, 16...   \n","...                                                  ...   \n","15571  [5, 10, 3919, 1983, 1466, 803, 7177, 75, 25004...   \n","15572  [5, 1896, 25004, 25004, 25004, 25004, 6, 1, 1,...   \n","15573  [5, 2169, 25004, 905, 25098, 10, 25004, 25004,...   \n","15574  [5, 10, 112, 78, 10, 25004, 25004, 73, 6, 1, 1...   \n","15575  [5, 5960, 99, 371, 73, 840, 51, 25004, 26, 37,...   \n","\n","                                          attention_mask  \\\n","0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n","1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n","...                                                  ...   \n","15571  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","15572  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","15573  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n","15574  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n","15575  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","\n","                                                  labels  \n","0      [5, 10, 31, 265, 265, 1147, 118, 19105, 3166, ...  \n","1      [5, 2169, 25088, 10, 10022, 10, 234, 112, 234,...  \n","2      [5, 10, 3919, 77, 10, 25005, 265, 265, 10, 825...  \n","3      [5, 10, 16369, 12, 2105, 19319, 10, 300, 70, 1...  \n","4      [5, 10, 2638, 22683, 3927, 716, 1491, 2552, 16...  \n","...                                                  ...  \n","15571  [5, 10, 3919, 1983, 1466, 803, 7177, 75, 25040...  \n","15572  [5, 1896, 1466, 265, 415, 73, 6, 1, 1, 1, 1, 1...  \n","15573  [5, 2169, 12355, 905, 25098, 10, 415, 260, 6, ...  \n","15574  [5, 10, 112, 78, 10, 25117, 265, 73, 6, 1, 1, ...  \n","15575  [5, 5960, 99, 371, 73, 840, 51, 15, 26, 37, 29...  \n","\n","[15576 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-44076077-fc10-45c9-b9f2-113349570d0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[5, 10, 25004, 25004, 25004, 1147, 118, 19105,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 31, 265, 265, 1147, 118, 19105, 3166, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[5, 2169, 25088, 10, 10022, 10, 234, 112, 234,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 2169, 25088, 10, 10022, 10, 234, 112, 234,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[5, 10, 3919, 77, 10, 25004, 25004, 25004, 10,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 3919, 77, 10, 25005, 265, 265, 10, 825...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[5, 10, 16369, 12, 2105, 19319, 10, 300, 25004...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 16369, 12, 2105, 19319, 10, 300, 70, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[5, 10, 2638, 22683, 3927, 716, 1491, 2552, 16...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n","      <td>[5, 10, 2638, 22683, 3927, 716, 1491, 2552, 16...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15571</th>\n","      <td>[5, 10, 3919, 1983, 1466, 803, 7177, 75, 25004...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 3919, 1983, 1466, 803, 7177, 75, 25040...</td>\n","    </tr>\n","    <tr>\n","      <th>15572</th>\n","      <td>[5, 1896, 25004, 25004, 25004, 25004, 6, 1, 1,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 1896, 1466, 265, 415, 73, 6, 1, 1, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>15573</th>\n","      <td>[5, 2169, 25004, 905, 25098, 10, 25004, 25004,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 2169, 12355, 905, 25098, 10, 415, 260, 6, ...</td>\n","    </tr>\n","    <tr>\n","      <th>15574</th>\n","      <td>[5, 10, 112, 78, 10, 25004, 25004, 73, 6, 1, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 112, 78, 10, 25117, 265, 73, 6, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>15575</th>\n","      <td>[5, 5960, 99, 371, 73, 840, 51, 25004, 26, 37,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 5960, 99, 371, 73, 840, 51, 15, 26, 37, 29...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15576 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44076077-fc10-45c9-b9f2-113349570d0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-44076077-fc10-45c9-b9f2-113349570d0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-44076077-fc10-45c9-b9f2-113349570d0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMoBbaxHwGPI"},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', model_max_length=512)\n","tokenizer_data = pickle.load(open('drive/MyDrive/AIBuilders/json/tokenizer_json_15k.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11125,"status":"ok","timestamp":1660925914969,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"q4lGm2yTGZ4L","outputId":"8d28c7ab-8f4a-427a-cc9e-22569aa70c8e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 15576/15576 [00:11<00:00, 1359.99it/s]\n"]}],"source":["a = len(df)\n","blacklist = ['<s>', '</s>', '<pad>']\n","for i in tqdm(range(a)):\n","  text = tokenizer_data.convert_ids_to_tokens(df.iloc[i]['input_ids'])\n","  text = [j for j in text if j not in blacklist]\n","\n","  labels = tokenizer_data.convert_ids_to_tokens(df.iloc[i]['labels'])\n","  labels = [j for j in labels if j not in blacklist]\n","  # print(len(text), len(labels))\n","  if len(text) != len(labels):\n","    print(\"ASS\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AxoXKjysuV7_"},"outputs":[],"source":["df_test = df[10576:]\n","df = df[:10576]\n","df_train, df_val = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.9 * len(df))])"]},{"cell_type":"code","source":["#make dataset for mt5\n","def convert_to_text_no_split_mask(data):\n","  len_data = len(data)\n","  blacklist = ['<s>', '</s>', '<pad>']\n","  output_df = pd.DataFrame(columns=['source_text', 'target_text'])\n","  for i in tqdm(range(len_data)):\n","    text = tokenizer_data.convert_ids_to_tokens(data.iloc[i]['input_ids'])\n","    text = [j for j in text if j not in blacklist]\n","    len_text = len(text)\n","    for j in range(len_text):\n","      text[j] = text[j].replace(\"▁\", \" \")\n","      text[j] = text[j].replace(\"_\", \" \")\n","    text = \"แก้คำผิด: \" + \"\".join(text)\n","    text = text.strip()\n","\n","    labels = tokenizer_data.convert_ids_to_tokens(data.iloc[i]['labels'])\n","    labels = [j for j in labels if j not in blacklist]\n","    len_labels = len(labels)\n","    for j in range(len_labels):\n","      labels[j] = labels[j].replace(\"▁\", \" \")\n","      labels[j] = labels[j].replace(\"_\", \" \")\n","    input_labels = \"\".join(labels)\n","    input_labels = input_labels.strip()\n","\n","    # print(f\"TEXT: {text}\")\n","    # print(f\"LABELS: {labels}\")\n","    row = pd.Series([text, input_labels], index=output_df.columns)\n","    output_df = output_df.append(row, ignore_index=True)\n","\n","    # row = pd.Series([text, labels], index=output_df.columns)\n","    # output_df = output_df.append(row, ignore_index=True)\n","  return output_df"],"metadata":{"id":"CpxWEvBlnAZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_no_split_df = convert_to_text_no_split_mask(df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bBErjHKnS8l","executionInfo":{"status":"ok","timestamp":1660384303697,"user_tz":-420,"elapsed":12813,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"4f5392a6-bcf8-47bc-c26a-a6564292a78a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5000/5000 [00:12<00:00, 393.62it/s]\n"]}]},{"cell_type":"code","source":["pickle.dump(test_no_split_df, open('test_mt5_no_split_json_15k.pkl', 'wb'))"],"metadata":{"id":"dDbYx8UPnsOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_no_split_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"9D2__C2Ynecq","executionInfo":{"status":"ok","timestamp":1660384317648,"user_tz":-420,"elapsed":485,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"8903e029-e46d-495a-e873-f836985b2ccb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            source_text  \\\n","0     แก้คำผิด:  จําเป็นต้องเปิดบริการกับสาขาที่เปิด...   \n","1                   แก้คำผิด:  เมื่อวาน<mask>ยังเข้าได้   \n","2                     แก้คำผิด:  ผม<mask>ต่างประเทศครับ   \n","3                   แก้คำผิด:  พอไปสมัครที่<mask><mask>   \n","4            แก้คำผิด:  <mask>มีปัญหา<mask><mask>ตอนนี้   \n","...                                                 ...   \n","4995  แก้คำผิด:  ไม่ทราบว่าทําการสมัครบริการซื้อสินค...   \n","4996              แก้คำผิด:  จะ<mask><mask><mask><mask>   \n","4997    แก้คำผิด:  อยาก<mask>ว่าจะเข้าระบบ <mask><mask>   \n","4998             แก้คำผิด:  เข้าไม่ได้ <mask><mask>ครับ   \n","4999  แก้คำผิด:  ช่วยดูทีครับจ่ายไม่<mask>มาจะสอง<ma...   \n","\n","                                            target_text  \n","0     จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี ไหมคร...  \n","1                                 เมื่อวาน ก็ยังเข้าได้  \n","2                                  ผมอยู่ต่างประเทศครับ  \n","3                                       พอไปสมัครที่ตู้  \n","4                                แอพมีปัญหาหรือคะตอนนี้  \n","...                                                 ...  \n","4995  ไม่ทราบว่าทําการสมัครบริการซื้อสินค้าทาง อินเท...  \n","4996                                จะสมัคร อย่างไรครับ  \n","4997                    อยาก รู้ว่าจะเข้าระบบ อย่างไรคะ  \n","4998                          เข้าไม่ได้ เป็นอะ ไร ครับ  \n","4999  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...  \n","\n","[5000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f29f6da9-66e9-4f2d-abde-205e28dc1358\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>แก้คำผิด:  จําเป็นต้องเปิดบริการกับสาขาที่เปิด...</td>\n","      <td>จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี ไหมคร...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>แก้คำผิด:  เมื่อวาน&lt;mask&gt;ยังเข้าได้</td>\n","      <td>เมื่อวาน ก็ยังเข้าได้</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>แก้คำผิด:  ผม&lt;mask&gt;ต่างประเทศครับ</td>\n","      <td>ผมอยู่ต่างประเทศครับ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>แก้คำผิด:  พอไปสมัครที่&lt;mask&gt;&lt;mask&gt;</td>\n","      <td>พอไปสมัครที่ตู้</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>แก้คำผิด:  &lt;mask&gt;มีปัญหา&lt;mask&gt;&lt;mask&gt;ตอนนี้</td>\n","      <td>แอพมีปัญหาหรือคะตอนนี้</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>แก้คำผิด:  ไม่ทราบว่าทําการสมัครบริการซื้อสินค...</td>\n","      <td>ไม่ทราบว่าทําการสมัครบริการซื้อสินค้าทาง อินเท...</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>แก้คำผิด:  จะ&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;</td>\n","      <td>จะสมัคร อย่างไรครับ</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>แก้คำผิด:  อยาก&lt;mask&gt;ว่าจะเข้าระบบ &lt;mask&gt;&lt;mask&gt;</td>\n","      <td>อยาก รู้ว่าจะเข้าระบบ อย่างไรคะ</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>แก้คำผิด:  เข้าไม่ได้ &lt;mask&gt;&lt;mask&gt;ครับ</td>\n","      <td>เข้าไม่ได้ เป็นอะ ไร ครับ</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>แก้คำผิด:  ช่วยดูทีครับจ่ายไม่&lt;mask&gt;มาจะสอง&lt;ma...</td>\n","      <td>ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f29f6da9-66e9-4f2d-abde-205e28dc1358')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f29f6da9-66e9-4f2d-abde-205e28dc1358 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f29f6da9-66e9-4f2d-abde-205e28dc1358');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["val_no_split_df = convert_to_text_no_split_mask(df_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsdtyqCX5mpa","executionInfo":{"status":"ok","timestamp":1660925946626,"user_tz":-420,"elapsed":3602,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"8c2aa533-284e-4eb0-9926-0028eca2d5cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1058/1058 [00:03<00:00, 309.53it/s]\n"]}]},{"cell_type":"code","source":["pickle.dump(val_no_split_df, open('val_mt5_no_split_json_15k.pkl', 'wb'))"],"metadata":{"id":"nyLeAzwV5rdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_no_split_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"B1SIv0-H5vx2","executionInfo":{"status":"ok","timestamp":1660925976145,"user_tz":-420,"elapsed":375,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"902241e9-2158-4aa2-d226-36020bab558f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            source_text  \\\n","0                             แก้คำผิด:  เสี่ยต่อ<mask>   \n","1                  แก้คำผิด:  พอดี<mask><mask><mask>ไกล   \n","2               แก้คำผิด:  มัน<mask>มีให้เข้าสู่ระบบค่ะ   \n","3     แก้คำผิด:  จริงค่ะ <mask><mask>ก็รอ นาทีกว่าๆ ...   \n","4     แก้คำผิด:  ขอทราบรายละเอียดเรื่องการนําเครื่อง...   \n","...                                                 ...   \n","1053        แก้คำผิด:  อ้าวเหรอ <mask>ขึ้นไปใส่ชื่อก่อน   \n","1054  แก้คำผิด:  เติม<mask><mask><mask><mask>กดเลขอะ...   \n","1055  แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...   \n","1056                        แก้คำผิด:  ผ่าน<mask><mask>   \n","1057             แก้คำผิด:  ทําไม่เป็น<mask>ค่ะ งง สุดๆ   \n","\n","                                            target_text  \n","0                                          เสี่ยต่อครับ  \n","1                                       พอดีตู้ อยู่ไกล  \n","2                            มัน ไม่มีให้เข้าสู่ระบบค่ะ  \n","3         จริงค่ะ  ดิฉัน ก็รอ นาทีกว่าๆ รอบกว่าจะได้คุย  \n","4     ขอทราบรายละเอียดเรื่องการนําเครื่องรูดบัตรมาไว...  \n","...                                                 ...  \n","1053                  อ้าวเหรอ  เดี๋ยวขึ้นไปใส่ชื่อก่อน  \n","1054                    เติมสตางค์โทรศัพท์  กดเลขอะไรคะ  \n","1055  หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...  \n","1056                                  ผ่าน อินเทอร์เน็ต  \n","1057                            ทําไม่เป็นอะค่ะ งง สุดๆ  \n","\n","[1058 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-405917b9-7f43-4054-84e5-74fdcca05900\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>แก้คำผิด:  เสี่ยต่อ&lt;mask&gt;</td>\n","      <td>เสี่ยต่อครับ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>แก้คำผิด:  พอดี&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;ไกล</td>\n","      <td>พอดีตู้ อยู่ไกล</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>แก้คำผิด:  มัน&lt;mask&gt;มีให้เข้าสู่ระบบค่ะ</td>\n","      <td>มัน ไม่มีให้เข้าสู่ระบบค่ะ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>แก้คำผิด:  จริงค่ะ &lt;mask&gt;&lt;mask&gt;ก็รอ นาทีกว่าๆ ...</td>\n","      <td>จริงค่ะ  ดิฉัน ก็รอ นาทีกว่าๆ รอบกว่าจะได้คุย</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>แก้คำผิด:  ขอทราบรายละเอียดเรื่องการนําเครื่อง...</td>\n","      <td>ขอทราบรายละเอียดเรื่องการนําเครื่องรูดบัตรมาไว...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1053</th>\n","      <td>แก้คำผิด:  อ้าวเหรอ &lt;mask&gt;ขึ้นไปใส่ชื่อก่อน</td>\n","      <td>อ้าวเหรอ  เดี๋ยวขึ้นไปใส่ชื่อก่อน</td>\n","    </tr>\n","    <tr>\n","      <th>1054</th>\n","      <td>แก้คำผิด:  เติม&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;กดเลขอะ...</td>\n","      <td>เติมสตางค์โทรศัพท์  กดเลขอะไรคะ</td>\n","    </tr>\n","    <tr>\n","      <th>1055</th>\n","      <td>แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...</td>\n","      <td>หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...</td>\n","    </tr>\n","    <tr>\n","      <th>1056</th>\n","      <td>แก้คำผิด:  ผ่าน&lt;mask&gt;&lt;mask&gt;</td>\n","      <td>ผ่าน อินเทอร์เน็ต</td>\n","    </tr>\n","    <tr>\n","      <th>1057</th>\n","      <td>แก้คำผิด:  ทําไม่เป็น&lt;mask&gt;ค่ะ งง สุดๆ</td>\n","      <td>ทําไม่เป็นอะค่ะ งง สุดๆ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1058 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-405917b9-7f43-4054-84e5-74fdcca05900')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-405917b9-7f43-4054-84e5-74fdcca05900 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-405917b9-7f43-4054-84e5-74fdcca05900');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6VhxPmxuXxJ"},"outputs":[],"source":["#make dataset for mt5\n","def convert_to_text(data):\n","  len_data = len(data)\n","  blacklist = ['<s>', '</s>', '<pad>']\n","  output_df = pd.DataFrame(columns=['source_text', 'target_text'])\n","  for i in tqdm(range(len_data)):\n","    text = tokenizer_data.convert_ids_to_tokens(data.iloc[i]['input_ids'])\n","    text = [j for j in text if j not in blacklist]\n","    len_text = len(text)\n","    for j in range(len_text):\n","      text[j] = text[j].replace(\"▁\", \" \")\n","      text[j] = text[j].replace(\"_\", \" \")\n","    # text = \"แก้คำผิด: \" + \"\".join(text)\n","    # text = text.strip()\n","\n","    labels = tokenizer_data.convert_ids_to_tokens(data.iloc[i]['labels'])\n","    labels = [j for j in labels if j not in blacklist]\n","    len_labels = len(labels)\n","    for j in range(len_labels):\n","      labels[j] = labels[j].replace(\"▁\", \" \")\n","      labels[j] = labels[j].replace(\"_\", \" \")\n","    input_labels = \"\".join(labels)\n","    input_labels = input_labels.strip()\n","\n","    # print(f\"TEXT: {text}\")\n","    # print(f\"LABELS: {labels}\")\n","    for j in range(len_text):\n","      if text[j] == \"<mask>\":\n","        input_text = labels.copy()\n","        input_text[j] = \"<mask>\"\n","        # print(f\"INPUT TEXT: {input_text}\")\n","        input_text = \"แก้คำผิด: \" + \"\".join(input_text)\n","        input_text = input_text.strip()\n","        row = pd.Series([input_text, input_labels], index=output_df.columns)\n","        output_df = output_df.append(row, ignore_index=True)\n","\n","    # row = pd.Series([text, labels], index=output_df.columns)\n","    # output_df = output_df.append(row, ignore_index=True)\n","  return output_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65605,"status":"ok","timestamp":1659498355981,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"NL4hjN3axTUI","outputId":"eed06feb-ffa1-4f49-db23-6221300439b6"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9518/9518 [00:40<00:00, 233.68it/s]\n","100%|██████████| 1058/1058 [00:04<00:00, 243.71it/s]\n","100%|██████████| 5000/5000 [00:20<00:00, 244.67it/s]\n"]}],"source":["train_df = convert_to_text(df_train)\n","valid_df = convert_to_text(df_val)\n","test_df = convert_to_text(df_test)"]},{"cell_type":"code","source":["pickle.dump(train_df, open('train_mt5_json_15k.pkl', 'wb'))\n","pickle.dump(valid_df, open('valid_mt5_json_15k.pkl', 'wb'))\n","pickle.dump(test_df, open('test_mt5_json_15k.pkl', 'wb'))"],"metadata":{"id":"mNceEkrsz5kX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pickle.load(open('drive/MyDrive/AIBuilders/json/train_mt5_json_15k.pkl', 'rb'))\n","valid_df = pickle.load(open('drive/MyDrive/AIBuilders/json/valid_mt5_json_15k.pkl', 'rb'))\n","test_df = pickle.load(open('drive/MyDrive/AIBuilders/json/test_mt5_json_15k.pkl', 'rb'))"],"metadata":{"id":"eiACs3NP0Ogi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":386,"status":"ok","timestamp":1659498553890,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"tVh_ddSs1BEQ","outputId":"60f39b05-b90c-4319-fdd7-d2a7bedaa31f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             source_text  \\\n","0                                แก้คำผิด:  ทําไม่<mask>   \n","1                          แก้คำผิด:  ทําไม่เป็นอะ<mask>   \n","2              แก้คำผิด:  ติดต่อธนาคารเรียบร้อย<mask>ค่ะ   \n","3            แก้คำผิด:  ติดต่อธนาคารเรียบร้อย แล้ว<mask>   \n","4         แก้คำผิด:  ติดต่อธนาคารเรียบร้อย แล้วค่ะ<mask>   \n","...                                                  ...   \n","18537  แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตร<m...   \n","18538  แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอย...   \n","18539  แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอย...   \n","18540               แก้คำผิด:  มาเข้าไม่ได้ทํา<mask>ครับ   \n","18541                 แก้คำผิด:  มาเข้าไม่ได้ทําไง<mask>   \n","\n","                                             target_text  \n","0                                           ทําไม่เป็นอะ  \n","1                                           ทําไม่เป็นอะ  \n","2                          ติดต่อธนาคารเรียบร้อย แล้วค่ะ  \n","3                          ติดต่อธนาคารเรียบร้อย แล้วค่ะ  \n","4                          ติดต่อธนาคารเรียบร้อย แล้วค่ะ  \n","...                                                  ...  \n","18537  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...  \n","18538  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...  \n","18539  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...  \n","18540                              มาเข้าไม่ได้ทําไงครับ  \n","18541                              มาเข้าไม่ได้ทําไงครับ  \n","\n","[18542 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-e72d55b4-6b22-472a-9f8f-c62419d8a4c3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>แก้คำผิด:  ทําไม่&lt;mask&gt;</td>\n","      <td>ทําไม่เป็นอะ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>แก้คำผิด:  ทําไม่เป็นอะ&lt;mask&gt;</td>\n","      <td>ทําไม่เป็นอะ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>แก้คำผิด:  ติดต่อธนาคารเรียบร้อย&lt;mask&gt;ค่ะ</td>\n","      <td>ติดต่อธนาคารเรียบร้อย แล้วค่ะ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>แก้คำผิด:  ติดต่อธนาคารเรียบร้อย แล้ว&lt;mask&gt;</td>\n","      <td>ติดต่อธนาคารเรียบร้อย แล้วค่ะ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>แก้คำผิด:  ติดต่อธนาคารเรียบร้อย แล้วค่ะ&lt;mask&gt;</td>\n","      <td>ติดต่อธนาคารเรียบร้อย แล้วค่ะ</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18537</th>\n","      <td>แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตร&lt;m...</td>\n","      <td>อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...</td>\n","    </tr>\n","    <tr>\n","      <th>18538</th>\n","      <td>แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอย...</td>\n","      <td>อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...</td>\n","    </tr>\n","    <tr>\n","      <th>18539</th>\n","      <td>แก้คำผิด:  อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอย...</td>\n","      <td>อยากได้ยอดเพิ่มทําอย่างไรคะมีบัตรอยู่แล้ว ทําม...</td>\n","    </tr>\n","    <tr>\n","      <th>18540</th>\n","      <td>แก้คำผิด:  มาเข้าไม่ได้ทํา&lt;mask&gt;ครับ</td>\n","      <td>มาเข้าไม่ได้ทําไงครับ</td>\n","    </tr>\n","    <tr>\n","      <th>18541</th>\n","      <td>แก้คำผิด:  มาเข้าไม่ได้ทําไง&lt;mask&gt;</td>\n","      <td>มาเข้าไม่ได้ทําไงครับ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18542 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e72d55b4-6b22-472a-9f8f-c62419d8a4c3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e72d55b4-6b22-472a-9f8f-c62419d8a4c3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e72d55b4-6b22-472a-9f8f-c62419d8a4c3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1659498557612,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"_4Mw9c0j1CLz","outputId":"5ea3c7fe-f606-416a-e95e-4377b2eb3b4f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            source_text  \\\n","0                             แก้คำผิด:  เสี่ยต่อ<mask>   \n","1                         แก้คำผิด:  พอดี<mask> อยู่ไกล   \n","2                       แก้คำผิด:  พอดีตู้<mask>อยู่ไกล   \n","3                          แก้คำผิด:  พอดีตู้ <mask>ไกล   \n","4               แก้คำผิด:  มัน<mask>มีให้เข้าสู่ระบบค่ะ   \n","...                                                 ...   \n","2102  แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...   \n","2103  แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...   \n","2104                              แก้คำผิด:  ผ่าน<mask>   \n","2105                 แก้คำผิด:  ผ่าน อินเทอร์เน็ต<mask>   \n","2106             แก้คำผิด:  ทําไม่เป็น<mask>ค่ะ งง สุดๆ   \n","\n","                                            target_text  \n","0                                          เสี่ยต่อครับ  \n","1                                       พอดีตู้ อยู่ไกล  \n","2                                       พอดีตู้ อยู่ไกล  \n","3                                       พอดีตู้ อยู่ไกล  \n","4                            มัน ไม่มีให้เข้าสู่ระบบค่ะ  \n","...                                                 ...  \n","2102  หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...  \n","2103  หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...  \n","2104                                  ผ่าน อินเทอร์เน็ต  \n","2105                                  ผ่าน อินเทอร์เน็ต  \n","2106                            ทําไม่เป็นอะค่ะ งง สุดๆ  \n","\n","[2107 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-2d556713-3659-4952-8339-de490ae9b287\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>แก้คำผิด:  เสี่ยต่อ&lt;mask&gt;</td>\n","      <td>เสี่ยต่อครับ</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>แก้คำผิด:  พอดี&lt;mask&gt; อยู่ไกล</td>\n","      <td>พอดีตู้ อยู่ไกล</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>แก้คำผิด:  พอดีตู้&lt;mask&gt;อยู่ไกล</td>\n","      <td>พอดีตู้ อยู่ไกล</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>แก้คำผิด:  พอดีตู้ &lt;mask&gt;ไกล</td>\n","      <td>พอดีตู้ อยู่ไกล</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>แก้คำผิด:  มัน&lt;mask&gt;มีให้เข้าสู่ระบบค่ะ</td>\n","      <td>มัน ไม่มีให้เข้าสู่ระบบค่ะ</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2102</th>\n","      <td>แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...</td>\n","      <td>หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...</td>\n","    </tr>\n","    <tr>\n","      <th>2103</th>\n","      <td>แก้คำผิด:  หากยังไม่สามารถเข้าระบบ ได้ แนะนําใ...</td>\n","      <td>หากยังไม่สามารถเข้าระบบ ได้ แนะนําให้ลองลบแอปพ...</td>\n","    </tr>\n","    <tr>\n","      <th>2104</th>\n","      <td>แก้คำผิด:  ผ่าน&lt;mask&gt;</td>\n","      <td>ผ่าน อินเทอร์เน็ต</td>\n","    </tr>\n","    <tr>\n","      <th>2105</th>\n","      <td>แก้คำผิด:  ผ่าน อินเทอร์เน็ต&lt;mask&gt;</td>\n","      <td>ผ่าน อินเทอร์เน็ต</td>\n","    </tr>\n","    <tr>\n","      <th>2106</th>\n","      <td>แก้คำผิด:  ทําไม่เป็น&lt;mask&gt;ค่ะ งง สุดๆ</td>\n","      <td>ทําไม่เป็นอะค่ะ งง สุดๆ</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2107 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d556713-3659-4952-8339-de490ae9b287')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d556713-3659-4952-8339-de490ae9b287 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d556713-3659-4952-8339-de490ae9b287');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["valid_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":366,"status":"ok","timestamp":1659498565024,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"pcTLehxU1D_h","outputId":"ff5cf61d-f792-4aae-fab7-1437bc23c95a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            source_text  \\\n","0     แก้คำผิด:  จําเป็นต้องเปิดบริการกับสาขาที่เปิด...   \n","1                   แก้คำผิด:  เมื่อวาน<mask>ยังเข้าได้   \n","2                     แก้คำผิด:  ผม<mask>ต่างประเทศครับ   \n","3                         แก้คำผิด:  พอไปสมัครที่<mask>   \n","4                      แก้คำผิด:  พอไปสมัครที่ตู้<mask>   \n","...                                                 ...   \n","9697                  แก้คำผิด:  เข้าไม่ได้ <mask> ครับ   \n","9698          แก้คำผิด:  เข้าไม่ได้ เป็นอะ ไร<mask>ครับ   \n","9699  แก้คำผิด:  ช่วยดูทีครับจ่ายไม่<mask>มาจะสองอาท...   \n","9700  แก้คำผิด:  ช่วยดูทีครับจ่ายไม่ได้มาจะสอง<mask>...   \n","9701  แก้คำผิด:  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย...   \n","\n","                                            target_text  \n","0     จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี ไหมคร...  \n","1                                 เมื่อวาน ก็ยังเข้าได้  \n","2                                  ผมอยู่ต่างประเทศครับ  \n","3                                       พอไปสมัครที่ตู้  \n","4                                       พอไปสมัครที่ตู้  \n","...                                                 ...  \n","9697                          เข้าไม่ได้ เป็นอะ ไร ครับ  \n","9698                          เข้าไม่ได้ เป็นอะ ไร ครับ  \n","9699  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...  \n","9700  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...  \n","9701  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...  \n","\n","[9702 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-0bb84fb5-5527-4aff-9814-a6a73e1e0d20\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>แก้คำผิด:  จําเป็นต้องเปิดบริการกับสาขาที่เปิด...</td>\n","      <td>จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี ไหมคร...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>แก้คำผิด:  เมื่อวาน&lt;mask&gt;ยังเข้าได้</td>\n","      <td>เมื่อวาน ก็ยังเข้าได้</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>แก้คำผิด:  ผม&lt;mask&gt;ต่างประเทศครับ</td>\n","      <td>ผมอยู่ต่างประเทศครับ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>แก้คำผิด:  พอไปสมัครที่&lt;mask&gt;</td>\n","      <td>พอไปสมัครที่ตู้</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>แก้คำผิด:  พอไปสมัครที่ตู้&lt;mask&gt;</td>\n","      <td>พอไปสมัครที่ตู้</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9697</th>\n","      <td>แก้คำผิด:  เข้าไม่ได้ &lt;mask&gt; ครับ</td>\n","      <td>เข้าไม่ได้ เป็นอะ ไร ครับ</td>\n","    </tr>\n","    <tr>\n","      <th>9698</th>\n","      <td>แก้คำผิด:  เข้าไม่ได้ เป็นอะ ไร&lt;mask&gt;ครับ</td>\n","      <td>เข้าไม่ได้ เป็นอะ ไร ครับ</td>\n","    </tr>\n","    <tr>\n","      <th>9699</th>\n","      <td>แก้คำผิด:  ช่วยดูทีครับจ่ายไม่&lt;mask&gt;มาจะสองอาท...</td>\n","      <td>ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...</td>\n","    </tr>\n","    <tr>\n","      <th>9700</th>\n","      <td>แก้คำผิด:  ช่วยดูทีครับจ่ายไม่ได้มาจะสอง&lt;mask&gt;...</td>\n","      <td>ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...</td>\n","    </tr>\n","    <tr>\n","      <th>9701</th>\n","      <td>แก้คำผิด:  ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย...</td>\n","      <td>ช่วยดูทีครับจ่ายไม่ได้มาจะสองอาทิตย์ แล้วรองหล...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9702 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bb84fb5-5527-4aff-9814-a6a73e1e0d20')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0bb84fb5-5527-4aff-9814-a6a73e1e0d20 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0bb84fb5-5527-4aff-9814-a6a73e1e0d20');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1659498569132,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"Ctw_14Zquano","outputId":"05cb3ccd-7aec-4285-d7fc-aaf3a81f2959"},"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 16\n"]}],"source":["pl.seed_everything(16)\n","torch.cuda.empty_cache()\n","\n","\n","class MT5Dataset(torch.utils.data.Dataset): #used for tokenizing\n","    def __init__(self, df, tokenizer):\n","        self.data = df.reset_index()\n","        self.tokenizer = tokenizer\n","        self.source_max_len = 1024\n","        self.target_max_len = 1024\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        data_row = self.data.iloc[idx]\n","        source, target = data_row[\"source_text\"], data_row[\"target_text\"]\n","\n","        source_encoding = self.tokenizer(\n","            source,\n","            padding=\"max_length\",\n","            max_length=self.source_max_len,\n","            truncation=True,\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            return_tensors=\"pt\",\n","        )\n","\n","        target_encoding = self.tokenizer(\n","            target,\n","            padding=\"max_length\",\n","            max_length=self.target_max_len,\n","            truncation=True,\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            return_tensors=\"pt\",\n","        )\n","        #tokenizes input and label\n","\n","        # Ensure labels are correct (see huggingface T5 training documentation)\n","        labels = target_encoding.input_ids\n","        labels[labels == self.tokenizer.pad_token_id] = -100\n","\n","        return dict(\n","            input_ids=source_encoding.input_ids.flatten(),\n","            attention_mask=source_encoding.attention_mask.flatten(),\n","            decoder_input_ids=labels.flatten(),\n","            decoder_attention_mask=target_encoding.attention_mask.flatten(),\n","        )\n","        #input: source_encoding\n","        #label (decoder_input): target_encoding\n","\n","\n","class MT5DataModule(pl.LightningDataModule): #make dataloader via MT5Dataset\n","    def __init__(\n","        self,\n","        tokenizer,\n","        train_df,\n","        valid_df,\n","        test_df,\n","        batch_size: int = 1,\n","        num_workers: int = 2,\n","    ):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","        self.tokenizer = tokenizer\n","\n","    def setup(self, stage: Optional[str] = None, batch_size=1):\n","        self.batch_size = batch_size\n","        if stage == \"fit\" or stage is None:\n","            self.train_data = MT5Dataset(self.train_df, self.tokenizer)\n","            self.valid_data = MT5Dataset(self.valid_df, self.tokenizer)\n","\n","        if stage == \"test\" or stage is None:\n","            self.test_data = MT5Dataset(self.test_df, self.tokenizer)\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.train_data, batch_size=self.batch_size, shuffle=True\n","        )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.valid_data, batch_size=self.batch_size, shuffle=False\n","        )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.test_data, batch_size=self.batch_size, shuffle=False\n","        )\n","\n","\n","class MT5Lightning(pl.LightningModule):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.avg_training_loss = None\n","        self.avg_val_loss = None\n","\n","    def forward(\n","        self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask\n","    ):\n","        output = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            labels=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","        )\n","        return output.loss, output.logits\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","        decoder_input_ids = batch[\"decoder_input_ids\"]\n","        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n","\n","        output = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","        )\n","\n","        self.log(\"loss\", output[0], prog_bar=True, on_step=True, on_epoch=True)\n","\n","        return output[0]\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","        decoder_input_ids = batch[\"decoder_input_ids\"]\n","        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n","\n","        output = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","        )\n","\n","        self.log(\"val_loss\", output[0], prog_bar=True, on_step=True, on_epoch=True)\n","\n","        return output[0]\n","\n","    def test_step(self, batch, batch_idx):\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","        decoder_input_ids = batch[\"decoder_input_ids\"]\n","        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n","\n","        output = self(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","        )\n","\n","        self.log(\"test_loss\", output.loss, prog_bar=True)\n","\n","        return output.loss\n","\n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=3e-4)\n","\n","    def training_epoch_end(self, training_step_outputs):\n","        self.avg_training_loss = np.round(\n","            torch.mean(torch.stack([x[\"loss\"] for x in training_step_outputs])).item(),\n","            4,\n","        )\n","        path = \"\"\n","        if os.path.exists(\"drive\"):\n","            path += \"drive/MyDrive/mt5-thai-qg/\"\n","        else:\n","            path += \"outputs/\"\n","        path += f\"mt5-qg-epoch-{self.current_epoch}-train-loss-{self.avg_training_loss}-val-loss-{self.avg_val_loss}\"\n","        self.tokenizer.save_pretrained(path)\n","        self.model.save_pretrained(path)\n","\n","    def validation_epoch_end(self, validation_step_outputs):\n","        _loss = [x.cpu() for x in validation_step_outputs]\n","        self.avg_val_loss = np.round(\n","            torch.mean(torch.stack(_loss)).item(),\n","            4,\n","        )\n"]},{"cell_type":"code","source":["# model = MT5ForConditionalGeneration.from_pretrained(\n","#     \"google/mt5-small\", return_dict=True\n","# )\n","# tokenizer = MT5TokenizerFast.from_pretrained(\"google/mt5-small\")\n","\n","\n","\n","model = MT5ForConditionalGeneration.from_pretrained(\n","    \"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-8-train-loss-0.0144-val-loss-0.278\",\n","    return_dict=True,\n",")\n","tokenizer = MT5TokenizerFast.from_pretrained(\n","    \"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-8-train-loss-0.0144-val-loss-0.278\"\n",")\n","\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8sFzk5l0yG0","executionInfo":{"status":"ok","timestamp":1659498679942,"user_tz":-420,"elapsed":21139,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"f08fd281-36bc-47a2-c138-92d86d6c8d39"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MT5ForConditionalGeneration(\n","  (shared): Embedding(250112, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(250112, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(250112, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415,"referenced_widgets":["cf51182bc3ad4c03b1c52ab234f85e59","78df3dd784b143bea77535deb28cc034","3bdb2834c2ad41ed9dc2b7dc9631cf6c","b42fa28fd19f41b3a859933e2a70c716","0b7edb027c104fe185f951caa7f02e9b","a9e4cb8d48ea418087530dd2ee7a9f38","1bf91e480eb0490582a5032d01be3495","a84d19651d7a4ce88ff3bb9278d5c2ff","3fabe8b67daf44bd8279ab8e33162e3f","4776f04dba244d3aab2a88c71aa43c5c","c85239627fb44b6babc4f60f0ed690eb","0bcca061b92e43499269c0a147ee65ea","f4af9fa6be7e4e71ad6d8a94f5897c5e","a5b6a79e04e24847a3ee13a1e51f7b2f","d25246d4e1a74a8389ce579b68e12a88","a49bc0ac285243c49058f5e0d0f46a7d","989a343a06964241afee3c6da8c470b9","4939e59c1e2b42f6a6790b458f660017","2dd88cc8f9124116b1878f8fb9772ca3","dae7c9d4a00b4cdca8414eb0b3c0ea82","d39640ca24a540f795f1003873fb7d1a","1ea88470f7f94da38eb6c168101a9175","95cddeb5dd7f4a6481e6647b094dca5b","2316561a89c84e0e918c74c805e5344e","8f25e79f07814fb2a1cac366957da0e3","8a90e0c6cc884a93a29ab6d83b058e00","1d506fb1906f47208a07afc88156fdef","8a7cbade081a452eac685027d8064007","8a59aae46aec4d6d923ff76cb385d3e3","6d418c5f153f484581e1ff1c8fcf583d","b62f68492a5646e2a7c24f86a68b3991","c128f9e5f6084e299d558b8679858aaf","f87cf9818d0e496e9a36994cddc4101c","36c7642c2ccb4461929752b2e10eabfd","49ba37b1d50d48c28d23a27e0ef45f56","122b13aaea1f40e9b31e33ecdc0f857c","8138181f03bd4380a04271052ef9dd97","c1447045c539477690ee9a0bf83d3dc7","5df5858c9e364f918cd830fe3f932587","afc0e594662e48f8a07a5be85413ab09","e0bcd581d44c40a193adf04799c55a53","e6ffe68f3e644ad28365ed6b50552be0","04c4fcac020b439fa1ddc11077fb413c","1dc30c34f33448268d4c6743e8b96b0c","9b2c5f18b9e5410ebeddd5b23d652977","b984f86d5b2a452e8c079139bce4959e","31b42b21888c4c6a9fc5f5450cff9918","237fa8635b37452e885a31a70b65b154","1a392d64311e4a37840a8351d9ed02ee","2945e5549c2346e7ba3305340515e3e6","000251af72a24889849b7c38495818a4","6f6d0bcc78b448d1bb17e430af899559","696bc531858241d7bf7881c4ae224814","41aaab93d5b14ad7b629f3e4ecdb0a7c","851d4d8a473a473b9dfa842292f92aa4","ee82265d0340433ea9578bbfe9ca77d7","45e8d8fcd7a34914ba379c56d42b0180","bf953bcf70a549519548a9628d3ac2a9","eceaa6656a7c460697076f7ed6a236fb","175fe809d124455b8475068f1e3a66df","25cb5ea7951e4d61a1284ce71f8b3180","e02a4437bd934b549f01e75e779c281d","3a310eb8ddf541aba01e1c3dfb72af39","20e321cbfd154892af939496b40a7f5c","583ea84db2814cb09bb8068cc137c72f","6a2c76e884334cfea916df80363cff3c","390fafda3087437b952754536b86179d","52f22eba742e445eabb848ef2d4fa6e5","f64729c47ff94ea1be6e5efbae63003b","971ed63be7d24fe5873facc3be2e5324","5444a87a18c8419fba1fe3cefd542b20","8403d9b077714775b5531d22222c4f69","ff8cbf65905847f3a8721b593f71f0c2","e7e39dc6498f4f6ca892da9d2a342c01","069b520e8ad844f6b095a0e73a9c6c12","1d70c7e3888c4c63b5a4262d1ae09f58","5054771977774af4bf201e9f46673c50"]},"id":"QdX5cYZo0y3a","executionInfo":{"status":"ok","timestamp":1659524424626,"user_tz":-420,"elapsed":25411132,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"b9e0b925-c9d1-4b7e-c2bc-61a15315d75f"},"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Missing logger folder: /content/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                        | Params\n","------------------------------------------------------\n","0 | model | MT5ForConditionalGeneration | 300 M \n","------------------------------------------------------\n","300 M     Trainable params\n","0         Non-trainable params\n","300 M     Total params\n","1,200.707 Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf51182bc3ad4c03b1c52ab234f85e59"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  category=PossibleUserWarning,\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  category=PossibleUserWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcca061b92e43499269c0a147ee65ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95cddeb5dd7f4a6481e6647b094dca5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c7642c2ccb4461929752b2e10eabfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b2c5f18b9e5410ebeddd5b23d652977"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee82265d0340433ea9578bbfe9ca77d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390fafda3087437b952754536b86179d"}},"metadata":{}}],"source":["dataset = MT5DataModule(tokenizer, train_df, valid_df, test_df, batch_size=1)\n","\n","MT5Model = MT5Lightning(model, tokenizer)\n","\n","callbacks = []\n","callbacks.append(EarlyStopping(monitor=\"val_loss\", mode=\"min\"))\n","\n","# wandb_logger = WandbLogger(\n","#     project=\"mT5-thai-multiple-e2e-qg\", name=\"mT5-small-thai-multiple-e2e-qg\"\n","# )\n","\n","trainer = pl.Trainer(\n","    accelerator=\"gpu\",\n","    devices=1,\n","    # logger=wandb_logger,\n","    max_epochs=20,\n","    log_every_n_steps=1,\n","    callbacks=callbacks,\n","    accumulate_grad_batches=20\n",")\n","\n","trainer.fit(MT5Model, dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipF4eNsNW9QW"},"outputs":[],"source":["def predict(text):\n","    with torch.no_grad():\n","        input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n","\n","        input_ids = input_ids.cuda()\n","\n","        # print(input_ids)\n","        model.cuda()\n","        generated_ids = model.generate(\n","            input_ids=input_ids,\n","            num_beams=3,\n","            max_length=10000,\n","            repetition_penalty=2.5,\n","            length_penalty=1.0,\n","            early_stopping=True,\n","            top_p=50,\n","            top_k=20,\n","            num_return_sequences=1,\n","        )\n","\n","        # print(generated_ids)\n","\n","        preds = [\n","            tokenizer.decode(\n","                g,\n","                skip_special_tokens=True,\n","                clean_up_tokenization_spaces=True,\n","            )\n","            for g in generated_ids\n","        ]\n","    return preds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9588,"status":"ok","timestamp":1659498695908,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"FavLVeYKW_aI","outputId":"260f8219-7617-4b38-b318-7ecc6ab1d0cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['เข้าไม่ได้ อะครับ']"]},"metadata":{},"execution_count":20}],"source":["text_to_predict = \"\"\"แก้คำผิด: เข้าไม่ได้ <mask><mask>ครับ\"\"\"\n","predicted = predict(text_to_predict)\n","predicted\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15056,"status":"ok","timestamp":1659526031981,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"-uMuewIXZMhI","outputId":"06020a43-9cbc-4b74-b9f2-dd065900cd29"},"outputs":[{"output_type":"stream","name":"stdout","text":["INPUT: แก้คำผิด:  จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี <mask>ครับ หรือสาขาไหนก็ได้\n","LABEL: จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี ไหมครับ หรือสาขาไหนก็ได้\n","จําเป็นต้องเปิดบริการกับสาขาที่เปิดบัญชี อะครับ หรือสาขาไหนก็ได้\n","------------------------------\n","INPUT: แก้คำผิด:  เมื่อวาน<mask>ยังเข้าได้\n","LABEL: เมื่อวาน ก็ยังเข้าได้\n","เมื่อวาน ก็ยังเข้าได้\n","------------------------------\n","INPUT: แก้คำผิด:  ผม<mask>ต่างประเทศครับ\n","LABEL: ผมอยู่ต่างประเทศครับ\n","ผมอยู่ต่างประเทศครับ\n","------------------------------\n","INPUT: แก้คำผิด:  พอไปสมัครที่<mask>\n","LABEL: พอไปสมัครที่ตู้\n","พอไปสมัครที่ตู้\n","------------------------------\n","INPUT: แก้คำผิด:  พอไปสมัครที่ตู้<mask>\n","LABEL: พอไปสมัครที่ตู้\n","พอไปสมัครที่ตู้ค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  <mask>มีปัญหาหรือคะตอนนี้\n","LABEL: แอพมีปัญหาหรือคะตอนนี้\n","ก็ไม่ได้มีปัญหาหรือคะตอนนี้\n","------------------------------\n","INPUT: แก้คำผิด:  แอพมีปัญหา<mask>คะตอนนี้\n","LABEL: แอพมีปัญหาหรือคะตอนนี้\n","แอพมีปัญหาหรือเปล่าคะตอนนี้\n","------------------------------\n","INPUT: แก้คำผิด:  แอพมีปัญหาหรือ<mask>ตอนนี้\n","LABEL: แอพมีปัญหาหรือคะตอนนี้\n","แอพมีปัญหาหรือคะตอนนี้\n","------------------------------\n","INPUT: แก้คำผิด:  พี่<mask>ผมอยาก รู้ว่า\n","LABEL: พี่ครับผมอยาก รู้ว่า\n","พี่คะผมอยาก รู้ว่า\n","------------------------------\n","INPUT: แก้คำผิด:  พี่ครับผมอยาก<mask>ว่า\n","LABEL: พี่ครับผมอยาก รู้ว่า\n","พี่ครับผมอยาก รู้ว่า\n","------------------------------\n","INPUT: แก้คำผิด:  แก้ไขปัญหาเปลี่ยนเบอร์มือถือได้อย่างไร<mask>\n","LABEL: แก้ไขปัญหาเปลี่ยนเบอร์มือถือได้อย่างไรครับ\n","แก้ไขปัญหาเปลี่ยนเบอร์มือถือได้อย่างไรคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ไม่ค่ะใช้<mask> เดิมค่ะ\n","LABEL: ไม่ค่ะใช้เบอร์ เดิมค่ะ\n","ไม่ค่ะใช้บัญชี เดิมค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  ไม่ค่ะใช้เบอร์<mask>เดิมค่ะ\n","LABEL: ไม่ค่ะใช้เบอร์ เดิมค่ะ\n","ไม่ค่ะใช้เบอร์ เดิมค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  เข้าไปโหลดตรง<mask>ครับ\n","LABEL: เข้าไปโหลดตรงไหนครับ\n","เข้าไปโหลดตรงไหนครับ\n","------------------------------\n","INPUT: แก้คำผิด:  จริงหรือไม่ถ้า<mask> k mobile banking ในแต่ละครั้งจะต้องเสียค่าธรรมเนียมและต้องเสียเท่าไหร่\n","LABEL: จริงหรือไม่ถ้าอัปเดต k mobile banking ในแต่ละครั้งจะต้องเสียค่าธรรมเนียมและต้องเสียเท่าไหร่\n","จริงหรือไม่ถ้าสมัคร k mobile banking แต่ละครั้งจะต้องเสียค่าธรรมเนียมและต้องเสียเท่าไหร่\n","------------------------------\n","INPUT: แก้คำผิด:  จะ<mask>  ได้ไงคะ\n","LABEL: จะเช็ค  ได้ไงคะ\n","จะสมัคร ได้ไงคะ\n","------------------------------\n","INPUT: แก้คำผิด:  จะเช็ค<mask> ได้ไงคะ\n","LABEL: จะเช็ค  ได้ไงคะ\n","จะเช็ค ได้ ได้ไงคะ\n","------------------------------\n","INPUT: แก้คำผิด:  จะเช็ค <mask>ได้ไงคะ\n","LABEL: จะเช็ค  ได้ไงคะ\n","จะเช็ค ได้ไงคะ\n","------------------------------\n","INPUT: แก้คำผิด:  โอนโดยใช้<mask>มือถือครับ\n","LABEL: โอนโดยใช้เบอร์มือถือครับ\n","โอนโดยใช้เบอร์มือถือครับ\n","------------------------------\n","INPUT: แก้คำผิด:  โอนโดยใช้เบอร์มือถือ<mask>\n","LABEL: โอนโดยใช้เบอร์มือถือครับ\n","โอนโดยใช้เบอร์มือถือค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  แต่<mask>ธนาคารเข้ายากค่ะ\n","LABEL: แต่แอปธนาคารเข้ายากค่ะ\n","แต่ ก็ธนาคารเข้ายากค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  แต่แอปธนาคารเข้า<mask>ค่ะ\n","LABEL: แต่แอปธนาคารเข้ายากค่ะ\n","แต่แอปธนาคารเข้าอะค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  สมัครผ่าน<mask>ไปแล้ว แต่ยังใช้ไม่ได้เลยค่ะ\n","LABEL: สมัครผ่านแอปไปแล้ว แต่ยังใช้ไม่ได้เลยค่ะ\n","สมัครผ่านแอปไปแล้ว แต่ยังใช้ไม่ได้เลยค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วถ้าอยาก<mask>ยอดการใช้งานบัตรเครดิตต้องทําอย่างไรอะคะ\n","LABEL: แล้วถ้าอยากเช็คยอดการใช้งานบัตรเครดิตต้องทําอย่างไรอะคะ\n","แล้วถ้าอยาก รู้ยอดการใช้งานบัตรเครดิตต้องทําอย่างไรอะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วถ้าอยากเช็คยอดการใช้งานบัตรเครดิตต้องทํา<mask>อะคะ\n","LABEL: แล้วถ้าอยากเช็คยอดการใช้งานบัตรเครดิตต้องทําอย่างไรอะคะ\n","แล้วถ้าอยากเช็คยอดการใช้งานบัตรเครดิตต้องทําอย่างไรอะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ทํางานก่อนนะ<mask>\n","LABEL: ทํางานก่อนนะจ้ะ\n","ทํางานก่อนนะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  คือโอนไป<mask>  นี้อะครับ\n","LABEL: คือโอนไปบัญชี  นี้อะครับ\n","คือโอนไปบัญชี นี้อะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  คือโอนไปบัญชี<mask> นี้อะครับ\n","LABEL: คือโอนไปบัญชี  นี้อะครับ\n","คือโอนไปบัญชี นี้อะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  คือโอนไปบัญชี <mask>นี้อะครับ\n","LABEL: คือโอนไปบัญชี  นี้อะครับ\n","คือโอนไปบัญชี นี้อะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเวลาส่งคืนทํา<mask>  คะ\n","LABEL: แล้วเวลาส่งคืนทําอย่างไร  คะ\n","แล้วเวลาส่งคืนทําไง คะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเวลาส่งคืนทําอย่างไร<mask> คะ\n","LABEL: แล้วเวลาส่งคืนทําอย่างไร  คะ\n","แล้วเวลาส่งคืนทําอย่างไร คะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเวลาส่งคืนทําอย่างไร <mask>คะ\n","LABEL: แล้วเวลาส่งคืนทําอย่างไร  คะ\n","แล้วเวลาส่งคืนทําอย่างไร อะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ขอบคุณ<mask>\n","LABEL: ขอบคุณครับ\n","ขอบคุณค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  ขอบคุณครับ<mask>\n","LABEL: ขอบคุณครับ\n","ขอบคุณครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ขอบคุณครับ <mask>\n","LABEL: ขอบคุณครับ\n","ขอบคุณครับ\n","------------------------------\n","INPUT: แก้คำผิด:  สอบถามหน่อยค่ะ บางทีก็โอน<mask>ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","LABEL: สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","สอบถามหน่อยค่ะ บางทีก็โอนได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","------------------------------\n","INPUT: แก้คำผิด:  สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ <mask>เพราะอะไรคะ\n","LABEL: สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ ใช่เพราะอะไรคะ\n","------------------------------\n","INPUT: แก้คำผิด:  สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไร<mask>\n","LABEL: สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","สอบถามหน่อยค่ะ บางทีก็โอนสตางค์ได้ บางทีก็โอนไม่ได้ เป็นเพราะอะไรคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ต้องทํา<mask>บ้างคะ\n","LABEL: ต้องทํายังไงบ้างคะ\n","ต้องทําอย่างไรบ้างคะ\n","------------------------------\n","INPUT: แก้คำผิด:  มีค่าธรรมเนียม<mask>บ้างอ่อคะ\n","LABEL: มีค่าธรรมเนียมอย่างไรบ้างอ่อคะ\n","มีค่าธรรมเนียมอะไรบ้างอ่อคะ\n","------------------------------\n","INPUT: แก้คำผิด:  <mask>ค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","LABEL: อ๋อค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","อ๋อค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:   อ๋อ<mask>ขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","LABEL: อ๋อค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","อ๋อค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:   อ๋อค่ะขอบคุณ<mask>แล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","LABEL: อ๋อค่ะขอบคุณค่ะแล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","อ๋อค่ะขอบคุณ แล้วถ้าสมัครบัตรเดบิต นี้ต้องเสียรายเดือนไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  รหัสจําได้<mask>\n","LABEL: รหัสจําได้ค่ะ\n","รหัสจําได้ไหม\n","------------------------------\n","INPUT: แก้คำผิด:  เวลาต้องหักค่าอะไรเพิ่ม<mask>ครับ\n","LABEL: เวลาต้องหักค่าอะไรเพิ่มไหมครับ\n","เวลาต้องหักค่าอะไรเพิ่มอะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ต้อง การ ใช้ บัตรเดบิต <mask>ครับ\n","LABEL: ต้อง การ ใช้ บัตรเดบิต อะครับ\n","ต้อง การ ใช้ บัตรเดบิต หรือเปล่าครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ได้<mask>ครับ\n","LABEL: ได้ เปล่าครับ\n","ได้ไหมครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ได้ เปล่า<mask>\n","LABEL: ได้ เปล่าครับ\n","ได้ เปล่าคะ\n","------------------------------\n","INPUT: แก้คำผิด:  การจ่ายเงินผ่าน <mask>  ของ <unk>\n","LABEL: การจ่ายเงินผ่าน  อินเทอร์เน็ต  ของ <unk>\n","การจ่ายเงินผ่าน บัญชี ของ \n","------------------------------\n","INPUT: แก้คำผิด:  การจ่ายเงินผ่าน  อินเทอร์เน็ต<mask> ของ <unk>\n","LABEL: การจ่ายเงินผ่าน  อินเทอร์เน็ต  ของ <unk>\n","การจ่ายเงินผ่าน อินเทอร์เน็ต ของ \n","------------------------------\n","INPUT: แก้คำผิด:  ไม่ทัน<mask>\n","LABEL: ไม่ทันอะ\n","ไม่ทันค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  จะเติมอะไร<mask>เติมไม่ได้\n","LABEL: จะเติมอะไร ก็เติมไม่ได้\n","จะเติมอะไร เติมไม่ได้\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วบัตรเก่า<mask>ครับ\n","LABEL: แล้วบัตรเก่าอะครับ\n","แล้วบัตรเก่าอะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  <mask>โอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่ไหมคะ\n","LABEL: อ๋อโอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่ไหมคะ\n","อ๋อโอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:   อ๋อโอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่<mask>คะ\n","LABEL: อ๋อโอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่ไหมคะ\n","อ๋อโอเคค่ะยกเลิกทันที แล้วก็สมัครใหม่ได้ทันทีเลยใช่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ลบแล้วลง<mask>ใหม่ เหรอครับ\n","LABEL: ลบแล้วลงแอปใหม่ เหรอครับ\n","ลบแล้วลงเบอร์ใหม่ เหรอครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ลบแล้วลงแอป<mask> เหรอครับ\n","LABEL: ลบแล้วลงแอปใหม่ เหรอครับ\n","ลบแล้วลงแอปใหม่ เหรอครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ลบแล้วลงแอปใหม่<mask>เหรอครับ\n","LABEL: ลบแล้วลงแอปใหม่ เหรอครับ\n","ลบแล้วลงแอปใหม่ เหรอครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ลบแล้วลงแอปใหม่ <mask>ครับ\n","LABEL: ลบแล้วลงแอปใหม่ เหรอครับ\n","ลบแล้วลงแอปใหม่ อะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ลบแล้วลงแอปใหม่ เหรอ<mask>\n","LABEL: ลบแล้วลงแอปใหม่ เหรอครับ\n","ลบแล้วลงแอปใหม่ เหรอคะ\n","------------------------------\n","INPUT: แก้คำผิด:  งง<mask>\n","LABEL: งงค่ะ\n","งงอะ\n","------------------------------\n","INPUT: แก้คำผิด:  งงค่ะ<mask>\n","LABEL: งงค่ะ\n","งงค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  เมื่อวานยังกดได้<mask>ค่ะ\n","LABEL: เมื่อวานยังกดได้อยู่ค่ะ\n","เมื่อวานยังกดได้อะค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  <mask>เป็นอะ ไรครับ โอนเงินไม่ได้เลยครับ\n","LABEL: แอปเป็นอะ ไรครับ โอนเงินไม่ได้เลยครับ\n","ก็เป็นอะ ไรครับ โอนเงินไม่ได้เลยครับ\n","------------------------------\n","INPUT: แก้คำผิด:  อยาก<mask> ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัคร อินเทอร์เน็ต ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อยากสมัคร<mask>ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัครอะค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อยากสมัคร ค่ะ<mask>ต่างประเทศจะสมัคร ได้ไหมคะ\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อยากสมัคร ค่ะอยู่ต่างประเทศจะ<mask> ได้ไหมคะ\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร<mask>ได้ไหมคะ\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหม<mask>\n","LABEL: อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","อยากสมัคร ค่ะอยู่ต่างประเทศจะสมัคร ได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  เหมือนเดิม<mask>ครับ\n","LABEL: เหมือนเดิมอะครับ\n","เหมือนเดิมอะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้<mask>ผมลบแอปแล้ว\n","LABEL: ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้อย่างไรผมลบแอปแล้ว\n","ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้ไหมผมลบแอปแล้ว\n","------------------------------\n","INPUT: แก้คำผิด:  ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้อย่างไรผมลบ<mask>แล้ว\n","LABEL: ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้อย่างไรผมลบแอปแล้ว\n","ไม่ครับผมเปลี่ยนใช้ซิมใหม่และจะเข้าบัญชีใหม่ครับแต่มันติดอันนี้ผมไม่เข้าใจว่ามันติดมาได้อย่างไรผมลบแอปแล้ว\n","------------------------------\n","INPUT: แก้คำผิด:  และ<mask> ใหม่เมื่อวานค่ะ\n","LABEL: และสมัคร ใหม่เมื่อวานค่ะ\n","และสมัคร ใหม่เมื่อวานค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  และสมัคร<mask>ใหม่เมื่อวานค่ะ\n","LABEL: และสมัคร ใหม่เมื่อวานค่ะ\n","และสมัคร ใหม่เมื่อวานค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  และสมัคร ใหม่เมื่อวาน<mask>\n","LABEL: และสมัคร ใหม่เมื่อวานค่ะ\n","และสมัคร ใหม่เมื่อวาน\n","------------------------------\n","INPUT: แก้คำผิด:  ถ้าเปลี่ยน<mask>ใหม่\n","LABEL: ถ้าเปลี่ยนเบอร์ใหม่\n","ถ้าเปลี่ยนเบอร์ใหม่\n","------------------------------\n","INPUT: แก้คำผิด:  มันต้องทํา<mask>อะครับ\n","LABEL: มันต้องทําอย่างไรอะครับ\n","นี่ต้องทําอย่างไรอะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  จะถามว่า รหัสผู้ใช้งานดูจากไหน<mask>คะ\n","LABEL: จะถามว่า รหัสผู้ใช้งานดูจากไหนอะคะ\n","จะถามว่า รหัสผู้ใช้งานดูจากไหนอะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  จะถามว่า รหัสผู้ใช้งานดูจากไหนอะ<mask>\n","LABEL: จะถามว่า รหัสผู้ใช้งานดูจากไหนอะคะ\n","จะถามว่า รหัสผู้ใช้งานดูจากไหนอะคะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเปิดบัญชี ต้องเอา<mask>ไปบ้างเหรอคะ\n","LABEL: แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างเหรอคะ\n","แล้วเปิดบัญชี ต้องเอาสตางค์ไปบ้างเหรอคะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเปิดบัญชี ต้องเอาอะไรไปบ้าง<mask>คะ\n","LABEL: แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างเหรอคะ\n","แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างเหรอ<mask>\n","LABEL: แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างเหรอคะ\n","แล้วเปิดบัญชี ต้องเอาอะไรไปบ้างเหรอคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อายุ ทํา<mask>ไหมคะ\n","LABEL: อายุ ทําได้ไหมคะ\n","อายุ ทําได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  อายุ ทําได้ไหม<mask>\n","LABEL: อายุ ทําได้ไหมคะ\n","อายุ ทําได้ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  มีเพื่อนแนะนํา มาว่าธนาคารกรุงศรีสามารถทําได้บ้าง ไม่ได้บ้าง<mask>ค่ะ\n","LABEL: มีเพื่อนแนะนํา มาว่าธนาคารกรุงศรีสามารถทําได้บ้าง ไม่ได้บ้างอะค่ะ\n","มีเพื่อนแนะนํา มาว่าธนาคารกรุงศรีสามารถทําได้บ้าง ไม่ได้บ้างอะค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  โหลดแอปมา ครั้ง<mask>ก็ยังสมัครไม่ได้สักทีเลยครับ\n","LABEL: โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีเลยครับ\n","โหลดแอปมา ครั้งหนึ่งก็ยังสมัครไม่ได้สักทีเลยครับ\n","------------------------------\n","INPUT: แก้คำผิด:  โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักที<mask>ครับ\n","LABEL: โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีเลยครับ\n","โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีอะครับ\n","------------------------------\n","INPUT: แก้คำผิด:  โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีเลย<mask>\n","LABEL: โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีเลยครับ\n","โหลดแอปมา ครั้ง แล้วก็ยังสมัครไม่ได้สักทีเลยคะ\n","------------------------------\n","INPUT: แก้คำผิด:  เปลี่ยน<mask>  แต่ต้องสมัครใหม่ไหมคะ\n","LABEL: เปลี่ยนโทรศัพท์  แต่ต้องสมัครใหม่ไหมคะ\n","เปลี่ยนเบอร์ แต่ต้องสมัครใหม่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  เปลี่ยนโทรศัพท์<mask> แต่ต้องสมัครใหม่ไหมคะ\n","LABEL: เปลี่ยนโทรศัพท์  แต่ต้องสมัครใหม่ไหมคะ\n","เปลี่ยนโทรศัพท์ แต่ต้องสมัครใหม่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  เปลี่ยนโทรศัพท์ <mask>แต่ต้องสมัครใหม่ไหมคะ\n","LABEL: เปลี่ยนโทรศัพท์  แต่ต้องสมัครใหม่ไหมคะ\n","เปลี่ยนโทรศัพท์ แต่ต้องสมัครใหม่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  เปลี่ยนโทรศัพท์  แต่ต้องสมัครใหม่<mask>คะ\n","LABEL: เปลี่ยนโทรศัพท์  แต่ต้องสมัครใหม่ไหมคะ\n","เปลี่ยนโทรศัพท์ แต่ต้องสมัครใหม่ไหมคะ\n","------------------------------\n","INPUT: แก้คำผิด:  ขอ<mask>ค่ะ\n","LABEL: ขอเบอร์ค่ะ\n","ขอยังไงค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  เขาบอกมันทําใน<mask>ได้เลย\n","LABEL: เขาบอกมันทําในแอปได้เลย\n","เขาบอกมันทําในแอปได้เลย\n","------------------------------\n","INPUT: แก้คำผิด:  ทําไมสมัครไม่ได้<mask>\n","LABEL: ทําไมสมัครไม่ได้ครับ\n","ทําไมสมัครไม่ได้คะ\n","------------------------------\n","INPUT: แก้คำผิด:  ทําไมสมัครไม่ได้ครับ<mask>\n","LABEL: ทําไมสมัครไม่ได้ครับ\n","ทําไมสมัครไม่ได้ครับ\n","------------------------------\n","INPUT: แก้คำผิด:  เข้าใช้<mask>ไม่ได้ค่ะ\n","LABEL: เข้าใช้แอปไม่ได้ค่ะ\n","เข้าใช้แอปไม่ได้ค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  ทําบัตร เครดิต หาย<mask>ค่ะ\n","LABEL: ทําบัตร เครดิต หายอะค่ะ\n","ทําบัตร เครดิต หายอะค่ะ\n","------------------------------\n","INPUT: แก้คำผิด:  โหลดใส่เครื่องใหม่<mask>ขึ้นแต่แบบนี้ค่ะ\n","LABEL: โหลดใส่เครื่องใหม่ ก็ขึ้นแต่แบบนี้ค่ะ\n","โหลดใส่เครื่องใหม่ ก็ขึ้นแต่แบบนี้ค่ะ\n","------------------------------\n","41 / 20\n"]}],"source":["cou = 0\n","for i in range(100):\n","  text_to_predict = test_df.iloc[i]['source_text']\n","  labels = test_df.iloc[i]['target_text']\n","  print(f\"INPUT: {text_to_predict}\")\n","  print(f\"LABEL: {labels}\")\n","  predicted = predict(text_to_predict)\n","  print(predicted[0])\n","  if predicted[0] == labels:\n","    cou += 1\n","  print(\"------------------------------\")\n","print(f\"{cou} / 20\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867,"referenced_widgets":["2b26d67ee49144ddaa7a968b21fcb271","992cd38899fb4d72813f721af8f57bdb","f82d72f405d44a1c815b376d4515a517","9994d5a29d72462cae0f2326cf60d274","1923362afb0d40b991be93c9e7eb3445","9b5ac575d2444a2684332632f4729f7d","f349705a4ac64e49ae66eca3578da471","fc1e6fe15a504b338a933e5ba34edfd2","6c2c40222afc4cfa8447e274be0c0a5b","4ef5e4456549494e9af9590932a1468c","16b304b8dc9a4aff959455b52544d3ed","c9021b39802e4207b876b3948f95876a","8c54a043cdb1428fb786fb77a3fbb2b2","b6e9d7b4904346e9bc4a645fe7ecab27","e6c6aa874cf543cc9dbc89e8f7427711","483158b39ae64f45b9c7ebe2e3668944","b97cb4a64688484683f928ed02533661","a4628aef19674546b9d09a2cf3a38d30","1a696d82a3994743898e129e77f4f8e2","0d7899b54ebc4002a1e93b9c89de1024","e30c266bf2b543f4a89859b02a59a2ec","bd5439d9bf8242089a6378ef45d85b0d"]},"executionInfo":{"elapsed":33798,"status":"ok","timestamp":1655636863194,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"BIamB4jjpPDd","outputId":"99765bbc-4164-4ce9-9bb5-bd2623080f18"},"outputs":[{"name":"stderr","output_type":"stream","text":["https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpeyypael4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b26d67ee49144ddaa7a968b21fcb271","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","creating metadata file for /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","loading configuration file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","Model config CamembertConfig {\n","  \"_name_or_path\": \"bookpanda/wangchanberta-base-att-spm-uncased-masking\",\n","  \"architectures\": [\n","    \"CamembertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_head\": 12,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 33660\n","}\n","\n","https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe_9clcso\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9021b39802e4207b876b3948f95876a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/427M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","creating metadata file for /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","loading weights file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","All model checkpoint weights were used when initializing CamembertForMaskedLM.\n","\n","All the weights of CamembertForMaskedLM were initialized from the model checkpoint at bookpanda/wangchanberta-base-att-spm-uncased-masking.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForMaskedLM for predictions without further training.\n"]}],"source":["amodel = AutoModelForMaskedLM.from_pretrained(\"bookpanda/wangchanberta-base-att-spm-uncased-masking\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f3eafeae8b844036a7b5f0c1a6ebe4e5","5fff9c8e4b0c4d6198aad11efb689820","70ec88c2387441ac80a20b7d79094eca","918e65e8746e4231b8a82a4b600eeebe","0eaa2e0e1e8342f6a7a3d301f574dbbe","145b2142cd644bbfb56e75ee681f322f","f8f781ac63034f7ea1c66d7ad1b9b8cc","649dea9a14af42fb9e900a591d8b12a4","d9f192112cfd48f3b6c42e149c94d5cc","f7bf0bcc78be4145a27ab0646ca104fc","8ed3ba25ad40403496364bcd87a89bce","7c71361f762243609c5bb03f7067d78c","d4cb88aa34de482883027be38aad4262","ac06732669bd4b6c817e6ad629394c65","cb7bee8ed9f74c86a6dccc3e147ab8d5","7fb9f1006f864efe97fc6c364c832984","c1571e270ccc4f3b9b5b026bb642aa18","04256747b95a43b3baab0462780b130f","a819e447802f40009cd655bd97d4adb5","59479122c9c542139624a08e81d68d68","f4f3948d040e4e319b287b5fefd81a86","a6e90eb74f6a448dab18e5b9593f6123"]},"executionInfo":{"elapsed":33252,"status":"ok","timestamp":1657091308355,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"g0gJa-IuwIrS","outputId":"d8e84a3b-5f3e-4ac5-8ff0-d46fd5224619"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3eafeae8b844036a7b5f0c1a6ebe4e5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c71361f762243609c5bb03f7067d78c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/404M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CamembertForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(25354, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=25354, bias=True)\n","  )\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","model_checkpoint = \"airesearch/wangchanberta-base-att-spm-uncased\"\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","FILE = \"drive/MyDrive/AIBuilders/json/mlm_json_3.pth\"\n","model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","model = model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657091308355,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"HuRt6oooIT25","outputId":"6c3af342-4c6a-4836-e238-6957d93ba644"},"outputs":[{"data":{"text/plain":["CamembertForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(25354, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=25354, bias=True)\n","  )\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"mmzS6fR27EPj"},"source":["# Data Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z4fISZnPbgK"},"outputs":[],"source":["df = pickle.load(open('drive/MyDrive/AIBuilders/json/mlm_json_15k.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spCaJAzyeKTN"},"outputs":[],"source":["df_test = df[10576:]\n","df = df[:10576]\n","df_train, df_val = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.9 * len(df))])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1657091325701,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"OvG-tIqcP5DS","outputId":"a326a3c4-cd52-4c07-ab72-2f794f902d6a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-794b09d8-367b-441c-90e3-14d3b882aeb5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1284</th>\n","      <td>[5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1,...</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>[5, 10, 1167, 1045, 878, 25004, 25004, 25004, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 1167, 1045, 878, 627, 70, 265, 6, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>9188</th>\n","      <td>[5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...</td>\n","    </tr>\n","    <tr>\n","      <th>5076</th>\n","      <td>[5, 10, 1834, 13725, 2102, 25004, 25004, 199, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n","      <td>[5, 10, 1834, 13725, 2102, 234, 265, 199, 1454...</td>\n","    </tr>\n","    <tr>\n","      <th>1393</th>\n","      <td>[5, 330, 13621, 25004, 25004, 25004, 6, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 330, 13621, 25105, 265, 265, 6, 1, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4757</th>\n","      <td>[5, 627, 1280, 25004, 25004, 25004, 25004, 250...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 627, 1280, 231, 265, 265, 726, 265, 126, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>10098</th>\n","      <td>[5, 729, 25004, 1481, 1116, 6, 1, 1, 1, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 729, 8704, 1481, 1116, 6, 1, 1, 1, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>6320</th>\n","      <td>[5, 7894, 1063, 145, 1849, 300, 25004, 6, 1, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 7894, 1063, 145, 1849, 300, 73, 6, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>5975</th>\n","      <td>[5, 2169, 25004, 864, 286, 94, 25004, 25004, 2...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 2169, 15, 864, 286, 94, 415, 260, 23, 695,...</td>\n","    </tr>\n","    <tr>\n","      <th>3572</th>\n","      <td>[5, 10, 26, 112, 7620, 25004, 25004, 6, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 26, 112, 7620, 894, 73, 6, 1, 1, 1, 1,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9518 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-794b09d8-367b-441c-90e3-14d3b882aeb5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-794b09d8-367b-441c-90e3-14d3b882aeb5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-794b09d8-367b-441c-90e3-14d3b882aeb5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               input_ids  \\\n","1284   [5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, ...   \n","6997   [5, 10, 1167, 1045, 878, 25004, 25004, 25004, ...   \n","9188   [5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...   \n","5076   [5, 10, 1834, 13725, 2102, 25004, 25004, 199, ...   \n","1393   [5, 330, 13621, 25004, 25004, 25004, 6, 1, 1, ...   \n","...                                                  ...   \n","4757   [5, 627, 1280, 25004, 25004, 25004, 25004, 250...   \n","10098  [5, 729, 25004, 1481, 1116, 6, 1, 1, 1, 1, 1, ...   \n","6320   [5, 7894, 1063, 145, 1849, 300, 25004, 6, 1, 1...   \n","5975   [5, 2169, 25004, 864, 286, 94, 25004, 25004, 2...   \n","3572   [5, 10, 26, 112, 7620, 25004, 25004, 6, 1, 1, ...   \n","\n","                                          attention_mask  \\\n","1284   [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","6997   [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n","9188   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","5076   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n","1393   [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","...                                                  ...   \n","4757   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","10098  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","6320   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","5975   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","3572   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","                                                  labels  \n","1284   [5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1,...  \n","6997   [5, 10, 1167, 1045, 878, 627, 70, 265, 6, 1, 1...  \n","9188   [5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...  \n","5076   [5, 10, 1834, 13725, 2102, 234, 265, 199, 1454...  \n","1393   [5, 330, 13621, 25105, 265, 265, 6, 1, 1, 1, 1...  \n","...                                                  ...  \n","4757   [5, 627, 1280, 231, 265, 265, 726, 265, 126, 1...  \n","10098  [5, 729, 8704, 1481, 1116, 6, 1, 1, 1, 1, 1, 1...  \n","6320   [5, 7894, 1063, 145, 1849, 300, 73, 6, 1, 1, 1...  \n","5975   [5, 2169, 15, 864, 286, 94, 415, 260, 23, 695,...  \n","3572   [5, 10, 26, 112, 7620, 894, 73, 6, 1, 1, 1, 1,...  \n","\n","[9518 rows x 3 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409,"status":"ok","timestamp":1657091330222,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"GH_XtzsDziSz","outputId":"f8dc44ad-016f-48d9-d818-fa3213552e1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["print(df_train.iloc[0]['input_ids'])\n","print(df_train.iloc[0]['attention_mask'])\n","print(df_train.iloc[0]['labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnBSmeMlezkG"},"outputs":[],"source":["df_train = Dataset.from_pandas(df_train)\n","df_val = Dataset.from_pandas(df_val)\n","df_test = Dataset.from_pandas(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1657091336177,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"aqQ3JMlbfA-b","outputId":"c31a1171-f554-4fe7-ce11-b5fa018f331d"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","    num_rows: 9518\n","})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsq-Zs_Lq4tI"},"outputs":[],"source":["combined_dataset = DatasetDict({\n","    'train': df_train,\n","    'test': df_val,\n","    'valid': df_test})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657091341383,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ExAkoSqJtYz5","outputId":"0b9ba6e7-a4c3-4929-98cf-b7c489325375"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 9518\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 1058\n","    })\n","    valid: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 5000\n","    })\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["combined_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1657091343806,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"g_uiCeTpfXXU","outputId":"ad10952e-a9fe-42dc-c3f3-0fe79433a913"},"outputs":[{"data":{"text/plain":["461"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","import gc\n","del df\n","del df_train\n","del df_val\n","del df_test\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657091345325,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"bTtMT49atGOM","outputId":"88743486-126a-491e-bda1-6c385ad4007e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login() # เอาไว้โยนโมเดลขึ้น hugging face ได้เลย"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy-jAg11qvgl"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","batch_size = 16\n","# Show the training loss with every epoch\n","logging_steps = len(combined_dataset[\"train\"]) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-masking\",\n","    overwrite_output_dir=True,\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    push_to_hub=True,\n","    num_train_epochs = 3,\n","    fp16=True, # สำหรับคนใช้ GPU\n","    logging_steps=logging_steps,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["ae41fd9a61fd4737a20bd1bc012313f5","2da3c5e1aaf44e73b98e3edc4bfdca7c","b952623bc4694706b802695b82a6d171","378ac02b3c0445dba5f0d360225b61a5","69b6cce9bf5a4f35afcc49f6cc9880bf","b0ac06c7bdda4e56953613c3fedef2a1","0eb3363e2c164990bdd1a3c586b206b6","7e257def77844680a7da34e13efdf2ea","4e0db67e76424135a7a5018168c8f098","2a657e553ed84d6eb4b21d78bf724337","38a65dc5cc2147918b87ecdc9d94ca2c","4e535d77dae1444c8175eb0ecd308770","2842b63f9ac74643b26fba7a7baf174e","3609200b1e6a436b8e98b9d7c1aef298","859645b4856b479e8454b205e8975ab8","20f9270c842f42488cacaaf9efa66aad","64e159c5af804bbfb1ee4eb59869d745","9a35f3b26d9147eda3e14f6eb6f39dcb","27029db2dc6d46a4a7bcd255f5cffe22","2e07ce15f1fb4a26bbc78ca2f4b4e805","5f3a4c697abb4707bf71ce007f983b63","ad626ea16d44478c9fff6cf9a5f9ef55","7f8ecb32ff9c45889dc34aea594fb8c4","3062e07104074ab28cd7d2ba9caf8981","a87be5b4deae49199c4352d6d40b53de","bf7c8af4510c4bdca84109e51b0ac42d","f463ef9a65d54cce967f453474840096","b184a8d3061a418a8c24b69e8adb5e51","a379143d7bae49d899ee0b3b22b477ec","a8b8fb1a4f2a41f194b68518be7b1755","ba82d007461248adab326acf16fba6cb","bb7971f12d2040c09b4a8df47ac80954","68584c751d1c4595846237cfd83b9201","62186b93324c455eb39970a26e120ac0","27d10cc518ec48698ca6a1e6cd4a88c2","e05dec65ddb54b96a740e6c072c31412","77ad22152cd9457c8e85f3dceacd2836","8cfba2e0f9834b76ae11c8ec37551711","44d8a0a1b4514aa6a1783ff34bc280c5","af5a054aade745b4ade6d6eddbb6258a","1780d968589b469385d19bce8f2912ea","6bbf4f327411495984d5e3d27afb5fc9","3e82d564ea2a48a0b8ea23387ac6c81a","08157f0343f94336ad5157e60b5ab2a9"]},"executionInfo":{"elapsed":192752,"status":"ok","timestamp":1657091552950,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"-tCZDaN8s05p","outputId":"dbb48631-066a-4cd3-8e86-094e3a6fec5c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Cloning https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking into local empty directory.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae41fd9a61fd4737a20bd1bc012313f5","version_major":2,"version_minor":0},"text/plain":["Download file pytorch_model.bin:   0%|          | 83.0/427M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e535d77dae1444c8175eb0ecd308770","version_major":2,"version_minor":0},"text/plain":["Download file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f8ecb32ff9c45889dc34aea594fb8c4","version_major":2,"version_minor":0},"text/plain":["Clean file training_args.bin:  34%|###4      | 1.00k/2.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62186b93324c455eb39970a26e120ac0","version_major":2,"version_minor":0},"text/plain":["Clean file pytorch_model.bin:   0%|          | 1.00k/427M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using amp half precision backend\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=combined_dataset[\"train\"],\n","    eval_dataset=combined_dataset[\"valid\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":771},"executionInfo":{"elapsed":2196813,"status":"ok","timestamp":1657096184063,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"QvLik2xbwl5C","outputId":"8649597c-e916-48b1-88ea-bff1fdd44223"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `CamembertForMaskedLM.forward` and have been ignored: __index_level_0__.\n","***** Running training *****\n","  Num examples = 9518\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1785\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1785' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1785/1785 36:35, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.019100</td>\n","      <td>0.020692</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.019100</td>\n","      <td>0.020692</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.019000</td>\n","      <td>0.020692</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=1785, training_loss=0.01904480025506153, metrics={'train_runtime': 2196.4521, 'train_samples_per_second': 13.0, 'train_steps_per_second': 0.813, 'total_flos': 7515096898646016.0, 'train_loss': 0.01904480025506153, 'epoch': 3.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vo42h-y6sRPx"},"outputs":[],"source":["FILE = \"/content/drive/MyDrive/AIBuilders/json/mlm_json_6.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["a81d4bc96f8449208265c0d8b50ce959","da1f26a0c43e49beb2deb9327aa5a07d","042230d6d0c842a4b9bd8302a799597e","645f2aac90b04e95817a1eddf6e8afff","db2b75a4c4054eae852505b76ac0f69b","eb4545e74f564cc294bf4e400ff737f1","058520ac5e8d4be09bc0b62405b94d0a","49848535c2094cd4ac4c79ce765fb046","66ffcfaad7614879bc63e5ca4beae83e","9981e2a9842041f9b590f5205794e73b","651237317ea84458b9623a92d026fe81","cea9a81e93d84955b85fe2a5a40675da","8d812b10c2b04d3fa215e66a7cff2cea","278047df951041bd90fdd5e5d3871490","dd7f3b4d7e2a4efd9ac073ec34ded50b","b0ffc3d3d9754712b4e87487d06e397a","7ef1c8bffcdd4b098c1dcae97f2d63ad","9f00dd09c3884b5ca16014ba7620f462","d01bdae0448749c29a0dc6bc11e16e42","64a5ac383e4742268a87fd1a815c119b","287e857523eb41e1b103f448e4e97cde","d3b3fa08164c49d19e31aa4a355d7f4c"]},"executionInfo":{"elapsed":353890,"status":"ok","timestamp":1655636768996,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"gWlP9YgBxEnu","outputId":"3e35af19-cf51-4d13-cf15-699274fadc4e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/pytorch_model.bin\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a81d4bc96f8449208265c0d8b50ce959","version_major":2,"version_minor":0},"text/plain":["Upload file pytorch_model.bin:   0%|          | 3.34k/427M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cea9a81e93d84955b85fe2a5a40675da","version_major":2,"version_minor":0},"text/plain":["Upload file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   0ad3488..042aaa7  main -> main\n","\n","Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n","To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   042aaa7..d124223  main -> main\n","\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/commit/042aaa7a82de0ea8414ca4f8eb1e486c59978c17'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()# โยนขึ้น hugging face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crQST5D-xj_L"},"outputs":[],"source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8153,"status":"ok","timestamp":1655628677930,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"0Cz7bvztxoW7","outputId":"f184a44a-5526-42b1-d364-49bad07c5f15"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'classifier.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","if use_cuda:\n","    model = model.cuda()\n","FILE = \"drive/MyDrive/AIBuilders/mlm/tagging_nova_75.pth\"\n","loaded_model = BertModel()\n","loaded_model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","loaded_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u65GCzVvxu8U"},"outputs":[],"source":["ids_to_labels = {0: 'f', 1: 'i'}\n","\n","def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","        else:\n","            try:\n","              label_ids.append(2)\n","            except:\n","                label_ids.append(-100)\n","\n","        previous_word_idx = word_idx\n","    return label_ids\n","\n","def evaluate_one_text(model, sentence):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n","\n","    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","\n","    logits = model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    return prediction_label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1655628697373,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"dStVnDt6x9Nu","outputId":"e67bb371-92c9-4e9e-ca0b-8e9aa2a1563e"},"outputs":[{"name":"stdout","output_type":"stream","text":["['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'i', 'i', 'i']\n","['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>']\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลก<mask>ป่าวคับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอะป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรื อป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลก จริง ๆป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอ๊ะป่าวคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิง<mask>คับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<pad>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงไหมคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<s>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง_คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงอะคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิงป่าว<mask></s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวครับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนี่</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าววะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวเนี่ย</s>'\n","{'input_ids': [5, 10, 136, 88, 932, 13, 3789, 30987, 10, 5204, 485, 7773, 3774, 2916, 801, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","<s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือ<pad>ครับ</s>\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","# if use_cuda:\n","#     model = model.cuda()\n","\n","text = \"ประเทศเราผลิตและส่งออกยาสูบเยอะสุดในโลกจิงป่าวคับ\"\n","ans = []\n","i_f = evaluate_one_text(loaded_model, text)\n","print(i_f)\n","a = tokenizer(text)\n","b = a['input_ids']\n","c = tokenizer.convert_ids_to_tokens(b)\n","print(c)\n","i_f_len = len(i_f)\n","for j in range(i_f_len):\n","  if(i_f[j] == 'i'):\n","    ph = a['input_ids'][j+1]\n","    a['input_ids'][j+1] = 25004\n","    print(tokenizer.decode(a['input_ids']))\n","    b = {'input_ids': torch.Tensor([a['input_ids']]).type(torch.int64).to(device), 'attention_mask': torch.Tensor([a['attention_mask']]).type(torch.int64).to(device)}\n","    token_logits = model(**b).logits\n","    mask_token_index = torch.where(b[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","    mask_token_logits = token_logits[0, mask_token_index, :]\n","    top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n","    ans.append((j, top_5_tokens[0]))\n","    text = ''.join(tokenizer.convert_ids_to_tokens(a['input_ids']))\n","    for token in top_5_tokens:\n","        print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n","    a['input_ids'][j+1] = ph\n","\n","print(a)\n","for x,y in ans:\n","  a['input_ids'][x+1] = y\n","print(''.join(tokenizer.convert_ids_to_tokens(a['input_ids'])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nX5csn56T5_M"},"outputs":[],"source":["asdsf = pd.read_csv(\"drive/MyDrive/AIBuilders/final.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655631575823,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"rjXdABefT9VQ","outputId":"90f27851-af69-4253-bb21-261ca3a8ed78"},"outputs":[{"name":"stdout","output_type":"stream","text":["ต้องลอง555\n","อยากได้เตาอบบาบีก้อน จะเอามาทำขนมให้ลูกๆ ไปทานเล่นระหว่างวันค่ะ เป็นแม่บ้านว่างๆ ก็จะสรรหาเมนูใหม่ๆ ตามยูทูปเอามาลองทำ มีลูกนี่แหละเป็นหนูทดลอง 555 เห็นเตาก้อนแล้วอยากทำขนมคุ๊กกี้อบมากเลยค่ะ เอาเป็นรูปซานต้ากับต้นคริสมาส ฝึกทันพอดีก่อนเทศกาลเลย ❤️❤️❤️❤️❤️\n","เกิน 50 ไม่ไป!\n","แฟชั่นไอส์แลนด์ วันที่3/12ค่า\n","ลดพิเศษเเต่ของน้อยไม่ค่อยเติม\n","ฮื้ออออ เค้าสับเพร่า เค้าสับเพร่าาาาา เค้าจ่ายเต็มมมมม แต่อร่อยเด้ออออ ฮื้อออ\n","ผ่านนิเทศไปก่อนนะ\n","ไปคนเดียวดีฝ่าา\n","สาขาเพลินนารี่ ถ้าไม่อยากขายก้อปิดเถอะคับ ดูแลไม่ดีแล้วพนง.ยังไม่มีจิตใจในการขายด้วย เวลา1ชม.กับหลายๆอย่างไม่ไหวคับ หาคนมาดูบ้างนะครับ\n","ขาดเลยละ55 ไฮเนเก้น พอๆๆ 2 ขวด 555\n","ลอรีอัล รีไวทัลลิฟท์ เดอร์มาลิฟท์เดย์ครีม 50กรัม/ไนท์ ครีม 50กรัม ได้รับคูปองส่วนลด จากราคาเต็ม 599 บาท ลด 120บาท เหลือ 479บาท ในโปรโมชั่น watsons Beauty in Summer (29 มี.ค.-25 เม.ย. 61)\n","แล้วโครงการอื่นล่ะ??? แสนสิริเตรียมแจงกรณีปัญหาผนังห้องชุดโครงการเดอะ เบส สุขุมวิท 77 พรุ่งนี้ หลังพบใช้โฟมเป็นวัสดุก่อผนัง”\n","มีซูชิหรอ\n","นิสสันโน๊ตครับ\n","ขอบพระคุณคร้าบ\n","ขอสำรองได้มั้ยอ่า\n","ตอนนอนใส่แบบสอดฟินไม่เลอะที่นอน ตอนเช้าแบบผ้าอนามัยทั่วไป แต่แบบนี้ก็น่าลองนะคะคงสะดวกกว่าเยอะ\n","ป๊า เค้าอยากกินน 😁😁\n","ไป อยากจังแล้วนิ\n","สมองไหลตลอด\n","แอดมินขอส่งเรื่องให้หัวหน้างานตรวจสอบการทำงานของพนักงานที่สาขาให้นะคะ และขอน้อมรับคำแนะนำของลูกค้า เพื่อส่งต่อไปยังหน่วยงานที่เกี่ยวข้องเพื่อการพัฒนาและปรับปรุงการบริการของเราให้ดียิ่งๆขึ้นไปนะคะ\n","ซื้อไร ชวนไปแดร๊กส์\n","การได้สั่งลาวันอาทิตย์ ด้วย Jameson Ginger & Lime สักแก้วนี่มันดีจริงๆ นะ ถ้าไม่เชื่อ ก็ลองทำตามดูได้! #JamesonThailand #TwiceAsSmooth\n","นี่นิสสันยังดูไม่ใหญ่อีกเหรอครับ..ส่วนตัวคิดว่ารถกระบะนิสันออกแบบดูเทอะทะกว่าค่ายอื่นในยุคเดียวกัน(แต่ดูตัวเลขแล้วก็ไม่ได้ใหญ่นะ)ถ้าเขาเดินเกมแบบค่ายเจ้าตลาดทั้ง2ค่ายหรือออกตัวเท่ๆแบบฟอร์ดน่าตะไปได้ดีกว่านี้(ฟอร์ดยังไม่ใข่แรปเตอร์นะแรปเตอร์ส่วนตัวว่าแรปเตอร์เป็นปิคอัพหรูน่าจะเฉพาะกลุ่มที่เงินถึงๆ)\n","(‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’) http://www.jiggaban.com/97024-get1025-4/ ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่... ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่\n","กูตื่นเต้นมากกกกกกกกกกกกกกกกจะหมดเวลาปิดหีบแล้ววววอีกไม่กี่นาที\n","http://www.steam-engine.org/\n","ประเทศอื่นเขาสนับสนุนให้ใช้แทนบุหรี่จริง แต่ประเทศไทยมันยากหน่อยเพราะลงทุนสร้างโรงงานยาสูบใหม่ไปหลายร้อยล้าน\n","เลิกซื้อ หันมาขอเพื่อนสูบแทนใช่มั้ยครับ\n","แม้ว่า Nissan Maxima และ Murano ในปัจจุบันทำยอดขายดีขึ้นกว่ารุ่นเดิมแค่ระดับหนึ่ง แต่ในจีน Maxima กลับล้มเหลว Murano แค่พอไปได้ นี่อาจจะเป็นเหตุผลหลักที่ทำให้การปรับโฉม Minorchange ต้องดูสง่างามขึ้น\n","ชิ\n","หน้าพี่แบคตอนโดนเพื่อนลากไปตีคือกุวงวารมาก ฮือ หน้าแบบนี่กุต้องโดนเหรอ สติหลุดไปแล้ว5555555555555555555\n","เลือกได้ 2 ซุป และน้ำจิ้มท่านละ 1 รสชาติค่ะ ^^\n","มีโปรบุฟเฟต์หรือค่ะถึงวันที่เท่าไรค่ะ\n","นิสสันโน๊ต รถประหยัดน้ำมัน ราคาเบา ดีไซร์เลิศ ขับขี่ดีมากๆ ใครๆก้อชอบ มีหลายสีให้เลือกด้วยครับ\n","พลาดเพราะรีโว่นั่นแหละ\n","5555เดะบอกอีกทีสอบเสร็จก่อน\n","ดูข่าวที่ชวนปราศรัย เหมือนแกยังไม่รู้ว่า ทักษิณไม่ได้เป็นนายกแล้ว\n","ถ้าทำประตูเปิดเหมือนRX8 เจ้า CHR จะเป็นผู้บุกเบิกรถทรงนี้อย่างเต็มตัว..เพราะมันจะเข้ากับบุคลิกรถแคปทึบสปอร์ต..น่าเสียดาย\n","หิวพี่ก้อนอีกแล้ว\n","ก็ต้องไง จะใครละ\n","รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” เมื่อวันเสาร์ที่ 9 ธันวาคม 2560 รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” ชวนคุณมาไขความลับชะลอวัย โดย พญ.พันธลี ชื่นสัมพันธ์ แพทย์สาขาเวชศาสตร์ชะลอวัย ด้านโภชนาการและเมตาบอลิสึม รพ.กรุงเทพพัทยา และ คุณวิสสุตา กฤติยานิธิ นักกำหนดอาหาร และทีมนักโภชนาการ รพ.กรุงเทพพัทยา มาให้ความรู้แก่ผู้ร่วมกิจกรรม รวมถึงการทำอาหารเมนูสุขภาพด้วยตัวเองแบบง่าย ๆ โดยมีการให้ความรู้ในหัวข้อ ดังนี้ • วิธีดูแลสุขภาพคุณผู้ชาย คุณผู้หญิงให้กลับมาดูหนุ่มสาวขึ้นอีกครั้ง • ลองเช็คสัญญาณความเสื่อม คุณเข้าสู่วัยทองก่อนวัยหรือไม่? • เคล็ดลับกายฟิต หุ่นเฟริ์มเหมือนตอนหนุ่มสาว • DIY : Menu Lunch Box กินชะลอวัย ป้องกันโรคภัย ห่างไกลความอ้วน โดยในเดือนธันวาคมนี้ รพ.กรุงเทพพัทยา ได้มีการจัดแพ็กเกจตรวจสุขภาพ ในชื่อ แพ็กเกจสุขภาพดีรับปีใหม่ 2561 ราคาประหยัด ให้กับผู้ใส่ใจสุขภาพได้เลือกซื้อแพ้กเกจตรวจสุขภาพเป็นของขวัญมอบให้กับคนที่ท่านรัก โดยสามารถสอบถามรายละเอียดของแพ็กเกจตรวจสุขภาพได้ที่ รพ.กรุงเทพพัทยา หรือ โทร. 0 3333 3333\n","มีลิปเมลินดาเบอร์03ไหมค่ะ\n","Ba hao 八號 บาร์จีนดีๆ ในซอยนานา เบียร์นุ่ม อาหารอร่อย นี่สั่ง Jian Bing กับเกี๊ยวเป็ดไป น้ำซอสคือดีมาก เป็นซิกเนเจอร์ของร้านเลย บรรยากาศร้านก็ดี ให้อารมณ์หว่องเข้ากับบรรยากาศในคืนฝนตก จะกลับไปอีกแน่นอน\n","พยามบอกเขาว่า ไอน้ำนะ ไม่ใช่ควัน\n","ไม่ทันและ...กุมาฮาจิบังและ\n","พาลูกหนูไปกินด้วย\n","ของหวาน ก็ฮันนี่โทส ของคาวก็บาบีก้อน\n","ศรีจันทร์คือชอบเนื้อรองพื้นมาก แต่แบบนุแพ้ ฮรือ\n","งานช้างงงงครัช!!! วันเสาร์ที่ 24/2/2561 พบกันที่ แตงโมทะเลเผา อาหารสด ดนตรีเพราะ เบียร์เย็นๆ...\n","พาไปกินหน่อยเจ้าค่ะ\n","งานแสงโสม\n","ผลการตรวจสอบไปสัมภาษณ์กับสแตนด์บาบีก้อนหน้าร้านนะครับ\n","พี่เพิ่งรู้ว่าร้านกอล์ฟ เดี๋ยวไปอุดหนุนบ้าง\n","14 เมษายนของทุกปี คือ วันครอบครัว ค่ะ #สวยกล้าทุกแสง #คู่หูท้าแดด #kmacosmetics\n","พี่โชคคคคคคค น้องทานเอ็มเคอยู่ เด๋วมาเล่นด้วยนะ\n","แพ้ผ้าอนามัยอีกแล้วควายจัด\n","- สำหรับร้าน MK Gold buffet ที่เปิดขายทุกวัน มีสองสาขาคือ - สาขาศาลาแดง - สาขาEsplanade รัชดา - สำหรับร้าน MK Gold buffet ที่เปิดขายเฉพาะวันจันทร์ - ศุกร์ มีรายชื่อสาขา ดังต่อไปนี้ 1.สาขาเอกมัย 2.สาขาเซ็นทรัล เวิล์ดค่ะ ^^\n","เด็กเอ๋ยเด็กดี ต้องกิน ดีกรี ลีโอ เหล้าขาว 🍻🍃😜🙊 #แคปชั่นคอวอยอ #แคปชั่นเสี่ยว #แคปชั่นอ่อย #แคปชั่นเด็ด #แคปชั่นน่ารัก #คำคม #แคปชั่นกวนตีน\n","เมื่อ “ปรากฏการณ์จันทร์เต็มดวง” ถูก “ตีความใหม่” โดย 3 ศิลปิน Duangrit x Dudesweet x Trimode กลายเป็นประสบการณ์ ‘The North Full Moon ปาร์ตี้แสงเหนือ’ เสมือนอยู่บนดวงจันทร์ เตรียมชมความล้ำและมันส์ จากมนุษย์พวกแรกที่ได้ไปถึง 18 พ.ย. นี้ #SangSom #RedefineFullMoon #TheNorthFullmoonParty\n","ทุกวันนี้รีโว่รอกโค่. ทำไวเเทกหงายได้ยังครับ 😝\n","งอนบาบีก้อนถึง2020\n","ก้อนมีรายละเอียดกาต้มน้ำเพิ่มเติมตามรูปนะคร้าบบ^^\n","รำ😑\n","หลอนจัดเลยครับ 55555\n","10 พย : ยโสธร 11 พย : หนองคายBike Week 15 พย : งานช้างสุรินทร์ 17: พย : ตะวันแดงพัทยา 18: พย : ลานเบียร์สิงห์ กบินทร์บุรี\n","กินไก่ KFC กับ เบียร์ช้าง ????\n","เออแบบอะไรก็ฮอตพอท!555\n","ใช้รุ่นนี้ไหมที่เขาจะเอามาทำแท็กซี่แทน..อัลติส\n","วันนี้นะ ที่ลานโตโยต้า คุณวาสี ถนนชัยภูมิ-บ้านเขว้า\n","แบรนด์sivannaมีของปลอมมั้ยคะ\n","มีเงินหรอ\n","รีเจนซี่ ตื่นสบายจริงเหรอ 555\n","ชาวกรุงตื่นเต้น รถบ้านสุดฮิป U Motel ที่ถูกเนรมิตขึ้นมาจาก U Beer #SleepWithU #UMotel อย่าลืมติดดาวเพจ https://www.facebook.com/UBeerThai/ เพื่อไม่พลาดเรื่องราวและกิจกรรม\n","safe series 2018 จาก netflix เรื่องเกี่ยวกับลูกสาวหายตัวไป พ่อเธอจึงออกตามหา เล่าเรื่องได้สูตรสำเร็จของนิยายฮาลาน โคเบนมาก การสืบต่อไปเรื่อยจนพบความจริง ที่ชอบก็คือแม่งเก่งที่ทำให้ทุกตัวละครน่าสงสัยไปหมดได้ ถือว่าเป็น 8ep ที่ไม่น่าเบื่อเลยสนุกมาก #ชิตพลรีวิว\n","บุหรี่ไฟฟ้านะ ไม่ใช่ยาบ้า มึงก้บ้า เกินไป\n","แต่งหน้าง่ายๆแต่กันน้ำขั้นสุด https://www.youtube.com/watch?v=Ywm0RT8Kqjo #แป้งเจ้านาง #แป้งพัฟเจ้านาง #Chaonangthailand #Chaonangthailandofficial #แป้งพัฟ #แป้ง #แป้งพัพถูกและดี #แป้งผสมกันแดดที่ดีที่สุดในยุค #แป้งผสมรองพื้น #แป้งพัฟคุมมัน #ลิปเจ้านาง #ลิปแมทเจ้านาง #ลิปแมท สอบถาม-สั่งซื้อ-สมัครตัวแทน โทร. 088-888-8888 📲Line : @chaonangth 📩Inbox : m.me/chaonangthailandofficial\n","น้อยใจแฟนหนุ่มมารับช้า ด.ญ.14 โดดสะพานลอยหวังฆ่าตัว อาการสาหัส\n","18.21น. ภูเก็ต เขต1 พลังประชารัฐ2,397 ประชาธิปัตย์1,818คะแนน ผลสังเกตการณ์นับคะแนนหน้าหน่วยจากอาสาสมัครTNN(อย่างไม่เป็นทางการ ) คลิก>https://www.tnnthailand.com/\n","หลังจากลบsocial media appทุกอันออกจากมือถือและตั้งกฏกับตัวเองไม่ให้เข้ามาเช็คอะไรทั้งสิ้น (ยกเว้น HBD เพื่อน พิมพ์ก่อนและเข้าโพส เวลาทั้งหมดห้ามเกิน 1 นาที) และตั้ง habit ใหม่คือทำโจทย์เลข ผลคือหลัง 30 วัน cognitive functioningดีขึ้นมาก คิดอะไรเร็ว งานเสร็จ เครียดน้อยลง หลับสบาย\n","แล้วตอนนี้มึงก็แดกอะไรไม่ได้เลยอ้อ\n","4x4 ไหมครับ รุ่นนี้\n","พี่ก้อนน่ารักมาก ยิ้มตลอดทาง กำลังใจและคู่คิดของกันและกันแท้ๆ\n","จันทร์ Shock โลก The Return คืนนี้ ดีเจโอ๊ต ปราโมทย์ เปิดบ้านต้อนรับดีเจคุณพ่อลูกหนึ่ง เจ็ม ณัฏฐ์ปวินท์ มาระเบิดความฮากับคำถามสุดช๊อกและของรางวัลสุดกวน 3-5 ทุ่มที่ EFM104.5 และชมสดพร้อมๆกันผ่าน Facebook Live & Youtube Live ลงทะเบียนเล่นเกมส์ได้แล้วตอนนี้ที่เบอร์ 02-222-2222 . สนับสนุนความ Shockkkkk โดย Centerpoint of Siam Square https://www.facebook.com/centerpointofsiamsquare BarBQ Plaza http://www.11street.co.th/store/MiniMallAction/getMiniMallHome.do?sellerHmpgUrl=barbqplaza MG http://mgcars.com/th/mg-models/mgzs/detail/overview รู้ใจดอทคอม https://www.roojai.com/ Traveloka https://www.traveloka.com/th-th/?utm_source=THFlightHotel&utm_medium=radio&utm_campaign=EOY-011117 CP https://www.facebook.com/dimsum.jadedragon/ Enchanter https://www.facebook.com/EnchanteurThailand/ #จันทร์ShockโลกTheReturn\n","ใจเยนนนน กูชักอ้วนใหญ่แล้ว\n","Civic ทุกรุ่นใช้ระบบกันสะเทือนหน้าแบบคอยล์สปริง ด้านหลังทอร์ชั่นบาร์พร้อมคอยล์สปริง เครื่องยนต์ยังคงใช้รหัส D และเพิ่มรุ่นใหม่ 1,500 ซีซี CVCC โดยในปี 1984 ได้เพิ่มรุ่นแรงรหัส Si สำหรับทำตลาดญี่ปุ่น ปรับปรุงระบบกันสะเทือน และใช้เครื่องยนต์ DOHC ZC ความจุ 1,600 ซีซี กำลังสูงสุด 130 แรงม้า ส่วนรุ่นที่ทำตลาดในสหรัฐอเมริกาในชื่อ Civic Si 3 ประตู และ CRX Si ใช้เครื่องยนต์หัวฉีด 12 วาล์ว กำลังสูงสุด 91 แรงม้า เดือนพฤศจิกายน 1984 ฮอนด้าเพิ่มระบบขับเคลื่อน 4 ล้อให้ Civic เป็นครั้งแรกในรุ่น Shuttle ช่วงแรกมีปุ่มกดสำหรับเข้า-ออกจากระบบขับเคลื่อน 4 ล้อที่เรียกว่า \"Realtime\" เพราะสามารถทำได้ขณะรถวิ่ง จากนั้นในเดือนกุมภาพันธ์ 1985 จึงเพิ่มรุ่น Quint Integra ตัวถังแฮทช์แบ็ก 3 ประตู ฐานล้อ 2,450 มิลลิเมตร และในเดือนพฤศจิกายน 1986 เพิ่มรุ่น 5 ประตูแฮทช์แบค พร้อมขยายขนาดฐานล้อเป็น 2,520 มม.\n","ไม่อยากกินลีโอ อยากกินฝรั่ง\n","ขี้มอไซไปไง ที่โฮมโปรมีจะไปปะละ ใจๆ5555หิวด้วย\n","Nissan X-trail ขับนิ่ม เสียงเงียบ สบาย คล่องตัว\n","Nissan Note. ดาวน์เท่าไรค่ะ\n","น่าสนใจค่ะMGเป็นรถที่ออกแบบเพื่อความปลอดภัยรูปแบบทรงสวยทันสมัย\n","กลับไปจัดเลย\n","พี่ต้าไง\n","ก้อมันจริงนิ\n","แนะนำให้เริ่มต้นจากการล้างหน้าด้วย Hada Labo Deep Clean & Pore Refining Face Wash โฟมสูตรอ่อนโยนที่จะช่วยลดความมันส่วนเกินเพื่อรูขุมขนกระชับนะคะ\n","นะ\n","เผยรถต้นแบบ Small Rs Concept ที่คาดว่าจะเป็น All New Honda Brio รุ่น RS\n","หนูอยากกินมากนะค่ะ ที่รัก 😗😗😗\n","อะไรคือความรัก.... . เตรียมตัวให้พร้อม แล้วมาพบกับคืนนี้ Stamp (เเสตมป์ อภิวัชร์) .... . ในวันพฤหัสบดีที่ 28 ธันวาคมนี้ที่ DND Ekkamai . •Ticket : . Pre-sale ราคาเพียง 400 บาท เท่านั้น !! Front Door: 500 บาท . 🍺First 250 people who come first will get FREE BEER (a bottle of Singha light each) . ติดต่อซื้อบัตรได้ทาง Line: @untoldproject Call :088-888-8888 IG & FB: @untoldproject.bkk . #DNDDoNotDisturb #DNDBoutiquePlayhouse #ChivasExtra #Singhalight #untoldproject\n","ขอเสียของบุหรี่ไฟฟ้าคือ...รัฐบาลขาดทุนจบ!!!\n"]}],"source":["for i in range(100,200):\n","  print(asdsf.iloc[i]['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2r4sIe_UTID"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"mt5_mask_json.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"042230d6d0c842a4b9bd8302a799597e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49848535c2094cd4ac4c79ce765fb046","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66ffcfaad7614879bc63e5ca4beae83e","value":447792171}},"04256747b95a43b3baab0462780b130f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"058520ac5e8d4be09bc0b62405b94d0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08157f0343f94336ad5157e60b5ab2a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d7899b54ebc4002a1e93b9c89de1024":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eaa2e0e1e8342f6a7a3d301f574dbbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb3363e2c164990bdd1a3c586b206b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"145b2142cd644bbfb56e75ee681f322f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b304b8dc9a4aff959455b52544d3ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1780d968589b469385d19bce8f2912ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1923362afb0d40b991be93c9e7eb3445":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a696d82a3994743898e129e77f4f8e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20f9270c842f42488cacaaf9efa66aad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27029db2dc6d46a4a7bcd255f5cffe22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"278047df951041bd90fdd5e5d3871490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01bdae0448749c29a0dc6bc11e16e42","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a5ac383e4742268a87fd1a815c119b","value":2991}},"27d10cc518ec48698ca6a1e6cd4a88c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d8a0a1b4514aa6a1783ff34bc280c5","placeholder":"​","style":"IPY_MODEL_af5a054aade745b4ade6d6eddbb6258a","value":"Clean file pytorch_model.bin: 100%"}},"2842b63f9ac74643b26fba7a7baf174e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64e159c5af804bbfb1ee4eb59869d745","placeholder":"​","style":"IPY_MODEL_9a35f3b26d9147eda3e14f6eb6f39dcb","value":"Download file training_args.bin: 100%"}},"287e857523eb41e1b103f448e4e97cde":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a657e553ed84d6eb4b21d78bf724337":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b26d67ee49144ddaa7a968b21fcb271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_992cd38899fb4d72813f721af8f57bdb","IPY_MODEL_f82d72f405d44a1c815b376d4515a517","IPY_MODEL_9994d5a29d72462cae0f2326cf60d274"],"layout":"IPY_MODEL_1923362afb0d40b991be93c9e7eb3445"}},"2da3c5e1aaf44e73b98e3edc4bfdca7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ac06c7bdda4e56953613c3fedef2a1","placeholder":"​","style":"IPY_MODEL_0eb3363e2c164990bdd1a3c586b206b6","value":"Download file pytorch_model.bin: 100%"}},"2e07ce15f1fb4a26bbc78ca2f4b4e805":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3062e07104074ab28cd7d2ba9caf8981":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b184a8d3061a418a8c24b69e8adb5e51","placeholder":"​","style":"IPY_MODEL_a379143d7bae49d899ee0b3b22b477ec","value":"Clean file training_args.bin: 100%"}},"3609200b1e6a436b8e98b9d7c1aef298":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27029db2dc6d46a4a7bcd255f5cffe22","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e07ce15f1fb4a26bbc78ca2f4b4e805","value":2991}},"378ac02b3c0445dba5f0d360225b61a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a657e553ed84d6eb4b21d78bf724337","placeholder":"​","style":"IPY_MODEL_38a65dc5cc2147918b87ecdc9d94ca2c","value":" 427M/427M [03:07&lt;00:00, 186kB/s]"}},"38a65dc5cc2147918b87ecdc9d94ca2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e82d564ea2a48a0b8ea23387ac6c81a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44d8a0a1b4514aa6a1783ff34bc280c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483158b39ae64f45b9c7ebe2e3668944":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49848535c2094cd4ac4c79ce765fb046":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e0db67e76424135a7a5018168c8f098":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e535d77dae1444c8175eb0ecd308770":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2842b63f9ac74643b26fba7a7baf174e","IPY_MODEL_3609200b1e6a436b8e98b9d7c1aef298","IPY_MODEL_859645b4856b479e8454b205e8975ab8"],"layout":"IPY_MODEL_20f9270c842f42488cacaaf9efa66aad"}},"4ef5e4456549494e9af9590932a1468c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59479122c9c542139624a08e81d68d68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f3a4c697abb4707bf71ce007f983b63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fff9c8e4b0c4d6198aad11efb689820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_145b2142cd644bbfb56e75ee681f322f","placeholder":"​","style":"IPY_MODEL_f8f781ac63034f7ea1c66d7ad1b9b8cc","value":"Downloading: 100%"}},"62186b93324c455eb39970a26e120ac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27d10cc518ec48698ca6a1e6cd4a88c2","IPY_MODEL_e05dec65ddb54b96a740e6c072c31412","IPY_MODEL_77ad22152cd9457c8e85f3dceacd2836"],"layout":"IPY_MODEL_8cfba2e0f9834b76ae11c8ec37551711"}},"645f2aac90b04e95817a1eddf6e8afff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9981e2a9842041f9b590f5205794e73b","placeholder":"​","style":"IPY_MODEL_651237317ea84458b9623a92d026fe81","value":" 427M/427M [05:30&lt;00:00, 642kB/s]"}},"649dea9a14af42fb9e900a591d8b12a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a5ac383e4742268a87fd1a815c119b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64e159c5af804bbfb1ee4eb59869d745":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651237317ea84458b9623a92d026fe81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66ffcfaad7614879bc63e5ca4beae83e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68584c751d1c4595846237cfd83b9201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69b6cce9bf5a4f35afcc49f6cc9880bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bbf4f327411495984d5e3d27afb5fc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c2c40222afc4cfa8447e274be0c0a5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70ec88c2387441ac80a20b7d79094eca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_649dea9a14af42fb9e900a591d8b12a4","max":546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9f192112cfd48f3b6c42e149c94d5cc","value":546}},"77ad22152cd9457c8e85f3dceacd2836":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e82d564ea2a48a0b8ea23387ac6c81a","placeholder":"​","style":"IPY_MODEL_08157f0343f94336ad5157e60b5ab2a9","value":" 427M/427M [01:01&lt;00:00, 7.72MB/s]"}},"7c71361f762243609c5bb03f7067d78c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4cb88aa34de482883027be38aad4262","IPY_MODEL_ac06732669bd4b6c817e6ad629394c65","IPY_MODEL_cb7bee8ed9f74c86a6dccc3e147ab8d5"],"layout":"IPY_MODEL_7fb9f1006f864efe97fc6c364c832984"}},"7e257def77844680a7da34e13efdf2ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ef1c8bffcdd4b098c1dcae97f2d63ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8ecb32ff9c45889dc34aea594fb8c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3062e07104074ab28cd7d2ba9caf8981","IPY_MODEL_a87be5b4deae49199c4352d6d40b53de","IPY_MODEL_bf7c8af4510c4bdca84109e51b0ac42d"],"layout":"IPY_MODEL_f463ef9a65d54cce967f453474840096"}},"7fb9f1006f864efe97fc6c364c832984":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"859645b4856b479e8454b205e8975ab8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f3a4c697abb4707bf71ce007f983b63","placeholder":"​","style":"IPY_MODEL_ad626ea16d44478c9fff6cf9a5f9ef55","value":" 2.92k/2.92k [03:06&lt;?, ?B/s]"}},"8c54a043cdb1428fb786fb77a3fbb2b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b97cb4a64688484683f928ed02533661","placeholder":"​","style":"IPY_MODEL_a4628aef19674546b9d09a2cf3a38d30","value":"Downloading: 100%"}},"8cfba2e0f9834b76ae11c8ec37551711":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d812b10c2b04d3fa215e66a7cff2cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ef1c8bffcdd4b098c1dcae97f2d63ad","placeholder":"​","style":"IPY_MODEL_9f00dd09c3884b5ca16014ba7620f462","value":"Upload file training_args.bin: 100%"}},"8ed3ba25ad40403496364bcd87a89bce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"918e65e8746e4231b8a82a4b600eeebe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7bf0bcc78be4145a27ab0646ca104fc","placeholder":"​","style":"IPY_MODEL_8ed3ba25ad40403496364bcd87a89bce","value":" 546/546 [00:00&lt;00:00, 12.8kB/s]"}},"992cd38899fb4d72813f721af8f57bdb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5ac575d2444a2684332632f4729f7d","placeholder":"​","style":"IPY_MODEL_f349705a4ac64e49ae66eca3578da471","value":"Downloading: 100%"}},"9981e2a9842041f9b590f5205794e73b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9994d5a29d72462cae0f2326cf60d274":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ef5e4456549494e9af9590932a1468c","placeholder":"​","style":"IPY_MODEL_16b304b8dc9a4aff959455b52544d3ed","value":" 772/772 [00:00&lt;00:00, 25.8kB/s]"}},"9a35f3b26d9147eda3e14f6eb6f39dcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b5ac575d2444a2684332632f4729f7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f00dd09c3884b5ca16014ba7620f462":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a379143d7bae49d899ee0b3b22b477ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4628aef19674546b9d09a2cf3a38d30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6e90eb74f6a448dab18e5b9593f6123":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a819e447802f40009cd655bd97d4adb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a81d4bc96f8449208265c0d8b50ce959":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da1f26a0c43e49beb2deb9327aa5a07d","IPY_MODEL_042230d6d0c842a4b9bd8302a799597e","IPY_MODEL_645f2aac90b04e95817a1eddf6e8afff"],"layout":"IPY_MODEL_db2b75a4c4054eae852505b76ac0f69b"}},"a87be5b4deae49199c4352d6d40b53de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b8fb1a4f2a41f194b68518be7b1755","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba82d007461248adab326acf16fba6cb","value":2991}},"a8b8fb1a4f2a41f194b68518be7b1755":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac06732669bd4b6c817e6ad629394c65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a819e447802f40009cd655bd97d4adb5","max":423498558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59479122c9c542139624a08e81d68d68","value":423498558}},"ad626ea16d44478c9fff6cf9a5f9ef55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae41fd9a61fd4737a20bd1bc012313f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2da3c5e1aaf44e73b98e3edc4bfdca7c","IPY_MODEL_b952623bc4694706b802695b82a6d171","IPY_MODEL_378ac02b3c0445dba5f0d360225b61a5"],"layout":"IPY_MODEL_69b6cce9bf5a4f35afcc49f6cc9880bf"}},"af5a054aade745b4ade6d6eddbb6258a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0ac06c7bdda4e56953613c3fedef2a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ffc3d3d9754712b4e87487d06e397a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b184a8d3061a418a8c24b69e8adb5e51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6e9d7b4904346e9bc4a645fe7ecab27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a696d82a3994743898e129e77f4f8e2","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d7899b54ebc4002a1e93b9c89de1024","value":447792171}},"b952623bc4694706b802695b82a6d171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e257def77844680a7da34e13efdf2ea","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e0db67e76424135a7a5018168c8f098","value":447792171}},"b97cb4a64688484683f928ed02533661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba82d007461248adab326acf16fba6cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb7971f12d2040c09b4a8df47ac80954":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5439d9bf8242089a6378ef45d85b0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf7c8af4510c4bdca84109e51b0ac42d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb7971f12d2040c09b4a8df47ac80954","placeholder":"​","style":"IPY_MODEL_68584c751d1c4595846237cfd83b9201","value":" 2.92k/2.92k [03:06&lt;00:00, 10.5B/s]"}},"c1571e270ccc4f3b9b5b026bb642aa18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9021b39802e4207b876b3948f95876a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c54a043cdb1428fb786fb77a3fbb2b2","IPY_MODEL_b6e9d7b4904346e9bc4a645fe7ecab27","IPY_MODEL_e6c6aa874cf543cc9dbc89e8f7427711"],"layout":"IPY_MODEL_483158b39ae64f45b9c7ebe2e3668944"}},"cb7bee8ed9f74c86a6dccc3e147ab8d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4f3948d040e4e319b287b5fefd81a86","placeholder":"​","style":"IPY_MODEL_a6e90eb74f6a448dab18e5b9593f6123","value":" 404M/404M [00:10&lt;00:00, 44.2MB/s]"}},"cea9a81e93d84955b85fe2a5a40675da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d812b10c2b04d3fa215e66a7cff2cea","IPY_MODEL_278047df951041bd90fdd5e5d3871490","IPY_MODEL_dd7f3b4d7e2a4efd9ac073ec34ded50b"],"layout":"IPY_MODEL_b0ffc3d3d9754712b4e87487d06e397a"}},"d01bdae0448749c29a0dc6bc11e16e42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b3fa08164c49d19e31aa4a355d7f4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4cb88aa34de482883027be38aad4262":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1571e270ccc4f3b9b5b026bb642aa18","placeholder":"​","style":"IPY_MODEL_04256747b95a43b3baab0462780b130f","value":"Downloading: 100%"}},"d9f192112cfd48f3b6c42e149c94d5cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da1f26a0c43e49beb2deb9327aa5a07d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4545e74f564cc294bf4e400ff737f1","placeholder":"​","style":"IPY_MODEL_058520ac5e8d4be09bc0b62405b94d0a","value":"Upload file pytorch_model.bin: 100%"}},"db2b75a4c4054eae852505b76ac0f69b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7f3b4d7e2a4efd9ac073ec34ded50b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_287e857523eb41e1b103f448e4e97cde","placeholder":"​","style":"IPY_MODEL_d3b3fa08164c49d19e31aa4a355d7f4c","value":" 2.92k/2.92k [05:30&lt;?, ?B/s]"}},"e05dec65ddb54b96a740e6c072c31412":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1780d968589b469385d19bce8f2912ea","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bbf4f327411495984d5e3d27afb5fc9","value":447792171}},"e30c266bf2b543f4a89859b02a59a2ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6c6aa874cf543cc9dbc89e8f7427711":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e30c266bf2b543f4a89859b02a59a2ec","placeholder":"​","style":"IPY_MODEL_bd5439d9bf8242089a6378ef45d85b0d","value":" 427M/427M [00:28&lt;00:00, 18.0MB/s]"}},"eb4545e74f564cc294bf4e400ff737f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f349705a4ac64e49ae66eca3578da471":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3eafeae8b844036a7b5f0c1a6ebe4e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fff9c8e4b0c4d6198aad11efb689820","IPY_MODEL_70ec88c2387441ac80a20b7d79094eca","IPY_MODEL_918e65e8746e4231b8a82a4b600eeebe"],"layout":"IPY_MODEL_0eaa2e0e1e8342f6a7a3d301f574dbbe"}},"f463ef9a65d54cce967f453474840096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4f3948d040e4e319b287b5fefd81a86":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7bf0bcc78be4145a27ab0646ca104fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82d72f405d44a1c815b376d4515a517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1e6fe15a504b338a933e5ba34edfd2","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c2c40222afc4cfa8447e274be0c0a5b","value":772}},"f8f781ac63034f7ea1c66d7ad1b9b8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1e6fe15a504b338a933e5ba34edfd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf51182bc3ad4c03b1c52ab234f85e59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78df3dd784b143bea77535deb28cc034","IPY_MODEL_3bdb2834c2ad41ed9dc2b7dc9631cf6c","IPY_MODEL_b42fa28fd19f41b3a859933e2a70c716"],"layout":"IPY_MODEL_0b7edb027c104fe185f951caa7f02e9b"}},"78df3dd784b143bea77535deb28cc034":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9e4cb8d48ea418087530dd2ee7a9f38","placeholder":"​","style":"IPY_MODEL_1bf91e480eb0490582a5032d01be3495","value":"Sanity Checking DataLoader 0: 100%"}},"3bdb2834c2ad41ed9dc2b7dc9631cf6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a84d19651d7a4ce88ff3bb9278d5c2ff","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fabe8b67daf44bd8279ab8e33162e3f","value":2}},"b42fa28fd19f41b3a859933e2a70c716":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4776f04dba244d3aab2a88c71aa43c5c","placeholder":"​","style":"IPY_MODEL_c85239627fb44b6babc4f60f0ed690eb","value":" 2/2 [00:00&lt;00:00, 15.05it/s]"}},"0b7edb027c104fe185f951caa7f02e9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a9e4cb8d48ea418087530dd2ee7a9f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bf91e480eb0490582a5032d01be3495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a84d19651d7a4ce88ff3bb9278d5c2ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fabe8b67daf44bd8279ab8e33162e3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4776f04dba244d3aab2a88c71aa43c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c85239627fb44b6babc4f60f0ed690eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bcca061b92e43499269c0a147ee65ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4af9fa6be7e4e71ad6d8a94f5897c5e","IPY_MODEL_a5b6a79e04e24847a3ee13a1e51f7b2f","IPY_MODEL_d25246d4e1a74a8389ce579b68e12a88"],"layout":"IPY_MODEL_a49bc0ac285243c49058f5e0d0f46a7d"}},"f4af9fa6be7e4e71ad6d8a94f5897c5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_989a343a06964241afee3c6da8c470b9","placeholder":"​","style":"IPY_MODEL_4939e59c1e2b42f6a6790b458f660017","value":"Epoch 4: 100%"}},"a5b6a79e04e24847a3ee13a1e51f7b2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dd88cc8f9124116b1878f8fb9772ca3","max":20649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dae7c9d4a00b4cdca8414eb0b3c0ea82","value":20649}},"d25246d4e1a74a8389ce579b68e12a88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d39640ca24a540f795f1003873fb7d1a","placeholder":"​","style":"IPY_MODEL_1ea88470f7f94da38eb6c168101a9175","value":" 20649/20649 [1:24:30&lt;00:00,  4.07it/s, loss=0.221, v_num=0, loss_step=0.177, val_loss_step=0.00374, val_loss_epoch=0.270, loss_epoch=0.180]"}},"a49bc0ac285243c49058f5e0d0f46a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"989a343a06964241afee3c6da8c470b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4939e59c1e2b42f6a6790b458f660017":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dd88cc8f9124116b1878f8fb9772ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dae7c9d4a00b4cdca8414eb0b3c0ea82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d39640ca24a540f795f1003873fb7d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea88470f7f94da38eb6c168101a9175":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95cddeb5dd7f4a6481e6647b094dca5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2316561a89c84e0e918c74c805e5344e","IPY_MODEL_8f25e79f07814fb2a1cac366957da0e3","IPY_MODEL_8a90e0c6cc884a93a29ab6d83b058e00"],"layout":"IPY_MODEL_1d506fb1906f47208a07afc88156fdef"}},"2316561a89c84e0e918c74c805e5344e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a7cbade081a452eac685027d8064007","placeholder":"​","style":"IPY_MODEL_8a59aae46aec4d6d923ff76cb385d3e3","value":"Validation DataLoader 0: 100%"}},"8f25e79f07814fb2a1cac366957da0e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d418c5f153f484581e1ff1c8fcf583d","max":2107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b62f68492a5646e2a7c24f86a68b3991","value":2107}},"8a90e0c6cc884a93a29ab6d83b058e00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c128f9e5f6084e299d558b8679858aaf","placeholder":"​","style":"IPY_MODEL_f87cf9818d0e496e9a36994cddc4101c","value":" 2107/2107 [02:58&lt;00:00, 11.78it/s]"}},"1d506fb1906f47208a07afc88156fdef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8a7cbade081a452eac685027d8064007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a59aae46aec4d6d923ff76cb385d3e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d418c5f153f484581e1ff1c8fcf583d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b62f68492a5646e2a7c24f86a68b3991":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c128f9e5f6084e299d558b8679858aaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87cf9818d0e496e9a36994cddc4101c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36c7642c2ccb4461929752b2e10eabfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49ba37b1d50d48c28d23a27e0ef45f56","IPY_MODEL_122b13aaea1f40e9b31e33ecdc0f857c","IPY_MODEL_8138181f03bd4380a04271052ef9dd97"],"layout":"IPY_MODEL_c1447045c539477690ee9a0bf83d3dc7"}},"49ba37b1d50d48c28d23a27e0ef45f56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5df5858c9e364f918cd830fe3f932587","placeholder":"​","style":"IPY_MODEL_afc0e594662e48f8a07a5be85413ab09","value":"Validation DataLoader 0: 100%"}},"122b13aaea1f40e9b31e33ecdc0f857c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0bcd581d44c40a193adf04799c55a53","max":2107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6ffe68f3e644ad28365ed6b50552be0","value":2107}},"8138181f03bd4380a04271052ef9dd97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04c4fcac020b439fa1ddc11077fb413c","placeholder":"​","style":"IPY_MODEL_1dc30c34f33448268d4c6743e8b96b0c","value":" 2107/2107 [02:57&lt;00:00, 11.84it/s]"}},"c1447045c539477690ee9a0bf83d3dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5df5858c9e364f918cd830fe3f932587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afc0e594662e48f8a07a5be85413ab09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0bcd581d44c40a193adf04799c55a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ffe68f3e644ad28365ed6b50552be0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04c4fcac020b439fa1ddc11077fb413c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dc30c34f33448268d4c6743e8b96b0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b2c5f18b9e5410ebeddd5b23d652977":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b984f86d5b2a452e8c079139bce4959e","IPY_MODEL_31b42b21888c4c6a9fc5f5450cff9918","IPY_MODEL_237fa8635b37452e885a31a70b65b154"],"layout":"IPY_MODEL_1a392d64311e4a37840a8351d9ed02ee"}},"b984f86d5b2a452e8c079139bce4959e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2945e5549c2346e7ba3305340515e3e6","placeholder":"​","style":"IPY_MODEL_000251af72a24889849b7c38495818a4","value":"Validation DataLoader 0: 100%"}},"31b42b21888c4c6a9fc5f5450cff9918":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f6d0bcc78b448d1bb17e430af899559","max":2107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_696bc531858241d7bf7881c4ae224814","value":2107}},"237fa8635b37452e885a31a70b65b154":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41aaab93d5b14ad7b629f3e4ecdb0a7c","placeholder":"​","style":"IPY_MODEL_851d4d8a473a473b9dfa842292f92aa4","value":" 2107/2107 [02:57&lt;00:00, 11.85it/s]"}},"1a392d64311e4a37840a8351d9ed02ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"2945e5549c2346e7ba3305340515e3e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"000251af72a24889849b7c38495818a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f6d0bcc78b448d1bb17e430af899559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"696bc531858241d7bf7881c4ae224814":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41aaab93d5b14ad7b629f3e4ecdb0a7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851d4d8a473a473b9dfa842292f92aa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee82265d0340433ea9578bbfe9ca77d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45e8d8fcd7a34914ba379c56d42b0180","IPY_MODEL_bf953bcf70a549519548a9628d3ac2a9","IPY_MODEL_eceaa6656a7c460697076f7ed6a236fb"],"layout":"IPY_MODEL_175fe809d124455b8475068f1e3a66df"}},"45e8d8fcd7a34914ba379c56d42b0180":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cb5ea7951e4d61a1284ce71f8b3180","placeholder":"​","style":"IPY_MODEL_e02a4437bd934b549f01e75e779c281d","value":"Validation DataLoader 0: 100%"}},"bf953bcf70a549519548a9628d3ac2a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a310eb8ddf541aba01e1c3dfb72af39","max":2107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20e321cbfd154892af939496b40a7f5c","value":2107}},"eceaa6656a7c460697076f7ed6a236fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_583ea84db2814cb09bb8068cc137c72f","placeholder":"​","style":"IPY_MODEL_6a2c76e884334cfea916df80363cff3c","value":" 2107/2107 [02:56&lt;00:00, 11.97it/s]"}},"175fe809d124455b8475068f1e3a66df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"25cb5ea7951e4d61a1284ce71f8b3180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e02a4437bd934b549f01e75e779c281d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a310eb8ddf541aba01e1c3dfb72af39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20e321cbfd154892af939496b40a7f5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"583ea84db2814cb09bb8068cc137c72f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a2c76e884334cfea916df80363cff3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"390fafda3087437b952754536b86179d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52f22eba742e445eabb848ef2d4fa6e5","IPY_MODEL_f64729c47ff94ea1be6e5efbae63003b","IPY_MODEL_971ed63be7d24fe5873facc3be2e5324"],"layout":"IPY_MODEL_5444a87a18c8419fba1fe3cefd542b20"}},"52f22eba742e445eabb848ef2d4fa6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8403d9b077714775b5531d22222c4f69","placeholder":"​","style":"IPY_MODEL_ff8cbf65905847f3a8721b593f71f0c2","value":"Validation DataLoader 0: 100%"}},"f64729c47ff94ea1be6e5efbae63003b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7e39dc6498f4f6ca892da9d2a342c01","max":2107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_069b520e8ad844f6b095a0e73a9c6c12","value":2107}},"971ed63be7d24fe5873facc3be2e5324":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d70c7e3888c4c63b5a4262d1ae09f58","placeholder":"​","style":"IPY_MODEL_5054771977774af4bf201e9f46673c50","value":" 2107/2107 [02:55&lt;00:00, 11.99it/s]"}},"5444a87a18c8419fba1fe3cefd542b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8403d9b077714775b5531d22222c4f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff8cbf65905847f3a8721b593f71f0c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7e39dc6498f4f6ca892da9d2a342c01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"069b520e8ad844f6b095a0e73a9c6c12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d70c7e3888c4c63b5a4262d1ae09f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5054771977774af4bf201e9f46673c50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}