{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22944,"status":"ok","timestamp":1657091183061,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"PpEJQHrF5Byi","outputId":"93a34d34-0f03-479d-f3dc-730c2520a4c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.2 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 24.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 10.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.11.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 48.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 33.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7668092922e84dfcf8eb2332c972dc736fdade5b2f5df98b1a9ba0ef15497810\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.15.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets==1.17.0\n","  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.11.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.3.5)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 53.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.64.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (6.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.70.13)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.3.5.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 58.4 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (3.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.17.0) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (3.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (21.4.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 61.0 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 63.0 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.17.0) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.17.0) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install transformers==4.15.0 sentencepiece\n","!pip install datasets==1.17.0 "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15911,"status":"ok","timestamp":1657101648617,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"zHFzMIqvsJxU","outputId":"908c8181-445f-42a2-f368-47d9accaaa07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eGkmLjsmINUK","executionInfo":{"status":"ok","timestamp":1657091213308,"user_tz":-420,"elapsed":9217,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["from transformers import AutoModelForMaskedLM, pipeline\n","from transformers import AutoTokenizer, BertForTokenClassification\n","import pandas as pd\n","from datasets import load_dataset, load_metric, Dataset, DatasetDict\n","import torch\n","import pickle\n","import numpy as np"]},{"cell_type":"code","source":["# tokenizer = AutoTokenizer.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', model_max_length=512)\n","tokenizer = pickle.load(open('drive/MyDrive/AIBuilders/json/tokenizer_json_15k.pkl', 'rb'))"],"metadata":{"id":"MMoBbaxHwGPI","executionInfo":{"status":"ok","timestamp":1657091244021,"user_tz":-420,"elapsed":1650,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["amodel = AutoModelForMaskedLM.from_pretrained(\"bookpanda/wangchanberta-base-att-spm-uncased-masking\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867,"referenced_widgets":["2b26d67ee49144ddaa7a968b21fcb271","992cd38899fb4d72813f721af8f57bdb","f82d72f405d44a1c815b376d4515a517","9994d5a29d72462cae0f2326cf60d274","1923362afb0d40b991be93c9e7eb3445","9b5ac575d2444a2684332632f4729f7d","f349705a4ac64e49ae66eca3578da471","fc1e6fe15a504b338a933e5ba34edfd2","6c2c40222afc4cfa8447e274be0c0a5b","4ef5e4456549494e9af9590932a1468c","16b304b8dc9a4aff959455b52544d3ed","c9021b39802e4207b876b3948f95876a","8c54a043cdb1428fb786fb77a3fbb2b2","b6e9d7b4904346e9bc4a645fe7ecab27","e6c6aa874cf543cc9dbc89e8f7427711","483158b39ae64f45b9c7ebe2e3668944","b97cb4a64688484683f928ed02533661","a4628aef19674546b9d09a2cf3a38d30","1a696d82a3994743898e129e77f4f8e2","0d7899b54ebc4002a1e93b9c89de1024","e30c266bf2b543f4a89859b02a59a2ec","bd5439d9bf8242089a6378ef45d85b0d"]},"id":"BIamB4jjpPDd","executionInfo":{"status":"ok","timestamp":1655636863194,"user_tz":-420,"elapsed":33798,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"99765bbc-4164-4ce9-9bb5-bd2623080f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpeyypael4\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b26d67ee49144ddaa7a968b21fcb271"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","creating metadata file for /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","loading configuration file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","Model config CamembertConfig {\n","  \"_name_or_path\": \"bookpanda/wangchanberta-base-att-spm-uncased-masking\",\n","  \"architectures\": [\n","    \"CamembertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_head\": 12,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 33660\n","}\n","\n","https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe_9clcso\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9021b39802e4207b876b3948f95876a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","creating metadata file for /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","loading weights file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","All model checkpoint weights were used when initializing CamembertForMaskedLM.\n","\n","All the weights of CamembertForMaskedLM were initialized from the model checkpoint at bookpanda/wangchanberta-base-att-spm-uncased-masking.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForMaskedLM for predictions without further training.\n"]}]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","model_checkpoint = \"airesearch/wangchanberta-base-att-spm-uncased\"\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","FILE = \"drive/MyDrive/AIBuilders/json/mlm_json_3.pth\"\n","model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","model = model.to(device)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f3eafeae8b844036a7b5f0c1a6ebe4e5","5fff9c8e4b0c4d6198aad11efb689820","70ec88c2387441ac80a20b7d79094eca","918e65e8746e4231b8a82a4b600eeebe","0eaa2e0e1e8342f6a7a3d301f574dbbe","145b2142cd644bbfb56e75ee681f322f","f8f781ac63034f7ea1c66d7ad1b9b8cc","649dea9a14af42fb9e900a591d8b12a4","d9f192112cfd48f3b6c42e149c94d5cc","f7bf0bcc78be4145a27ab0646ca104fc","8ed3ba25ad40403496364bcd87a89bce","7c71361f762243609c5bb03f7067d78c","d4cb88aa34de482883027be38aad4262","ac06732669bd4b6c817e6ad629394c65","cb7bee8ed9f74c86a6dccc3e147ab8d5","7fb9f1006f864efe97fc6c364c832984","c1571e270ccc4f3b9b5b026bb642aa18","04256747b95a43b3baab0462780b130f","a819e447802f40009cd655bd97d4adb5","59479122c9c542139624a08e81d68d68","f4f3948d040e4e319b287b5fefd81a86","a6e90eb74f6a448dab18e5b9593f6123"]},"id":"g0gJa-IuwIrS","executionInfo":{"status":"ok","timestamp":1657091308355,"user_tz":-420,"elapsed":33252,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"d8e84a3b-5f3e-4ac5-8ff0-d46fd5224619"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3eafeae8b844036a7b5f0c1a6ebe4e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/404M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c71361f762243609c5bb03f7067d78c"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CamembertForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(25354, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=25354, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657091308355,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"HuRt6oooIT25","outputId":"6c3af342-4c6a-4836-e238-6957d93ba644"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CamembertForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(25354, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=25354, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"mmzS6fR27EPj"},"source":["# Data Prep"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_z4fISZnPbgK","executionInfo":{"status":"ok","timestamp":1657091309373,"user_tz":-420,"elapsed":1021,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["df = pickle.load(open('drive/MyDrive/AIBuilders/json/mlm_json_15k.pkl', 'rb'))"]},{"cell_type":"code","source":["df_test = df[10576:]\n","df = df[:10576]\n","df_train, df_val = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.9 * len(df))])"],"metadata":{"id":"spCaJAzyeKTN","executionInfo":{"status":"ok","timestamp":1657091313011,"user_tz":-420,"elapsed":490,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1657091325701,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"OvG-tIqcP5DS","outputId":"a326a3c4-cd52-4c07-ab72-2f794f902d6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               input_ids  \\\n","1284   [5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, ...   \n","6997   [5, 10, 1167, 1045, 878, 25004, 25004, 25004, ...   \n","9188   [5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...   \n","5076   [5, 10, 1834, 13725, 2102, 25004, 25004, 199, ...   \n","1393   [5, 330, 13621, 25004, 25004, 25004, 6, 1, 1, ...   \n","...                                                  ...   \n","4757   [5, 627, 1280, 25004, 25004, 25004, 25004, 250...   \n","10098  [5, 729, 25004, 1481, 1116, 6, 1, 1, 1, 1, 1, ...   \n","6320   [5, 7894, 1063, 145, 1849, 300, 25004, 6, 1, 1...   \n","5975   [5, 2169, 25004, 864, 286, 94, 25004, 25004, 2...   \n","3572   [5, 10, 26, 112, 7620, 25004, 25004, 6, 1, 1, ...   \n","\n","                                          attention_mask  \\\n","1284   [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","6997   [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n","9188   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","5076   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n","1393   [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","...                                                  ...   \n","4757   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","10098  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","6320   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","5975   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","3572   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","                                                  labels  \n","1284   [5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1,...  \n","6997   [5, 10, 1167, 1045, 878, 627, 70, 265, 6, 1, 1...  \n","9188   [5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...  \n","5076   [5, 10, 1834, 13725, 2102, 234, 265, 199, 1454...  \n","1393   [5, 330, 13621, 25105, 265, 265, 6, 1, 1, 1, 1...  \n","...                                                  ...  \n","4757   [5, 627, 1280, 231, 265, 265, 726, 265, 126, 1...  \n","10098  [5, 729, 8704, 1481, 1116, 6, 1, 1, 1, 1, 1, 1...  \n","6320   [5, 7894, 1063, 145, 1849, 300, 73, 6, 1, 1, 1...  \n","5975   [5, 2169, 15, 864, 286, 94, 415, 260, 23, 695,...  \n","3572   [5, 10, 26, 112, 7620, 894, 73, 6, 1, 1, 1, 1,...  \n","\n","[9518 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-794b09d8-367b-441c-90e3-14d3b882aeb5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1284</th>\n","      <td>[5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1,...</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>[5, 10, 1167, 1045, 878, 25004, 25004, 25004, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 1167, 1045, 878, 627, 70, 265, 6, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>9188</th>\n","      <td>[5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 1145, 1044, 78, 70, 471, 22167, 19404,...</td>\n","    </tr>\n","    <tr>\n","      <th>5076</th>\n","      <td>[5, 10, 1834, 13725, 2102, 25004, 25004, 199, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n","      <td>[5, 10, 1834, 13725, 2102, 234, 265, 199, 1454...</td>\n","    </tr>\n","    <tr>\n","      <th>1393</th>\n","      <td>[5, 330, 13621, 25004, 25004, 25004, 6, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 330, 13621, 25105, 265, 265, 6, 1, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4757</th>\n","      <td>[5, 627, 1280, 25004, 25004, 25004, 25004, 250...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 627, 1280, 231, 265, 265, 726, 265, 126, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>10098</th>\n","      <td>[5, 729, 25004, 1481, 1116, 6, 1, 1, 1, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 729, 8704, 1481, 1116, 6, 1, 1, 1, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>6320</th>\n","      <td>[5, 7894, 1063, 145, 1849, 300, 25004, 6, 1, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 7894, 1063, 145, 1849, 300, 73, 6, 1, 1, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>5975</th>\n","      <td>[5, 2169, 25004, 864, 286, 94, 25004, 25004, 2...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 2169, 15, 864, 286, 94, 415, 260, 23, 695,...</td>\n","    </tr>\n","    <tr>\n","      <th>3572</th>\n","      <td>[5, 10, 26, 112, 7620, 25004, 25004, 6, 1, 1, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[5, 10, 26, 112, 7620, 894, 73, 6, 1, 1, 1, 1,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9518 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-794b09d8-367b-441c-90e3-14d3b882aeb5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-794b09d8-367b-441c-90e3-14d3b882aeb5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-794b09d8-367b-441c-90e3-14d3b882aeb5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["df_train"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409,"status":"ok","timestamp":1657091330222,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"GH_XtzsDziSz","outputId":"f8dc44ad-016f-48d9-d818-fa3213552e1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 5248, 51, 25004, 25004, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[5, 5248, 51, 25101, 265, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["print(df_train.iloc[0]['input_ids'])\n","print(df_train.iloc[0]['attention_mask'])\n","print(df_train.iloc[0]['labels'])"]},{"cell_type":"code","source":["df_train = Dataset.from_pandas(df_train)\n","df_val = Dataset.from_pandas(df_val)\n","df_test = Dataset.from_pandas(df_test)"],"metadata":{"id":"KnBSmeMlezkG","executionInfo":{"status":"ok","timestamp":1657091334609,"user_tz":-420,"elapsed":1565,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqQ3JMlbfA-b","executionInfo":{"status":"ok","timestamp":1657091336177,"user_tz":-420,"elapsed":3,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"c31a1171-f554-4fe7-ce11-b5fa018f331d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","    num_rows: 9518\n","})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rsq-Zs_Lq4tI","executionInfo":{"status":"ok","timestamp":1657091340141,"user_tz":-420,"elapsed":335,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["combined_dataset = DatasetDict({\n","    'train': df_train,\n","    'test': df_val,\n","    'valid': df_test})"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657091341383,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ExAkoSqJtYz5","outputId":"0b9ba6e7-a4c3-4929-98cf-b7c489325375"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 9518\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 1058\n","    })\n","    valid: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 5000\n","    })\n","})"]},"metadata":{},"execution_count":16}],"source":["combined_dataset"]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","import gc\n","del df\n","del df_train\n","del df_val\n","del df_test\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_uiCeTpfXXU","executionInfo":{"status":"ok","timestamp":1657091343806,"user_tz":-420,"elapsed":2,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"ad10952e-a9fe-42dc-c3f3-0fe79433a913"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["461"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300,"referenced_widgets":["999a1423a011427d92b4bae8d77a1d8d","ae575dea2bbc4f37b886319c19f80add","97f66fe062a04133baf0c6980ff64b6f","3bee5df8c45e4c819fe87a12361cd1a3","c5474edb64d848f998659f5fece65fc6","af2e08b8087c4cb59eb32352ec7ad400","6dab459d3ac74d0891a58ab22fe75d9d","937000d241914846b467756686e3bdba","91e1ffe326cd478b8b6629d937d1713f","608b52cafe6c4b1cac020acf9cb6cb07","2336df9c24f448ea819c8789bc253a78","4293d1299fb14923b02e3cb09e33f220","34ebcc136e5f45c18322d14df3e4cec2","a04eefbe607e4a2eaa259a3b054e4962"]},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657091345325,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"bTtMT49atGOM","outputId":"88743486-126a-491e-bda1-6c385ad4007e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login() # เอาไว้โยนโมเดลขึ้น hugging face ได้เลย"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"dy-jAg11qvgl","executionInfo":{"status":"ok","timestamp":1657091358253,"user_tz":-420,"elapsed":341,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","batch_size = 16\n","# Show the training loss with every epoch\n","logging_steps = len(combined_dataset[\"train\"]) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-masking\",\n","    overwrite_output_dir=True,\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    push_to_hub=True,\n","    num_train_epochs = 3,\n","    fp16=True, # สำหรับคนใช้ GPU\n","    logging_steps=logging_steps,\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["ae41fd9a61fd4737a20bd1bc012313f5","2da3c5e1aaf44e73b98e3edc4bfdca7c","b952623bc4694706b802695b82a6d171","378ac02b3c0445dba5f0d360225b61a5","69b6cce9bf5a4f35afcc49f6cc9880bf","b0ac06c7bdda4e56953613c3fedef2a1","0eb3363e2c164990bdd1a3c586b206b6","7e257def77844680a7da34e13efdf2ea","4e0db67e76424135a7a5018168c8f098","2a657e553ed84d6eb4b21d78bf724337","38a65dc5cc2147918b87ecdc9d94ca2c","4e535d77dae1444c8175eb0ecd308770","2842b63f9ac74643b26fba7a7baf174e","3609200b1e6a436b8e98b9d7c1aef298","859645b4856b479e8454b205e8975ab8","20f9270c842f42488cacaaf9efa66aad","64e159c5af804bbfb1ee4eb59869d745","9a35f3b26d9147eda3e14f6eb6f39dcb","27029db2dc6d46a4a7bcd255f5cffe22","2e07ce15f1fb4a26bbc78ca2f4b4e805","5f3a4c697abb4707bf71ce007f983b63","ad626ea16d44478c9fff6cf9a5f9ef55","7f8ecb32ff9c45889dc34aea594fb8c4","3062e07104074ab28cd7d2ba9caf8981","a87be5b4deae49199c4352d6d40b53de","bf7c8af4510c4bdca84109e51b0ac42d","f463ef9a65d54cce967f453474840096","b184a8d3061a418a8c24b69e8adb5e51","a379143d7bae49d899ee0b3b22b477ec","a8b8fb1a4f2a41f194b68518be7b1755","ba82d007461248adab326acf16fba6cb","bb7971f12d2040c09b4a8df47ac80954","68584c751d1c4595846237cfd83b9201","62186b93324c455eb39970a26e120ac0","27d10cc518ec48698ca6a1e6cd4a88c2","e05dec65ddb54b96a740e6c072c31412","77ad22152cd9457c8e85f3dceacd2836","8cfba2e0f9834b76ae11c8ec37551711","44d8a0a1b4514aa6a1783ff34bc280c5","af5a054aade745b4ade6d6eddbb6258a","1780d968589b469385d19bce8f2912ea","6bbf4f327411495984d5e3d27afb5fc9","3e82d564ea2a48a0b8ea23387ac6c81a","08157f0343f94336ad5157e60b5ab2a9"]},"id":"-tCZDaN8s05p","executionInfo":{"status":"ok","timestamp":1657091552950,"user_tz":-420,"elapsed":192752,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"dbb48631-066a-4cd3-8e86-094e3a6fec5c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking into local empty directory.\n"]},{"output_type":"display_data","data":{"text/plain":["Download file pytorch_model.bin:   0%|          | 83.0/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae41fd9a61fd4737a20bd1bc012313f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Download file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e535d77dae1444c8175eb0ecd308770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Clean file training_args.bin:  34%|###4      | 1.00k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8ecb32ff9c45889dc34aea594fb8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Clean file pytorch_model.bin:   0%|          | 1.00k/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62186b93324c455eb39970a26e120ac0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using amp half precision backend\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=combined_dataset[\"train\"],\n","    eval_dataset=combined_dataset[\"valid\"],\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":771},"executionInfo":{"elapsed":2196813,"status":"ok","timestamp":1657096184063,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"QvLik2xbwl5C","outputId":"8649597c-e916-48b1-88ea-bff1fdd44223"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `CamembertForMaskedLM.forward` and have been ignored: __index_level_0__.\n","***** Running training *****\n","  Num examples = 9518\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1785\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1785' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1785/1785 36:35, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.019100</td>\n","      <td>0.020692</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.019100</td>\n","      <td>0.020692</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.019000</td>\n","      <td>0.020692</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1785, training_loss=0.01904480025506153, metrics={'train_runtime': 2196.4521, 'train_samples_per_second': 13.0, 'train_steps_per_second': 0.813, 'total_flos': 7515096898646016.0, 'train_loss': 0.01904480025506153, 'epoch': 3.0})"]},"metadata":{},"execution_count":23}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"vo42h-y6sRPx","executionInfo":{"status":"ok","timestamp":1657093934195,"user_tz":-420,"elapsed":1968,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["FILE = \"/content/drive/MyDrive/AIBuilders/json/mlm_json_6.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["a81d4bc96f8449208265c0d8b50ce959","da1f26a0c43e49beb2deb9327aa5a07d","042230d6d0c842a4b9bd8302a799597e","645f2aac90b04e95817a1eddf6e8afff","db2b75a4c4054eae852505b76ac0f69b","eb4545e74f564cc294bf4e400ff737f1","058520ac5e8d4be09bc0b62405b94d0a","49848535c2094cd4ac4c79ce765fb046","66ffcfaad7614879bc63e5ca4beae83e","9981e2a9842041f9b590f5205794e73b","651237317ea84458b9623a92d026fe81","cea9a81e93d84955b85fe2a5a40675da","8d812b10c2b04d3fa215e66a7cff2cea","278047df951041bd90fdd5e5d3871490","dd7f3b4d7e2a4efd9ac073ec34ded50b","b0ffc3d3d9754712b4e87487d06e397a","7ef1c8bffcdd4b098c1dcae97f2d63ad","9f00dd09c3884b5ca16014ba7620f462","d01bdae0448749c29a0dc6bc11e16e42","64a5ac383e4742268a87fd1a815c119b","287e857523eb41e1b103f448e4e97cde","d3b3fa08164c49d19e31aa4a355d7f4c"]},"executionInfo":{"elapsed":353890,"status":"ok","timestamp":1655636768996,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"gWlP9YgBxEnu","outputId":"3e35af19-cf51-4d13-cf15-699274fadc4e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/pytorch_model.bin\n"]},{"output_type":"display_data","data":{"text/plain":["Upload file pytorch_model.bin:   0%|          | 3.34k/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81d4bc96f8449208265c0d8b50ce959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Upload file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea9a81e93d84955b85fe2a5a40675da"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   0ad3488..042aaa7  main -> main\n","\n","Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n","To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   042aaa7..d124223  main -> main\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/commit/042aaa7a82de0ea8414ca4f8eb1e486c59978c17'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}],"source":["trainer.push_to_hub()# โยนขึ้น hugging face"]},{"cell_type":"code","source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"],"metadata":{"id":"crQST5D-xj_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","if use_cuda:\n","    model = model.cuda()\n","FILE = \"drive/MyDrive/AIBuilders/mlm/tagging_nova_75.pth\"\n","loaded_model = BertModel()\n","loaded_model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","loaded_model.eval()"],"metadata":{"id":"0Cz7bvztxoW7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655628677930,"user_tz":-420,"elapsed":8153,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"f184a44a-5526-42b1-d364-49bad07c5f15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'classifier.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ids_to_labels = {0: 'f', 1: 'i'}\n","\n","def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","        else:\n","            try:\n","              label_ids.append(2)\n","            except:\n","                label_ids.append(-100)\n","\n","        previous_word_idx = word_idx\n","    return label_ids\n","\n","def evaluate_one_text(model, sentence):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n","\n","    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","\n","    logits = model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    return prediction_label"],"metadata":{"id":"u65GCzVvxu8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1655628697373,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"dStVnDt6x9Nu","outputId":"e67bb371-92c9-4e9e-ca0b-8e9aa2a1563e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'i', 'i', 'i']\n","['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>']\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลก<mask>ป่าวคับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอะป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรื อป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลก จริง ๆป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอ๊ะป่าวคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิง<mask>คับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<pad>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงไหมคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<s>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง_คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงอะคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิงป่าว<mask></s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวครับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนี่</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าววะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวเนี่ย</s>'\n","{'input_ids': [5, 10, 136, 88, 932, 13, 3789, 30987, 10, 5204, 485, 7773, 3774, 2916, 801, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","<s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือ<pad>ครับ</s>\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","# if use_cuda:\n","#     model = model.cuda()\n","\n","text = \"ประเทศเราผลิตและส่งออกยาสูบเยอะสุดในโลกจิงป่าวคับ\"\n","ans = []\n","i_f = evaluate_one_text(loaded_model, text)\n","print(i_f)\n","a = tokenizer(text)\n","b = a['input_ids']\n","c = tokenizer.convert_ids_to_tokens(b)\n","print(c)\n","i_f_len = len(i_f)\n","for j in range(i_f_len):\n","  if(i_f[j] == 'i'):\n","    ph = a['input_ids'][j+1]\n","    a['input_ids'][j+1] = 25004\n","    print(tokenizer.decode(a['input_ids']))\n","    b = {'input_ids': torch.Tensor([a['input_ids']]).type(torch.int64).to(device), 'attention_mask': torch.Tensor([a['attention_mask']]).type(torch.int64).to(device)}\n","    token_logits = model(**b).logits\n","    mask_token_index = torch.where(b[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","    mask_token_logits = token_logits[0, mask_token_index, :]\n","    top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n","    ans.append((j, top_5_tokens[0]))\n","    text = ''.join(tokenizer.convert_ids_to_tokens(a['input_ids']))\n","    for token in top_5_tokens:\n","        print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n","    a['input_ids'][j+1] = ph\n","\n","print(a)\n","for x,y in ans:\n","  a['input_ids'][x+1] = y\n","print(''.join(tokenizer.convert_ids_to_tokens(a['input_ids'])))"]},{"cell_type":"code","source":["asdsf = pd.read_csv(\"drive/MyDrive/AIBuilders/final.csv\")"],"metadata":{"id":"nX5csn56T5_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(100,200):\n","  print(asdsf.iloc[i]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjXdABefT9VQ","executionInfo":{"status":"ok","timestamp":1655631575823,"user_tz":-420,"elapsed":5,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"90f27851-af69-4253-bb21-261ca3a8ed78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ต้องลอง555\n","อยากได้เตาอบบาบีก้อน จะเอามาทำขนมให้ลูกๆ ไปทานเล่นระหว่างวันค่ะ เป็นแม่บ้านว่างๆ ก็จะสรรหาเมนูใหม่ๆ ตามยูทูปเอามาลองทำ มีลูกนี่แหละเป็นหนูทดลอง 555 เห็นเตาก้อนแล้วอยากทำขนมคุ๊กกี้อบมากเลยค่ะ เอาเป็นรูปซานต้ากับต้นคริสมาส ฝึกทันพอดีก่อนเทศกาลเลย ❤️❤️❤️❤️❤️\n","เกิน 50 ไม่ไป!\n","แฟชั่นไอส์แลนด์ วันที่3/12ค่า\n","ลดพิเศษเเต่ของน้อยไม่ค่อยเติม\n","ฮื้ออออ เค้าสับเพร่า เค้าสับเพร่าาาาา เค้าจ่ายเต็มมมมม แต่อร่อยเด้ออออ ฮื้อออ\n","ผ่านนิเทศไปก่อนนะ\n","ไปคนเดียวดีฝ่าา\n","สาขาเพลินนารี่ ถ้าไม่อยากขายก้อปิดเถอะคับ ดูแลไม่ดีแล้วพนง.ยังไม่มีจิตใจในการขายด้วย เวลา1ชม.กับหลายๆอย่างไม่ไหวคับ หาคนมาดูบ้างนะครับ\n","ขาดเลยละ55 ไฮเนเก้น พอๆๆ 2 ขวด 555\n","ลอรีอัล รีไวทัลลิฟท์ เดอร์มาลิฟท์เดย์ครีม 50กรัม/ไนท์ ครีม 50กรัม ได้รับคูปองส่วนลด จากราคาเต็ม 599 บาท ลด 120บาท เหลือ 479บาท ในโปรโมชั่น watsons Beauty in Summer (29 มี.ค.-25 เม.ย. 61)\n","แล้วโครงการอื่นล่ะ??? แสนสิริเตรียมแจงกรณีปัญหาผนังห้องชุดโครงการเดอะ เบส สุขุมวิท 77 พรุ่งนี้ หลังพบใช้โฟมเป็นวัสดุก่อผนัง”\n","มีซูชิหรอ\n","นิสสันโน๊ตครับ\n","ขอบพระคุณคร้าบ\n","ขอสำรองได้มั้ยอ่า\n","ตอนนอนใส่แบบสอดฟินไม่เลอะที่นอน ตอนเช้าแบบผ้าอนามัยทั่วไป แต่แบบนี้ก็น่าลองนะคะคงสะดวกกว่าเยอะ\n","ป๊า เค้าอยากกินน 😁😁\n","ไป อยากจังแล้วนิ\n","สมองไหลตลอด\n","แอดมินขอส่งเรื่องให้หัวหน้างานตรวจสอบการทำงานของพนักงานที่สาขาให้นะคะ และขอน้อมรับคำแนะนำของลูกค้า เพื่อส่งต่อไปยังหน่วยงานที่เกี่ยวข้องเพื่อการพัฒนาและปรับปรุงการบริการของเราให้ดียิ่งๆขึ้นไปนะคะ\n","ซื้อไร ชวนไปแดร๊กส์\n","การได้สั่งลาวันอาทิตย์ ด้วย Jameson Ginger & Lime สักแก้วนี่มันดีจริงๆ นะ ถ้าไม่เชื่อ ก็ลองทำตามดูได้! #JamesonThailand #TwiceAsSmooth\n","นี่นิสสันยังดูไม่ใหญ่อีกเหรอครับ..ส่วนตัวคิดว่ารถกระบะนิสันออกแบบดูเทอะทะกว่าค่ายอื่นในยุคเดียวกัน(แต่ดูตัวเลขแล้วก็ไม่ได้ใหญ่นะ)ถ้าเขาเดินเกมแบบค่ายเจ้าตลาดทั้ง2ค่ายหรือออกตัวเท่ๆแบบฟอร์ดน่าตะไปได้ดีกว่านี้(ฟอร์ดยังไม่ใข่แรปเตอร์นะแรปเตอร์ส่วนตัวว่าแรปเตอร์เป็นปิคอัพหรูน่าจะเฉพาะกลุ่มที่เงินถึงๆ)\n","(‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’) http://www.jiggaban.com/97024-get1025-4/ ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่... ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่\n","กูตื่นเต้นมากกกกกกกกกกกกกกกกจะหมดเวลาปิดหีบแล้ววววอีกไม่กี่นาที\n","http://www.steam-engine.org/\n","ประเทศอื่นเขาสนับสนุนให้ใช้แทนบุหรี่จริง แต่ประเทศไทยมันยากหน่อยเพราะลงทุนสร้างโรงงานยาสูบใหม่ไปหลายร้อยล้าน\n","เลิกซื้อ หันมาขอเพื่อนสูบแทนใช่มั้ยครับ\n","แม้ว่า Nissan Maxima และ Murano ในปัจจุบันทำยอดขายดีขึ้นกว่ารุ่นเดิมแค่ระดับหนึ่ง แต่ในจีน Maxima กลับล้มเหลว Murano แค่พอไปได้ นี่อาจจะเป็นเหตุผลหลักที่ทำให้การปรับโฉม Minorchange ต้องดูสง่างามขึ้น\n","ชิ\n","หน้าพี่แบคตอนโดนเพื่อนลากไปตีคือกุวงวารมาก ฮือ หน้าแบบนี่กุต้องโดนเหรอ สติหลุดไปแล้ว5555555555555555555\n","เลือกได้ 2 ซุป และน้ำจิ้มท่านละ 1 รสชาติค่ะ ^^\n","มีโปรบุฟเฟต์หรือค่ะถึงวันที่เท่าไรค่ะ\n","นิสสันโน๊ต รถประหยัดน้ำมัน ราคาเบา ดีไซร์เลิศ ขับขี่ดีมากๆ ใครๆก้อชอบ มีหลายสีให้เลือกด้วยครับ\n","พลาดเพราะรีโว่นั่นแหละ\n","5555เดะบอกอีกทีสอบเสร็จก่อน\n","ดูข่าวที่ชวนปราศรัย เหมือนแกยังไม่รู้ว่า ทักษิณไม่ได้เป็นนายกแล้ว\n","ถ้าทำประตูเปิดเหมือนRX8 เจ้า CHR จะเป็นผู้บุกเบิกรถทรงนี้อย่างเต็มตัว..เพราะมันจะเข้ากับบุคลิกรถแคปทึบสปอร์ต..น่าเสียดาย\n","หิวพี่ก้อนอีกแล้ว\n","ก็ต้องไง จะใครละ\n","รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” เมื่อวันเสาร์ที่ 9 ธันวาคม 2560 รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” ชวนคุณมาไขความลับชะลอวัย โดย พญ.พันธลี ชื่นสัมพันธ์ แพทย์สาขาเวชศาสตร์ชะลอวัย ด้านโภชนาการและเมตาบอลิสึม รพ.กรุงเทพพัทยา และ คุณวิสสุตา กฤติยานิธิ นักกำหนดอาหาร และทีมนักโภชนาการ รพ.กรุงเทพพัทยา มาให้ความรู้แก่ผู้ร่วมกิจกรรม รวมถึงการทำอาหารเมนูสุขภาพด้วยตัวเองแบบง่าย ๆ โดยมีการให้ความรู้ในหัวข้อ ดังนี้ • วิธีดูแลสุขภาพคุณผู้ชาย คุณผู้หญิงให้กลับมาดูหนุ่มสาวขึ้นอีกครั้ง • ลองเช็คสัญญาณความเสื่อม คุณเข้าสู่วัยทองก่อนวัยหรือไม่? • เคล็ดลับกายฟิต หุ่นเฟริ์มเหมือนตอนหนุ่มสาว • DIY : Menu Lunch Box กินชะลอวัย ป้องกันโรคภัย ห่างไกลความอ้วน โดยในเดือนธันวาคมนี้ รพ.กรุงเทพพัทยา ได้มีการจัดแพ็กเกจตรวจสุขภาพ ในชื่อ แพ็กเกจสุขภาพดีรับปีใหม่ 2561 ราคาประหยัด ให้กับผู้ใส่ใจสุขภาพได้เลือกซื้อแพ้กเกจตรวจสุขภาพเป็นของขวัญมอบให้กับคนที่ท่านรัก โดยสามารถสอบถามรายละเอียดของแพ็กเกจตรวจสุขภาพได้ที่ รพ.กรุงเทพพัทยา หรือ โทร. 0 3333 3333\n","มีลิปเมลินดาเบอร์03ไหมค่ะ\n","Ba hao 八號 บาร์จีนดีๆ ในซอยนานา เบียร์นุ่ม อาหารอร่อย นี่สั่ง Jian Bing กับเกี๊ยวเป็ดไป น้ำซอสคือดีมาก เป็นซิกเนเจอร์ของร้านเลย บรรยากาศร้านก็ดี ให้อารมณ์หว่องเข้ากับบรรยากาศในคืนฝนตก จะกลับไปอีกแน่นอน\n","พยามบอกเขาว่า ไอน้ำนะ ไม่ใช่ควัน\n","ไม่ทันและ...กุมาฮาจิบังและ\n","พาลูกหนูไปกินด้วย\n","ของหวาน ก็ฮันนี่โทส ของคาวก็บาบีก้อน\n","ศรีจันทร์คือชอบเนื้อรองพื้นมาก แต่แบบนุแพ้ ฮรือ\n","งานช้างงงงครัช!!! วันเสาร์ที่ 24/2/2561 พบกันที่ แตงโมทะเลเผา อาหารสด ดนตรีเพราะ เบียร์เย็นๆ...\n","พาไปกินหน่อยเจ้าค่ะ\n","งานแสงโสม\n","ผลการตรวจสอบไปสัมภาษณ์กับสแตนด์บาบีก้อนหน้าร้านนะครับ\n","พี่เพิ่งรู้ว่าร้านกอล์ฟ เดี๋ยวไปอุดหนุนบ้าง\n","14 เมษายนของทุกปี คือ วันครอบครัว ค่ะ #สวยกล้าทุกแสง #คู่หูท้าแดด #kmacosmetics\n","พี่โชคคคคคคค น้องทานเอ็มเคอยู่ เด๋วมาเล่นด้วยนะ\n","แพ้ผ้าอนามัยอีกแล้วควายจัด\n","- สำหรับร้าน MK Gold buffet ที่เปิดขายทุกวัน มีสองสาขาคือ - สาขาศาลาแดง - สาขาEsplanade รัชดา - สำหรับร้าน MK Gold buffet ที่เปิดขายเฉพาะวันจันทร์ - ศุกร์ มีรายชื่อสาขา ดังต่อไปนี้ 1.สาขาเอกมัย 2.สาขาเซ็นทรัล เวิล์ดค่ะ ^^\n","เด็กเอ๋ยเด็กดี ต้องกิน ดีกรี ลีโอ เหล้าขาว 🍻🍃😜🙊 #แคปชั่นคอวอยอ #แคปชั่นเสี่ยว #แคปชั่นอ่อย #แคปชั่นเด็ด #แคปชั่นน่ารัก #คำคม #แคปชั่นกวนตีน\n","เมื่อ “ปรากฏการณ์จันทร์เต็มดวง” ถูก “ตีความใหม่” โดย 3 ศิลปิน Duangrit x Dudesweet x Trimode กลายเป็นประสบการณ์ ‘The North Full Moon ปาร์ตี้แสงเหนือ’ เสมือนอยู่บนดวงจันทร์ เตรียมชมความล้ำและมันส์ จากมนุษย์พวกแรกที่ได้ไปถึง 18 พ.ย. นี้ #SangSom #RedefineFullMoon #TheNorthFullmoonParty\n","ทุกวันนี้รีโว่รอกโค่. ทำไวเเทกหงายได้ยังครับ 😝\n","งอนบาบีก้อนถึง2020\n","ก้อนมีรายละเอียดกาต้มน้ำเพิ่มเติมตามรูปนะคร้าบบ^^\n","รำ😑\n","หลอนจัดเลยครับ 55555\n","10 พย : ยโสธร 11 พย : หนองคายBike Week 15 พย : งานช้างสุรินทร์ 17: พย : ตะวันแดงพัทยา 18: พย : ลานเบียร์สิงห์ กบินทร์บุรี\n","กินไก่ KFC กับ เบียร์ช้าง ????\n","เออแบบอะไรก็ฮอตพอท!555\n","ใช้รุ่นนี้ไหมที่เขาจะเอามาทำแท็กซี่แทน..อัลติส\n","วันนี้นะ ที่ลานโตโยต้า คุณวาสี ถนนชัยภูมิ-บ้านเขว้า\n","แบรนด์sivannaมีของปลอมมั้ยคะ\n","มีเงินหรอ\n","รีเจนซี่ ตื่นสบายจริงเหรอ 555\n","ชาวกรุงตื่นเต้น รถบ้านสุดฮิป U Motel ที่ถูกเนรมิตขึ้นมาจาก U Beer #SleepWithU #UMotel อย่าลืมติดดาวเพจ https://www.facebook.com/UBeerThai/ เพื่อไม่พลาดเรื่องราวและกิจกรรม\n","safe series 2018 จาก netflix เรื่องเกี่ยวกับลูกสาวหายตัวไป พ่อเธอจึงออกตามหา เล่าเรื่องได้สูตรสำเร็จของนิยายฮาลาน โคเบนมาก การสืบต่อไปเรื่อยจนพบความจริง ที่ชอบก็คือแม่งเก่งที่ทำให้ทุกตัวละครน่าสงสัยไปหมดได้ ถือว่าเป็น 8ep ที่ไม่น่าเบื่อเลยสนุกมาก #ชิตพลรีวิว\n","บุหรี่ไฟฟ้านะ ไม่ใช่ยาบ้า มึงก้บ้า เกินไป\n","แต่งหน้าง่ายๆแต่กันน้ำขั้นสุด https://www.youtube.com/watch?v=Ywm0RT8Kqjo #แป้งเจ้านาง #แป้งพัฟเจ้านาง #Chaonangthailand #Chaonangthailandofficial #แป้งพัฟ #แป้ง #แป้งพัพถูกและดี #แป้งผสมกันแดดที่ดีที่สุดในยุค #แป้งผสมรองพื้น #แป้งพัฟคุมมัน #ลิปเจ้านาง #ลิปแมทเจ้านาง #ลิปแมท สอบถาม-สั่งซื้อ-สมัครตัวแทน โทร. 088-888-8888 📲Line : @chaonangth 📩Inbox : m.me/chaonangthailandofficial\n","น้อยใจแฟนหนุ่มมารับช้า ด.ญ.14 โดดสะพานลอยหวังฆ่าตัว อาการสาหัส\n","18.21น. ภูเก็ต เขต1 พลังประชารัฐ2,397 ประชาธิปัตย์1,818คะแนน ผลสังเกตการณ์นับคะแนนหน้าหน่วยจากอาสาสมัครTNN(อย่างไม่เป็นทางการ ) คลิก>https://www.tnnthailand.com/\n","หลังจากลบsocial media appทุกอันออกจากมือถือและตั้งกฏกับตัวเองไม่ให้เข้ามาเช็คอะไรทั้งสิ้น (ยกเว้น HBD เพื่อน พิมพ์ก่อนและเข้าโพส เวลาทั้งหมดห้ามเกิน 1 นาที) และตั้ง habit ใหม่คือทำโจทย์เลข ผลคือหลัง 30 วัน cognitive functioningดีขึ้นมาก คิดอะไรเร็ว งานเสร็จ เครียดน้อยลง หลับสบาย\n","แล้วตอนนี้มึงก็แดกอะไรไม่ได้เลยอ้อ\n","4x4 ไหมครับ รุ่นนี้\n","พี่ก้อนน่ารักมาก ยิ้มตลอดทาง กำลังใจและคู่คิดของกันและกันแท้ๆ\n","จันทร์ Shock โลก The Return คืนนี้ ดีเจโอ๊ต ปราโมทย์ เปิดบ้านต้อนรับดีเจคุณพ่อลูกหนึ่ง เจ็ม ณัฏฐ์ปวินท์ มาระเบิดความฮากับคำถามสุดช๊อกและของรางวัลสุดกวน 3-5 ทุ่มที่ EFM104.5 และชมสดพร้อมๆกันผ่าน Facebook Live & Youtube Live ลงทะเบียนเล่นเกมส์ได้แล้วตอนนี้ที่เบอร์ 02-222-2222 . สนับสนุนความ Shockkkkk โดย Centerpoint of Siam Square https://www.facebook.com/centerpointofsiamsquare BarBQ Plaza http://www.11street.co.th/store/MiniMallAction/getMiniMallHome.do?sellerHmpgUrl=barbqplaza MG http://mgcars.com/th/mg-models/mgzs/detail/overview รู้ใจดอทคอม https://www.roojai.com/ Traveloka https://www.traveloka.com/th-th/?utm_source=THFlightHotel&utm_medium=radio&utm_campaign=EOY-011117 CP https://www.facebook.com/dimsum.jadedragon/ Enchanter https://www.facebook.com/EnchanteurThailand/ #จันทร์ShockโลกTheReturn\n","ใจเยนนนน กูชักอ้วนใหญ่แล้ว\n","Civic ทุกรุ่นใช้ระบบกันสะเทือนหน้าแบบคอยล์สปริง ด้านหลังทอร์ชั่นบาร์พร้อมคอยล์สปริง เครื่องยนต์ยังคงใช้รหัส D และเพิ่มรุ่นใหม่ 1,500 ซีซี CVCC โดยในปี 1984 ได้เพิ่มรุ่นแรงรหัส Si สำหรับทำตลาดญี่ปุ่น ปรับปรุงระบบกันสะเทือน และใช้เครื่องยนต์ DOHC ZC ความจุ 1,600 ซีซี กำลังสูงสุด 130 แรงม้า ส่วนรุ่นที่ทำตลาดในสหรัฐอเมริกาในชื่อ Civic Si 3 ประตู และ CRX Si ใช้เครื่องยนต์หัวฉีด 12 วาล์ว กำลังสูงสุด 91 แรงม้า เดือนพฤศจิกายน 1984 ฮอนด้าเพิ่มระบบขับเคลื่อน 4 ล้อให้ Civic เป็นครั้งแรกในรุ่น Shuttle ช่วงแรกมีปุ่มกดสำหรับเข้า-ออกจากระบบขับเคลื่อน 4 ล้อที่เรียกว่า \"Realtime\" เพราะสามารถทำได้ขณะรถวิ่ง จากนั้นในเดือนกุมภาพันธ์ 1985 จึงเพิ่มรุ่น Quint Integra ตัวถังแฮทช์แบ็ก 3 ประตู ฐานล้อ 2,450 มิลลิเมตร และในเดือนพฤศจิกายน 1986 เพิ่มรุ่น 5 ประตูแฮทช์แบค พร้อมขยายขนาดฐานล้อเป็น 2,520 มม.\n","ไม่อยากกินลีโอ อยากกินฝรั่ง\n","ขี้มอไซไปไง ที่โฮมโปรมีจะไปปะละ ใจๆ5555หิวด้วย\n","Nissan X-trail ขับนิ่ม เสียงเงียบ สบาย คล่องตัว\n","Nissan Note. ดาวน์เท่าไรค่ะ\n","น่าสนใจค่ะMGเป็นรถที่ออกแบบเพื่อความปลอดภัยรูปแบบทรงสวยทันสมัย\n","กลับไปจัดเลย\n","พี่ต้าไง\n","ก้อมันจริงนิ\n","แนะนำให้เริ่มต้นจากการล้างหน้าด้วย Hada Labo Deep Clean & Pore Refining Face Wash โฟมสูตรอ่อนโยนที่จะช่วยลดความมันส่วนเกินเพื่อรูขุมขนกระชับนะคะ\n","นะ\n","เผยรถต้นแบบ Small Rs Concept ที่คาดว่าจะเป็น All New Honda Brio รุ่น RS\n","หนูอยากกินมากนะค่ะ ที่รัก 😗😗😗\n","อะไรคือความรัก.... . เตรียมตัวให้พร้อม แล้วมาพบกับคืนนี้ Stamp (เเสตมป์ อภิวัชร์) .... . ในวันพฤหัสบดีที่ 28 ธันวาคมนี้ที่ DND Ekkamai . •Ticket : . Pre-sale ราคาเพียง 400 บาท เท่านั้น !! Front Door: 500 บาท . 🍺First 250 people who come first will get FREE BEER (a bottle of Singha light each) . ติดต่อซื้อบัตรได้ทาง Line: @untoldproject Call :088-888-8888 IG & FB: @untoldproject.bkk . #DNDDoNotDisturb #DNDBoutiquePlayhouse #ChivasExtra #Singhalight #untoldproject\n","ขอเสียของบุหรี่ไฟฟ้าคือ...รัฐบาลขาดทุนจบ!!!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"U2r4sIe_UTID"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"mlm_json.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b26d67ee49144ddaa7a968b21fcb271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_992cd38899fb4d72813f721af8f57bdb","IPY_MODEL_f82d72f405d44a1c815b376d4515a517","IPY_MODEL_9994d5a29d72462cae0f2326cf60d274"],"layout":"IPY_MODEL_1923362afb0d40b991be93c9e7eb3445"}},"992cd38899fb4d72813f721af8f57bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5ac575d2444a2684332632f4729f7d","placeholder":"​","style":"IPY_MODEL_f349705a4ac64e49ae66eca3578da471","value":"Downloading: 100%"}},"f82d72f405d44a1c815b376d4515a517":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1e6fe15a504b338a933e5ba34edfd2","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c2c40222afc4cfa8447e274be0c0a5b","value":772}},"9994d5a29d72462cae0f2326cf60d274":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ef5e4456549494e9af9590932a1468c","placeholder":"​","style":"IPY_MODEL_16b304b8dc9a4aff959455b52544d3ed","value":" 772/772 [00:00&lt;00:00, 25.8kB/s]"}},"1923362afb0d40b991be93c9e7eb3445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b5ac575d2444a2684332632f4729f7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f349705a4ac64e49ae66eca3578da471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1e6fe15a504b338a933e5ba34edfd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2c40222afc4cfa8447e274be0c0a5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ef5e4456549494e9af9590932a1468c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b304b8dc9a4aff959455b52544d3ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9021b39802e4207b876b3948f95876a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c54a043cdb1428fb786fb77a3fbb2b2","IPY_MODEL_b6e9d7b4904346e9bc4a645fe7ecab27","IPY_MODEL_e6c6aa874cf543cc9dbc89e8f7427711"],"layout":"IPY_MODEL_483158b39ae64f45b9c7ebe2e3668944"}},"8c54a043cdb1428fb786fb77a3fbb2b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b97cb4a64688484683f928ed02533661","placeholder":"​","style":"IPY_MODEL_a4628aef19674546b9d09a2cf3a38d30","value":"Downloading: 100%"}},"b6e9d7b4904346e9bc4a645fe7ecab27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a696d82a3994743898e129e77f4f8e2","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d7899b54ebc4002a1e93b9c89de1024","value":447792171}},"e6c6aa874cf543cc9dbc89e8f7427711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e30c266bf2b543f4a89859b02a59a2ec","placeholder":"​","style":"IPY_MODEL_bd5439d9bf8242089a6378ef45d85b0d","value":" 427M/427M [00:28&lt;00:00, 18.0MB/s]"}},"483158b39ae64f45b9c7ebe2e3668944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97cb4a64688484683f928ed02533661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4628aef19674546b9d09a2cf3a38d30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a696d82a3994743898e129e77f4f8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d7899b54ebc4002a1e93b9c89de1024":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e30c266bf2b543f4a89859b02a59a2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5439d9bf8242089a6378ef45d85b0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a81d4bc96f8449208265c0d8b50ce959":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da1f26a0c43e49beb2deb9327aa5a07d","IPY_MODEL_042230d6d0c842a4b9bd8302a799597e","IPY_MODEL_645f2aac90b04e95817a1eddf6e8afff"],"layout":"IPY_MODEL_db2b75a4c4054eae852505b76ac0f69b"}},"da1f26a0c43e49beb2deb9327aa5a07d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4545e74f564cc294bf4e400ff737f1","placeholder":"​","style":"IPY_MODEL_058520ac5e8d4be09bc0b62405b94d0a","value":"Upload file pytorch_model.bin: 100%"}},"042230d6d0c842a4b9bd8302a799597e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49848535c2094cd4ac4c79ce765fb046","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66ffcfaad7614879bc63e5ca4beae83e","value":447792171}},"645f2aac90b04e95817a1eddf6e8afff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9981e2a9842041f9b590f5205794e73b","placeholder":"​","style":"IPY_MODEL_651237317ea84458b9623a92d026fe81","value":" 427M/427M [05:30&lt;00:00, 642kB/s]"}},"db2b75a4c4054eae852505b76ac0f69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4545e74f564cc294bf4e400ff737f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058520ac5e8d4be09bc0b62405b94d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49848535c2094cd4ac4c79ce765fb046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ffcfaad7614879bc63e5ca4beae83e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9981e2a9842041f9b590f5205794e73b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651237317ea84458b9623a92d026fe81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cea9a81e93d84955b85fe2a5a40675da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d812b10c2b04d3fa215e66a7cff2cea","IPY_MODEL_278047df951041bd90fdd5e5d3871490","IPY_MODEL_dd7f3b4d7e2a4efd9ac073ec34ded50b"],"layout":"IPY_MODEL_b0ffc3d3d9754712b4e87487d06e397a"}},"8d812b10c2b04d3fa215e66a7cff2cea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ef1c8bffcdd4b098c1dcae97f2d63ad","placeholder":"​","style":"IPY_MODEL_9f00dd09c3884b5ca16014ba7620f462","value":"Upload file training_args.bin: 100%"}},"278047df951041bd90fdd5e5d3871490":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01bdae0448749c29a0dc6bc11e16e42","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a5ac383e4742268a87fd1a815c119b","value":2991}},"dd7f3b4d7e2a4efd9ac073ec34ded50b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_287e857523eb41e1b103f448e4e97cde","placeholder":"​","style":"IPY_MODEL_d3b3fa08164c49d19e31aa4a355d7f4c","value":" 2.92k/2.92k [05:30&lt;?, ?B/s]"}},"b0ffc3d3d9754712b4e87487d06e397a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ef1c8bffcdd4b098c1dcae97f2d63ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f00dd09c3884b5ca16014ba7620f462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01bdae0448749c29a0dc6bc11e16e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a5ac383e4742268a87fd1a815c119b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"287e857523eb41e1b103f448e4e97cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b3fa08164c49d19e31aa4a355d7f4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3eafeae8b844036a7b5f0c1a6ebe4e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fff9c8e4b0c4d6198aad11efb689820","IPY_MODEL_70ec88c2387441ac80a20b7d79094eca","IPY_MODEL_918e65e8746e4231b8a82a4b600eeebe"],"layout":"IPY_MODEL_0eaa2e0e1e8342f6a7a3d301f574dbbe"}},"5fff9c8e4b0c4d6198aad11efb689820":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_145b2142cd644bbfb56e75ee681f322f","placeholder":"​","style":"IPY_MODEL_f8f781ac63034f7ea1c66d7ad1b9b8cc","value":"Downloading: 100%"}},"70ec88c2387441ac80a20b7d79094eca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_649dea9a14af42fb9e900a591d8b12a4","max":546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9f192112cfd48f3b6c42e149c94d5cc","value":546}},"918e65e8746e4231b8a82a4b600eeebe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7bf0bcc78be4145a27ab0646ca104fc","placeholder":"​","style":"IPY_MODEL_8ed3ba25ad40403496364bcd87a89bce","value":" 546/546 [00:00&lt;00:00, 12.8kB/s]"}},"0eaa2e0e1e8342f6a7a3d301f574dbbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"145b2142cd644bbfb56e75ee681f322f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f781ac63034f7ea1c66d7ad1b9b8cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"649dea9a14af42fb9e900a591d8b12a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9f192112cfd48f3b6c42e149c94d5cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7bf0bcc78be4145a27ab0646ca104fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ed3ba25ad40403496364bcd87a89bce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c71361f762243609c5bb03f7067d78c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4cb88aa34de482883027be38aad4262","IPY_MODEL_ac06732669bd4b6c817e6ad629394c65","IPY_MODEL_cb7bee8ed9f74c86a6dccc3e147ab8d5"],"layout":"IPY_MODEL_7fb9f1006f864efe97fc6c364c832984"}},"d4cb88aa34de482883027be38aad4262":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1571e270ccc4f3b9b5b026bb642aa18","placeholder":"​","style":"IPY_MODEL_04256747b95a43b3baab0462780b130f","value":"Downloading: 100%"}},"ac06732669bd4b6c817e6ad629394c65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a819e447802f40009cd655bd97d4adb5","max":423498558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59479122c9c542139624a08e81d68d68","value":423498558}},"cb7bee8ed9f74c86a6dccc3e147ab8d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4f3948d040e4e319b287b5fefd81a86","placeholder":"​","style":"IPY_MODEL_a6e90eb74f6a448dab18e5b9593f6123","value":" 404M/404M [00:10&lt;00:00, 44.2MB/s]"}},"7fb9f1006f864efe97fc6c364c832984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1571e270ccc4f3b9b5b026bb642aa18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04256747b95a43b3baab0462780b130f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a819e447802f40009cd655bd97d4adb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59479122c9c542139624a08e81d68d68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4f3948d040e4e319b287b5fefd81a86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6e90eb74f6a448dab18e5b9593f6123":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"999a1423a011427d92b4bae8d77a1d8d":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ae575dea2bbc4f37b886319c19f80add","IPY_MODEL_97f66fe062a04133baf0c6980ff64b6f","IPY_MODEL_3bee5df8c45e4c819fe87a12361cd1a3","IPY_MODEL_c5474edb64d848f998659f5fece65fc6"],"layout":"IPY_MODEL_af2e08b8087c4cb59eb32352ec7ad400"}},"ae575dea2bbc4f37b886319c19f80add":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dab459d3ac74d0891a58ab22fe75d9d","placeholder":"​","style":"IPY_MODEL_937000d241914846b467756686e3bdba","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"97f66fe062a04133baf0c6980ff64b6f":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_91e1ffe326cd478b8b6629d937d1713f","placeholder":"​","style":"IPY_MODEL_608b52cafe6c4b1cac020acf9cb6cb07","value":""}},"3bee5df8c45e4c819fe87a12361cd1a3":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_2336df9c24f448ea819c8789bc253a78","style":"IPY_MODEL_4293d1299fb14923b02e3cb09e33f220","tooltip":""}},"c5474edb64d848f998659f5fece65fc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34ebcc136e5f45c18322d14df3e4cec2","placeholder":"​","style":"IPY_MODEL_a04eefbe607e4a2eaa259a3b054e4962","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"af2e08b8087c4cb59eb32352ec7ad400":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"6dab459d3ac74d0891a58ab22fe75d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937000d241914846b467756686e3bdba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91e1ffe326cd478b8b6629d937d1713f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"608b52cafe6c4b1cac020acf9cb6cb07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2336df9c24f448ea819c8789bc253a78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4293d1299fb14923b02e3cb09e33f220":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"34ebcc136e5f45c18322d14df3e4cec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a04eefbe607e4a2eaa259a3b054e4962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae41fd9a61fd4737a20bd1bc012313f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2da3c5e1aaf44e73b98e3edc4bfdca7c","IPY_MODEL_b952623bc4694706b802695b82a6d171","IPY_MODEL_378ac02b3c0445dba5f0d360225b61a5"],"layout":"IPY_MODEL_69b6cce9bf5a4f35afcc49f6cc9880bf"}},"2da3c5e1aaf44e73b98e3edc4bfdca7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ac06c7bdda4e56953613c3fedef2a1","placeholder":"​","style":"IPY_MODEL_0eb3363e2c164990bdd1a3c586b206b6","value":"Download file pytorch_model.bin: 100%"}},"b952623bc4694706b802695b82a6d171":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e257def77844680a7da34e13efdf2ea","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e0db67e76424135a7a5018168c8f098","value":447792171}},"378ac02b3c0445dba5f0d360225b61a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a657e553ed84d6eb4b21d78bf724337","placeholder":"​","style":"IPY_MODEL_38a65dc5cc2147918b87ecdc9d94ca2c","value":" 427M/427M [03:07&lt;00:00, 186kB/s]"}},"69b6cce9bf5a4f35afcc49f6cc9880bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ac06c7bdda4e56953613c3fedef2a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb3363e2c164990bdd1a3c586b206b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e257def77844680a7da34e13efdf2ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e0db67e76424135a7a5018168c8f098":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a657e553ed84d6eb4b21d78bf724337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38a65dc5cc2147918b87ecdc9d94ca2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e535d77dae1444c8175eb0ecd308770":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2842b63f9ac74643b26fba7a7baf174e","IPY_MODEL_3609200b1e6a436b8e98b9d7c1aef298","IPY_MODEL_859645b4856b479e8454b205e8975ab8"],"layout":"IPY_MODEL_20f9270c842f42488cacaaf9efa66aad"}},"2842b63f9ac74643b26fba7a7baf174e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64e159c5af804bbfb1ee4eb59869d745","placeholder":"​","style":"IPY_MODEL_9a35f3b26d9147eda3e14f6eb6f39dcb","value":"Download file training_args.bin: 100%"}},"3609200b1e6a436b8e98b9d7c1aef298":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27029db2dc6d46a4a7bcd255f5cffe22","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e07ce15f1fb4a26bbc78ca2f4b4e805","value":2991}},"859645b4856b479e8454b205e8975ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f3a4c697abb4707bf71ce007f983b63","placeholder":"​","style":"IPY_MODEL_ad626ea16d44478c9fff6cf9a5f9ef55","value":" 2.92k/2.92k [03:06&lt;?, ?B/s]"}},"20f9270c842f42488cacaaf9efa66aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e159c5af804bbfb1ee4eb59869d745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a35f3b26d9147eda3e14f6eb6f39dcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27029db2dc6d46a4a7bcd255f5cffe22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e07ce15f1fb4a26bbc78ca2f4b4e805":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f3a4c697abb4707bf71ce007f983b63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad626ea16d44478c9fff6cf9a5f9ef55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f8ecb32ff9c45889dc34aea594fb8c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3062e07104074ab28cd7d2ba9caf8981","IPY_MODEL_a87be5b4deae49199c4352d6d40b53de","IPY_MODEL_bf7c8af4510c4bdca84109e51b0ac42d"],"layout":"IPY_MODEL_f463ef9a65d54cce967f453474840096"}},"3062e07104074ab28cd7d2ba9caf8981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b184a8d3061a418a8c24b69e8adb5e51","placeholder":"​","style":"IPY_MODEL_a379143d7bae49d899ee0b3b22b477ec","value":"Clean file training_args.bin: 100%"}},"a87be5b4deae49199c4352d6d40b53de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b8fb1a4f2a41f194b68518be7b1755","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba82d007461248adab326acf16fba6cb","value":2991}},"bf7c8af4510c4bdca84109e51b0ac42d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb7971f12d2040c09b4a8df47ac80954","placeholder":"​","style":"IPY_MODEL_68584c751d1c4595846237cfd83b9201","value":" 2.92k/2.92k [03:06&lt;00:00, 10.5B/s]"}},"f463ef9a65d54cce967f453474840096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b184a8d3061a418a8c24b69e8adb5e51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a379143d7bae49d899ee0b3b22b477ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8b8fb1a4f2a41f194b68518be7b1755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba82d007461248adab326acf16fba6cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb7971f12d2040c09b4a8df47ac80954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68584c751d1c4595846237cfd83b9201":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62186b93324c455eb39970a26e120ac0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27d10cc518ec48698ca6a1e6cd4a88c2","IPY_MODEL_e05dec65ddb54b96a740e6c072c31412","IPY_MODEL_77ad22152cd9457c8e85f3dceacd2836"],"layout":"IPY_MODEL_8cfba2e0f9834b76ae11c8ec37551711"}},"27d10cc518ec48698ca6a1e6cd4a88c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d8a0a1b4514aa6a1783ff34bc280c5","placeholder":"​","style":"IPY_MODEL_af5a054aade745b4ade6d6eddbb6258a","value":"Clean file pytorch_model.bin: 100%"}},"e05dec65ddb54b96a740e6c072c31412":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1780d968589b469385d19bce8f2912ea","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bbf4f327411495984d5e3d27afb5fc9","value":447792171}},"77ad22152cd9457c8e85f3dceacd2836":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e82d564ea2a48a0b8ea23387ac6c81a","placeholder":"​","style":"IPY_MODEL_08157f0343f94336ad5157e60b5ab2a9","value":" 427M/427M [01:01&lt;00:00, 7.72MB/s]"}},"8cfba2e0f9834b76ae11c8ec37551711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44d8a0a1b4514aa6a1783ff34bc280c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af5a054aade745b4ade6d6eddbb6258a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1780d968589b469385d19bce8f2912ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bbf4f327411495984d5e3d27afb5fc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e82d564ea2a48a0b8ea23387ac6c81a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08157f0343f94336ad5157e60b5ab2a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}