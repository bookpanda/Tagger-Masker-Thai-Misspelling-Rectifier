{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1657254685528,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"q-8jviuNMYEE"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38661,"status":"ok","timestamp":1657254724793,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"Xn4m_rzYuqaj","outputId":"91a28ace-4745-4ef6-f769-44a2b6166285"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 51.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 71.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.7.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.4 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 18.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.11.4)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 59.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bcca99528d4a80eebff6244d72b0b5c7df149a9ab1af5f688df30ac71f6d0b14\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.15.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets==1.17.0\n","  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.8.1)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (6.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (21.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.3.5.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2.23.0)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 70.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.64.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 54.4 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 52.2 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.70.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.17.0) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2.10)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 60.9 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 73.7 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.17.0) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.17.0) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 xxhash-3.0.0 yarl-1.7.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langid\n","  Downloading langid-1.1.6.tar.gz (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from langid) (1.21.6)\n","Building wheels for collected packages: langid\n","  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941188 sha256=068d82243d7e8f94f97b3ec00c2f824d083ec1e431b72f4aac3262a6ae6b72e1\n","  Stored in directory: /root/.cache/pip/wheels/2b/bb/7f/11e4db39477278161e882eadc46fb558949a28b13470fc74b8\n","Successfully built langid\n","Installing collected packages: langid\n","Successfully installed langid-1.1.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jiwer\n","  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n","Collecting python-Levenshtein==0.12.2\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149860 sha256=caeb77a685eea4afd805db4f5a919508299d7e350e17588788ce609049d036d0\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein, jiwer\n","Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pythainlp\n","  Downloading pythainlp-3.0.8-py3-none-any.whl (11.5 MB)\n","\u001b[K     |████████████████████████████████| 11.5 MB 4.4 MB/s \n","\u001b[?25hCollecting tinydb>=3.0\n","  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (4.1.1)\n","Installing collected packages: tinydb, pythainlp\n","Successfully installed pythainlp-3.0.8 tinydb-4.7.0\n"]}],"source":["!pip install transformers==4.15.0 sentencepiece\n","!pip install datasets==1.17.0 \n","!pip install langid\n","!pip install jiwer\n","! pip install pythainlp"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13518,"status":"ok","timestamp":1657254738305,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"HwW6pLJ8utnf"},"outputs":[],"source":["import torch\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import re\n","from transformers import AutoModelForMaskedLM, pipeline\n","from transformers import AutoTokenizer, BertForTokenClassification\n","from tqdm import tqdm \n","import pickle\n","from datasets import load_metric\n","import subprocess\n","import sys\n","import langid\n","from nltk.translate.gleu_score import sentence_gleu\n","from jiwer import cer\n","from pythainlp import correct"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26147,"status":"ok","timestamp":1657254766227,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"LFJ1FnHXu0cJ","outputId":"adf897df-48b3-4a53-9700-3a3e29b01dd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":59162,"status":"ok","timestamp":1657255162967,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"3zPAmXetu6Vm"},"outputs":[],"source":["tokenizer = pickle.load(open('drive/MyDrive/AIBuilders/tpth/tokenizer_40k_nova.pkl', 'rb'))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":22258,"status":"ok","timestamp":1657270527292,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ADqbZe3vvH_Y"},"outputs":[],"source":["ds_mlm = pickle.load(open('drive/MyDrive/AIBuilders/tpth/mlm_ds_40k_nova.pkl', 'rb'))\n","ds_tag = pickle.load(open('drive/MyDrive/AIBuilders/tpth/ner_ds_40k_nova.pkl', 'rb'))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657270527292,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ZZWGtsN_QtU5","outputId":"4cfa4cc9-0cab-47e4-e9e9-aaabee235ac8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":11}],"source":["# ds_mlm = ds_mlm[37890:]\n","# ds_tag = ds_tag[37890:]\n","# ds_mlm = ds_mlm[38890:]\n","# ds_tag = ds_tag[38890:]\n","# ds_mlm = ds_mlm[39890:]\n","# ds_tag = ds_tag[39890:]\n","ds_mlm = ds_mlm[40890:]\n","ds_tag = ds_tag[40890:]\n","NUM_SAMPLE = ds_mlm.shape[0]\n","NUM_SAMPLE"]},{"cell_type":"code","source":["bleu = load_metric(\"bleu\")\n","glue = load_metric(\"glue\", \"mrpc\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","NUM_SAMPLE=1000\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","  # print(text_id)\n","  # print(labels_id)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(text_token_len):\n","    text_token[j] = text_token[j].replace(\"▁\", \" \")\n","    try:\n","      corrected = correct(text_token[j])\n","    except:\n","      print(f\"err pythainlp: {text_token[j]}\")\n","    else:\n","      # print(f\"{text_token[j]} => {corrected}\")\n","      text_token[j] = corrected\n","    \n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  # print(references)\n","  # print(predictions)\n","  # print(original)\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ii8AI9fBR9a","executionInfo":{"status":"ok","timestamp":1657286882029,"user_tz":-420,"elapsed":16201807,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"282b4af4-cdb4-4a58-e07e-87ae8686f753"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [4:29:59<00:00, 16.20s/it]"]},{"output_type":"stream","name":"stdout","text":["AVG ACC: 0.0016464283215952699\n","AVG f1: 0.0029028534659916896\n","# HIGHER BLEU PREDICTION: 0\n","# LOWER BLEU PREDICTION: 1000\n","# EQUAL BLEU PREDICTION: 0\n","# GLEU PREDICTION: 0.2380370204838368\n","# GLEU ORIGINAL: 0.8641163716651621\n","# CER PREDICTION: 0.2457286122856353\n","# CER ORIGINAL: 0.0358968238745513\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["bleu = load_metric(\"bleu\")\n","glue = load_metric(\"glue\", \"mrpc\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","NUM_SAMPLE=1000\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","  # print(text_id)\n","  # print(labels_id)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(text_token_len):\n","    text_token[j] = text_token[j].replace(\"▁\", \" \")\n","    try:\n","      corrected = correct(text_token[j])\n","    except:\n","      print(f\"err pythainlp: {text_token[j]}\")\n","    else:\n","      # print(f\"{text_token[j]} => {corrected}\")\n","      text_token[j] = corrected\n","    \n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  # print(references)\n","  # print(predictions)\n","  # print(original)\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295,"referenced_widgets":["1cd5b4cffce842abb1bfdf5903c7540f","eda96e6b3cd04e22a30508bb7c29f5b5","8d3f86945b51433dbdb1c44205a887ef","f3690f9d6954432eb11753acdcb51eb7","83e778043b774a7a9b4bc682eb053091","52201ce493524c29970323d79a75dad2","8635739f820d4555ae9804e7af8918d6","542a3e2bf1eb44e0950099250431ad7d","2893e03a2d474e0f9670a2bbc357d0af","e9080c3ff4af4effab240970c54670fd","dc08118847da4d99a399099eb9fe71f4","23199bfe6b6141699125d3d036450af7","6951280f6c2c4b3f8bc11e7872b1424f","c01e52dd59764cd69c6ee366b213aacc","e4b6fd7d9a5541ba8140ec93c3aa9ee8","35ab324a0fa14299b98d1fdf36ef2c71","26d71ec040424dbbbeb6975a77207228","396ca01c543e45ae95dcc997530800fd","bf564205cee34b78a711c94a676879b6","b42553669aa845848330da115d08e8fd","e6a43f6f80ca4141a8dec971c923da49","4b12bbf4398e4010acd55d47bb0418d4","b2cb310fafde44838ed000ec0970aa9c","b7684105fb684e3d9288a609b1fdc6c5","d884761ee5344e54b6456868c1dd8abf","70cdc2f00f6944299c15a9e7d2ee0f0b","075627e8e8de4cd79f1f63e2f0a9ba3d","20b8329b7f0e4c4fa43dd4550286ef08","764aeb41fa7a4bfa9a17bbe7b0948237","256dabfeb58540e8a0f696ecc9524c70","7ca5cce392a84116b6fb68e8963ac827","49d74c28915b4352b6856acd065eb2d9","125a609e42954578b382bab9a135f846"]},"id":"lDPuJQe6FeCr","executionInfo":{"status":"ok","timestamp":1657270434041,"user_tz":-420,"elapsed":15244786,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"53407762-8567-4590-b755-2bb2191d4ff1"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cd5b4cffce842abb1bfdf5903c7540f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23199bfe6b6141699125d3d036450af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2cb310fafde44838ed000ec0970aa9c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [4:14:02<00:00, 15.24s/it]"]},{"output_type":"stream","name":"stdout","text":["AVG ACC: 0.0010222687402040953\n","AVG f1: 0.0018401107401775825\n","# HIGHER BLEU PREDICTION: 0\n","# LOWER BLEU PREDICTION: 1000\n","# EQUAL BLEU PREDICTION: 0\n","# GLEU PREDICTION: 0.24594468942708955\n","# GLEU ORIGINAL: 0.8738663666530905\n","# CER PREDICTION: 0.23535208944018957\n","# CER ORIGINAL: 0.03306011655733898\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["bleu = load_metric(\"bleu\")\n","glue = load_metric(\"glue\", \"mrpc\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","NUM_SAMPLE=1000\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","  # print(text_id)\n","  # print(labels_id)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(text_token_len):\n","    text_token[j] = text_token[j].replace(\"▁\", \" \")\n","    try:\n","      corrected = correct(text_token[j])\n","    except:\n","      print(f\"err pythainlp: {text_token[j]}\")\n","    else:\n","      # print(f\"{text_token[j]} => {corrected}\")\n","      text_token[j] = corrected\n","    \n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  # print(references)\n","  # print(predictions)\n","  # print(original)\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBelFbkFKNEq","executionInfo":{"status":"ok","timestamp":1657207000564,"user_tz":-420,"elapsed":17981296,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"e4aafb7b-9e88-4288-8d9e-8eb457c9eee5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [4:59:35<00:00, 17.98s/it]"]},{"output_type":"stream","name":"stdout","text":["AVG ACC: 0.0018666903330733196\n","AVG f1: 0.0033239966347243612\n","# HIGHER BLEU PREDICTION: 0\n","# LOWER BLEU PREDICTION: 1000\n","# EQUAL BLEU PREDICTION: 0\n","# GLEU PREDICTION: 0.23835110303842347\n","# GLEU ORIGINAL: 0.8552652205795028\n","# CER PREDICTION: 0.241142016109713\n","# CER ORIGINAL: 0.03876608703880578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gqz78W7p8KT","outputId":"08c8f393-2313-409d-b742-5e4f9e9d4f42","executionInfo":{"status":"ok","timestamp":1657188901173,"user_tz":-420,"elapsed":18491799,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [5:08:09<00:00, 18.49s/it]"]},{"output_type":"stream","name":"stdout","text":["AVG ACC: 0.001659097849941958\n","AVG f1: 0.002984204275700828\n","# HIGHER BLEU PREDICTION: 0\n","# LOWER BLEU PREDICTION: 1000\n","# EQUAL BLEU PREDICTION: 0\n","# GLEU PREDICTION: 0.23970478794255046\n","# GLEU ORIGINAL: 0.8636914705294098\n","# CER PREDICTION: 0.23985341176107164\n","# CER ORIGINAL: 0.035971571261440315\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["bleu = load_metric(\"bleu\")\n","glue = load_metric(\"glue\", \"mrpc\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","NUM_SAMPLE=1000\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","  # print(text_id)\n","  # print(labels_id)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(text_token_len):\n","    text_token[j] = text_token[j].replace(\"▁\", \" \")\n","    try:\n","      corrected = correct(text_token[j])\n","    except:\n","      print(f\"err pythainlp: {text_token[j]}\")\n","    else:\n","      # print(f\"{text_token[j]} => {corrected}\")\n","      text_token[j] = corrected\n","    \n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  # print(references)\n","  # print(predictions)\n","  # print(original)\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["428c91525c4844e59ddeff451c4a8486","435413bcc4d94db994b802592c16fac6","b967b52432a64ac694e5d6815ec01e3e","f015dd9d71964426955f1dd77c0cf77c","eed952ee077f4db3986736a3cba1f1cb","04e838f2a20a4617add76799a187e5f5","f19f2b319e2d424cbb920beda75fb968","3819cfdb2b1045bf99459c39c8c760d6","2ed37459898e4f38938020a4d03d84f7","b3ff58c8d050420098faf1c7d6b8f5df","d1d67166fad0486e8585b802233da3bb","906565c9fc4f433997f9b13480dc7c5a","e61c9cfe1d0f4b1f816454673f6813bb","f3e634d21f5342eb8d2043a8bce0cbf3","b33cf5993fe64f7f9b4ed0209a872bee","3f52eae2ad644a3d95118aed1cd3ac95","b95c71092f6a4e33a9167973210aa0ef","205398264bf3470382d97412eb08fa89","f3c7f22f331d440dbbafed2845d5b421","f298e906fb6d4590bee5ebcfa662ac31","2757435761814c3cad7fa56aca612ae3","3d162d996f874601aba3b70153e4a664"]},"executionInfo":{"elapsed":21625,"status":"ok","timestamp":1657083374807,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"Hch1D-4gKYzw","outputId":"f3a437d2-642e-4d9b-96b5-1b36f6f106db"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"428c91525c4844e59ddeff451c4a8486","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"906565c9fc4f433997f9b13480dc7c5a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/404M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'classifier.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["class BertModel(torch.nn.Module):\n","    def __init__(self):\n","        super(BertModel, self).__init__()\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_id, mask, label):\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","        return output\n","\n","FILE = \"drive/MyDrive/AIBuilders/tpth/tagging_tpth_200.pth\"\n","tagging_model = BertModel()\n","tagging_model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","tagging_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s1F9A0EKdXH"},"outputs":[],"source":["ids_to_labels = {0: 'f', 1: 'i'}\n","\n","def evaluate_one_text(model, sentence, mask, labels):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    input_id = torch.Tensor([sentence]).type(torch.int64)\n","    label_ids = []\n","    for i in sentence:\n","      if i == 1 or i == 5 or i == 6:\n","        label_ids.append(-100)\n","      else:\n","        label_ids.append(2)\n","    label_ids = torch.Tensor([label_ids]).type(torch.int64)\n","    mask = torch.Tensor([mask]).type(torch.int64)\n","\n","    logits = tagging_model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    return prediction_label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2719806,"status":"ok","timestamp":1657088613550,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"7_bXYO6kxYjm","outputId":"a1fda1eb-b325-4910-a328-273d0d1a3125"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5000/5000 [45:18<00:00,  1.84it/s]"]},{"name":"stdout","output_type":"stream","text":["AVG ACC: 0.0019727217347858456\n","AVG f1: 0.0030288659576171734\n","# HIGHER BLEU PREDICTION: 103\n","# LOWER BLEU PREDICTION: 2099\n","# EQUAL BLEU PREDICTION: 2798\n","# GLEU PREDICTION: 0.8487772656839223\n","# GLEU ORIGINAL: 0.8660844114008937\n","# CER PREDICTION: 0.04070377522416636\n","# CER ORIGINAL: 0.03541724276517062\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["bleu = load_metric(\"bleu\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","# NUM_SAMPLE=10\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  mask = ds_mlm.iloc[i]['attention_mask']\n","  mask = [k for k in mask if k != 0]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","\n","  i_f = evaluate_one_text(tagging_model, text_id, mask, labels_id)\n","  # print(i_f)\n","  i_f_len = len(i_f)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  # print(f\"TEXT TOKEN: {text_token}\")\n","  for j in range(i_f_len):\n","    text_token[j+1] = text_token[j+1].replace(\"▁\", \" \")\n","    if(i_f[j] == 'i'):    \n","      try:\n","        corrected = correct(text_token[j+1])\n","      except:\n","        print(f\"err pythainlp: {text_token[j+1]}\")\n","      else:\n","        # print(f\"{text_token[j+1]} => {corrected}\")\n","        text_token[j+1] = corrected\n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  # print(references)\n","  # print(original)\n","  # print(predictions)\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-13VnG_xb4L"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"pythainlp_tpth.ipynb","provenance":[],"authorship_tag":"ABX9TyN481ypHDP4n7xvMKUVUh/b"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04e838f2a20a4617add76799a187e5f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205398264bf3470382d97412eb08fa89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2757435761814c3cad7fa56aca612ae3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed37459898e4f38938020a4d03d84f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3819cfdb2b1045bf99459c39c8c760d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d162d996f874601aba3b70153e4a664":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f52eae2ad644a3d95118aed1cd3ac95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"428c91525c4844e59ddeff451c4a8486":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_435413bcc4d94db994b802592c16fac6","IPY_MODEL_b967b52432a64ac694e5d6815ec01e3e","IPY_MODEL_f015dd9d71964426955f1dd77c0cf77c"],"layout":"IPY_MODEL_eed952ee077f4db3986736a3cba1f1cb"}},"435413bcc4d94db994b802592c16fac6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04e838f2a20a4617add76799a187e5f5","placeholder":"​","style":"IPY_MODEL_f19f2b319e2d424cbb920beda75fb968","value":"Downloading: 100%"}},"906565c9fc4f433997f9b13480dc7c5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e61c9cfe1d0f4b1f816454673f6813bb","IPY_MODEL_f3e634d21f5342eb8d2043a8bce0cbf3","IPY_MODEL_b33cf5993fe64f7f9b4ed0209a872bee"],"layout":"IPY_MODEL_3f52eae2ad644a3d95118aed1cd3ac95"}},"b33cf5993fe64f7f9b4ed0209a872bee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2757435761814c3cad7fa56aca612ae3","placeholder":"​","style":"IPY_MODEL_3d162d996f874601aba3b70153e4a664","value":" 404M/404M [00:12&lt;00:00, 38.5MB/s]"}},"b3ff58c8d050420098faf1c7d6b8f5df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b95c71092f6a4e33a9167973210aa0ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b967b52432a64ac694e5d6815ec01e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3819cfdb2b1045bf99459c39c8c760d6","max":546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ed37459898e4f38938020a4d03d84f7","value":546}},"d1d67166fad0486e8585b802233da3bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e61c9cfe1d0f4b1f816454673f6813bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b95c71092f6a4e33a9167973210aa0ef","placeholder":"​","style":"IPY_MODEL_205398264bf3470382d97412eb08fa89","value":"Downloading: 100%"}},"eed952ee077f4db3986736a3cba1f1cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f015dd9d71964426955f1dd77c0cf77c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3ff58c8d050420098faf1c7d6b8f5df","placeholder":"​","style":"IPY_MODEL_d1d67166fad0486e8585b802233da3bb","value":" 546/546 [00:00&lt;00:00, 13.4kB/s]"}},"f19f2b319e2d424cbb920beda75fb968":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f298e906fb6d4590bee5ebcfa662ac31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3c7f22f331d440dbbafed2845d5b421":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e634d21f5342eb8d2043a8bce0cbf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c7f22f331d440dbbafed2845d5b421","max":423498558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f298e906fb6d4590bee5ebcfa662ac31","value":423498558}},"1cd5b4cffce842abb1bfdf5903c7540f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eda96e6b3cd04e22a30508bb7c29f5b5","IPY_MODEL_8d3f86945b51433dbdb1c44205a887ef","IPY_MODEL_f3690f9d6954432eb11753acdcb51eb7"],"layout":"IPY_MODEL_83e778043b774a7a9b4bc682eb053091"}},"eda96e6b3cd04e22a30508bb7c29f5b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52201ce493524c29970323d79a75dad2","placeholder":"​","style":"IPY_MODEL_8635739f820d4555ae9804e7af8918d6","value":"Downloading: "}},"8d3f86945b51433dbdb1c44205a887ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_542a3e2bf1eb44e0950099250431ad7d","max":2488,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2893e03a2d474e0f9670a2bbc357d0af","value":2488}},"f3690f9d6954432eb11753acdcb51eb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9080c3ff4af4effab240970c54670fd","placeholder":"​","style":"IPY_MODEL_dc08118847da4d99a399099eb9fe71f4","value":" 6.08k/? [00:00&lt;00:00, 168kB/s]"}},"83e778043b774a7a9b4bc682eb053091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52201ce493524c29970323d79a75dad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8635739f820d4555ae9804e7af8918d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"542a3e2bf1eb44e0950099250431ad7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2893e03a2d474e0f9670a2bbc357d0af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9080c3ff4af4effab240970c54670fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc08118847da4d99a399099eb9fe71f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23199bfe6b6141699125d3d036450af7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6951280f6c2c4b3f8bc11e7872b1424f","IPY_MODEL_c01e52dd59764cd69c6ee366b213aacc","IPY_MODEL_e4b6fd7d9a5541ba8140ec93c3aa9ee8"],"layout":"IPY_MODEL_35ab324a0fa14299b98d1fdf36ef2c71"}},"6951280f6c2c4b3f8bc11e7872b1424f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26d71ec040424dbbbeb6975a77207228","placeholder":"​","style":"IPY_MODEL_396ca01c543e45ae95dcc997530800fd","value":"Downloading: "}},"c01e52dd59764cd69c6ee366b213aacc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf564205cee34b78a711c94a676879b6","max":1554,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b42553669aa845848330da115d08e8fd","value":1554}},"e4b6fd7d9a5541ba8140ec93c3aa9ee8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6a43f6f80ca4141a8dec971c923da49","placeholder":"​","style":"IPY_MODEL_4b12bbf4398e4010acd55d47bb0418d4","value":" 4.07k/? [00:00&lt;00:00, 135kB/s]"}},"35ab324a0fa14299b98d1fdf36ef2c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26d71ec040424dbbbeb6975a77207228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"396ca01c543e45ae95dcc997530800fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf564205cee34b78a711c94a676879b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42553669aa845848330da115d08e8fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6a43f6f80ca4141a8dec971c923da49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b12bbf4398e4010acd55d47bb0418d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2cb310fafde44838ed000ec0970aa9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7684105fb684e3d9288a609b1fdc6c5","IPY_MODEL_d884761ee5344e54b6456868c1dd8abf","IPY_MODEL_70cdc2f00f6944299c15a9e7d2ee0f0b"],"layout":"IPY_MODEL_075627e8e8de4cd79f1f63e2f0a9ba3d"}},"b7684105fb684e3d9288a609b1fdc6c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20b8329b7f0e4c4fa43dd4550286ef08","placeholder":"​","style":"IPY_MODEL_764aeb41fa7a4bfa9a17bbe7b0948237","value":"Downloading: "}},"d884761ee5344e54b6456868c1dd8abf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_256dabfeb58540e8a0f696ecc9524c70","max":1858,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ca5cce392a84116b6fb68e8963ac827","value":1858}},"70cdc2f00f6944299c15a9e7d2ee0f0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49d74c28915b4352b6856acd065eb2d9","placeholder":"​","style":"IPY_MODEL_125a609e42954578b382bab9a135f846","value":" 5.78k/? [00:00&lt;00:00, 165kB/s]"}},"075627e8e8de4cd79f1f63e2f0a9ba3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20b8329b7f0e4c4fa43dd4550286ef08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"764aeb41fa7a4bfa9a17bbe7b0948237":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"256dabfeb58540e8a0f696ecc9524c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ca5cce392a84116b6fb68e8963ac827":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49d74c28915b4352b6856acd065eb2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"125a609e42954578b382bab9a135f846":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}