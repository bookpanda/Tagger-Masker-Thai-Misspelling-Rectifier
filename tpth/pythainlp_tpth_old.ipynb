{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pythainlp_json.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM3zL7gZL/JtCipXlXQ0W7r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"metadata":{"id":"q-8jviuNMYEE","executionInfo":{"status":"ok","timestamp":1657004984308,"user_tz":-420,"elapsed":397,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install transformers==4.15.0 sentencepiece\n","!pip install datasets==1.17.0 \n","!pip install langid\n","!pip install jiwer\n","! pip install pythainlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xn4m_rzYuqaj","executionInfo":{"status":"ok","timestamp":1657005050047,"user_tz":-420,"elapsed":27728,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"c936f683-d2e3-43dc-f06a-bca9fb0faddf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.15.0 in /usr/local/lib/python3.7/dist-packages (4.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (0.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.11.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (0.0.53)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets==1.17.0 in /usr/local/lib/python3.7/dist-packages (1.17.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.8.1)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (6.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.21.6)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.70.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.11.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2022.5.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (3.0.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.17.0) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2022.6.15)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.7.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (2.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.17.0) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.17.0) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: langid in /usr/local/lib/python3.7/dist-packages (1.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from langid) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: python-Levenshtein==0.12.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pythainlp\n","  Downloading pythainlp-3.0.8-py3-none-any.whl (11.5 MB)\n","\u001b[K     |████████████████████████████████| 11.5 MB 5.0 MB/s \n","\u001b[?25hCollecting tinydb>=3.0\n","  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2022.6.15)\n","Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (4.1.1)\n","Installing collected packages: tinydb, pythainlp\n","Successfully installed pythainlp-3.0.8 tinydb-4.7.0\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import re\n","from transformers import AutoModelForMaskedLM, pipeline\n","from transformers import AutoTokenizer, BertForTokenClassification\n","from tqdm import tqdm \n","import pickle\n","from datasets import load_metric\n","import subprocess\n","import sys\n","import langid\n","from nltk.translate.gleu_score import sentence_gleu\n","from jiwer import cer\n","from pythainlp import correct"],"metadata":{"id":"HwW6pLJ8utnf","executionInfo":{"status":"ok","timestamp":1657005067762,"user_tz":-420,"elapsed":17719,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFJ1FnHXu0cJ","executionInfo":{"status":"ok","timestamp":1657005090657,"user_tz":-420,"elapsed":16996,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"e8f89a89-3420-4032-9cde-7f8b15e03b4a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["tokenizer = pickle.load(open('drive/MyDrive/AIBuilders/json/tokenizer_json_15k.pkl', 'rb'))"],"metadata":{"id":"3zPAmXetu6Vm","executionInfo":{"status":"ok","timestamp":1657005092146,"user_tz":-420,"elapsed":1493,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["ds_mlm = pickle.load(open('drive/MyDrive/AIBuilders/json/mlm_json_15k.pkl', 'rb'))\n","ds_tag = pickle.load(open('drive/MyDrive/AIBuilders/json/ner_json_15k.pkl', 'rb'))"],"metadata":{"id":"ADqbZe3vvH_Y","executionInfo":{"status":"ok","timestamp":1657005519454,"user_tz":-420,"elapsed":9347,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["ds_mlm = ds_mlm[10576:]\n","ds_tag = ds_tag[10576:]\n","NUM_SAMPLE = ds_mlm.shape[0]\n","NUM_SAMPLE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZWGtsN_QtU5","executionInfo":{"status":"ok","timestamp":1657005519455,"user_tz":-420,"elapsed":10,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"43fb4e1f-db9b-4d99-b90a-684c26e0799e"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["bleu = load_metric(\"bleu\")\n","glue = load_metric(\"glue\", \"mrpc\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","total_gs_ori = 0\n","total_gs_pred = 0\n","total_cer_ori = 0\n","total_cer_pred = 0\n","\n","# NUM_SAMPLE=10\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_id = [k for k in text_id if k != 1]\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  labels_id = [k for k in labels_id if k != 1]\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","  # print(text_id)\n","  # print(labels_id)\n","\n","  # print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(text_token_len):\n","    text_token[j] = text_token[j].replace(\"▁\", \" \")\n","    try:\n","      corrected = correct(text_token[j])\n","    except:\n","      print(f\"err pythainlp: {text_token[j]}\")\n","    else:\n","      # print(f\"{text_token[j]} => {corrected}\")\n","      text_token[j] = corrected\n","    \n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  # print(len(text_token), len(labels_token))\n","  # print(text_token)\n","  # print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  # print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  references[0][0] = [k.replace(\"▁\", \" \") for k in references[0][0]]\n","  original[0] = [k.replace(\"▁\", \" \") for k in original[0]]\n","  predictions[0] = [k.replace(\"▁\", \" \") for k in predictions[0]]\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","\n","  # print(references)\n","  # print(predictions)\n","  # print(original)\n","  gleu_score = sentence_gleu(references[0], predictions[0], min_len=1, max_len=4)\n","  total_gs_pred += gleu_score\n","  gleu_score_original = sentence_gleu(references[0], original[0], min_len=1, max_len=4)\n","  total_gs_ori += gleu_score_original\n","\n","  cer_text_ori = \"\".join(original[0])\n","  cer_text_pred = \"\".join(predictions[0])\n","  cer_text_ref = \"\".join(references[0][0])\n","  cer_text_ori = cer_text_ori.replace(\"_\", \"\")\n","  cer_text_ori = cer_text_ori.replace(\"▁\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"_\", \"\")\n","  cer_text_pred = cer_text_pred.replace(\"▁\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"_\", \"\")\n","  cer_text_ref = cer_text_ref.replace(\"▁\", \"\")\n","  # print(f\"ORI: {cer_text_ori}\")\n","  # print(f\"PRED: {cer_text_pred}\")\n","  # print(f\"REF: {cer_text_ref}\")\n","  cer_original = cer(cer_text_ori, cer_text_ref)\n","  total_cer_ori += cer_original\n","  cer_pred = cer(cer_text_pred, cer_text_ref)\n","  total_cer_pred += cer_pred\n","\n","  # print(f\"GLUE PREDICTED: {gleu_score}\")\n","  # print(f\"GLUE ORIGINAL: {gleu_score_original}\")\n","  # print(f\"CER PREDICTED: {cer_pred}\")\n","  # print(f\"CER ORIGINAL: {cer_original}\")\n","  # print(f\"ACC: {acc}\")\n","  # print(f\"f1: {f1}\")\n","  # print(f\"ORIGINAL : {bleu_original}\")\n","  # print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  # print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")\n","print(f\"# GLEU PREDICTION: {float(total_gs_pred/NUM_SAMPLE)}\")\n","print(f\"# GLEU ORIGINAL: {float(total_gs_ori/NUM_SAMPLE)}\")\n","print(f\"# CER PREDICTION: {float(total_cer_pred/NUM_SAMPLE)}\")\n","print(f\"# CER ORIGINAL: {float(total_cer_ori/NUM_SAMPLE)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gqz78W7p8KT","outputId":"ae49c4d5-1eb9-4c1f-b203-7c43317b8151"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 1985/5000 [1:22:27<2:51:15,  3.41s/it]"]}]},{"cell_type":"code","source":["class BertModel(torch.nn.Module):\n","    def __init__(self):\n","        super(BertModel, self).__init__()\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_id, mask, label):\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","        return output\n","\n","FILE = \"drive/MyDrive/AIBuilders/mlm/tagging_nova_75.pth\"\n","tagging_model = BertModel()\n","tagging_model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","tagging_model.eval()"],"metadata":{"id":"Hch1D-4gKYzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ids_to_labels = {0: 'f', 1: 'i'}\n","\n","def evaluate_one_text(model, sentence, mask, labels):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    input_id = torch.Tensor([sentence]).type(torch.int64)\n","    label_ids = []\n","    for i in sentence:\n","      if i == 1 or i == 5 or i == 6:\n","        label_ids.append(-100)\n","      else:\n","        label_ids.append(2)\n","    label_ids = torch.Tensor([label_ids]).type(torch.int64)\n","    mask = torch.Tensor([mask]).type(torch.int64)\n","\n","    logits = tagging_model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    return prediction_label"],"metadata":{"id":"5s1F9A0EKdXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleu = load_metric(\"bleu\")\n","totalacc = 0\n","bleu_higher = 0\n","bleu_lower = 0\n","bleu_equal = 0\n","total_f1 = 0\n","\n","for i in tqdm(range(NUM_SAMPLE)):\n","  text_id = ds_tag.iloc[i]['text']['input_ids'].squeeze(0).tolist()\n","  text_token = tokenizer.convert_ids_to_tokens(text_id)\n","  original_token = text_token.copy()\n","  text_token_len = len(text_token)\n","  original = [original_token]\n","  labels_id = ds_mlm.iloc[i]['labels']\n","  mask = ds_mlm.iloc[i]['attention_mask']\n","  labels_token = tokenizer.convert_ids_to_tokens(labels_id)\n","  references = [[labels_token]]\n","\n","  i_f = evaluate_one_text(tagging_model, text_id, mask, labels_id)\n","  print(i_f)\n","  i_f_len = len(i_f)\n","\n","  print(f\"NO. {i}, {''.join(text_token)}\")\n","\n","  for j in range(i_f_len):\n","    text_token[j+1] = text_token[j+1].replace(\"▁\", \" \")\n","    if(i_f[j] == 'i'):    \n","      if langid.classify(text_token[j+1])[0] == 'th':\n","        try:\n","          corrected = spell(text_token[j+1],\"th_TH\")\n","        except:\n","          print(f\"err hunspell: {text_token[j+1]}\")\n","        else:\n","          if not corrected == \"No Suggestions\":\n","            print(f\"{text_token[j+1]} => {corrected[0]}\")\n","            text_token[j+1] = corrected[0]\n","  predictions = [text_token]\n","  final = \"\".join(text_token)\n","  final = final.replace(\"▁\", \" \")\n","\n","  numer = 0\n","  denom = 0\n","  TP = 0\n","  FP = 0\n","  TN = 0\n","  FN = 0\n","  print(len(text_token), len(labels_token))\n","  print(text_token)\n","  print(labels_token)\n","  labels_len = len(labels_token)\n","  for i in range(labels_len):\n","    if not text_token[i] == original_token[i]: #change\n","      denom += 1\n","      if text_token[i] == labels_token[i]:\n","        numer += 1\n","        TP += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FP += 1\n","    elif text_token[i] == original_token[i]: #no change\n","      if text_token[i] == labels_token[i]:\n","        TN += 1\n","      elif not text_token[i] == labels_token[i]:\n","        FN += 1\n","  if denom == 0:\n","    acc = 0\n","  else:\n","    acc = float(numer)/float(denom)\n","  totalacc += acc\n","\n","  print(f\"TP:{TP}   TN:{TN}   FP:{FP}   FN:{FN}\")\n","  precision = float(TP) / float(TP+FP) if TP+FP > 0 else 0\n","  recall = float(TP) / float(TP+FN) if TP+FN > 0 else 0\n","  f1 = float(2*precision*recall) / float(precision + recall) if precision+recall > 0 else 0\n","  total_f1 += f1\n","\n","  bleu_original = bleu.compute(predictions=original, references=references)\n","  bleu_prediction = bleu.compute(predictions=predictions, references=references)\n","\n","  if bleu_prediction['bleu'] > bleu_original['bleu']:\n","    bleu_higher += 1\n","  elif bleu_prediction['bleu'] < bleu_original['bleu']:\n","    bleu_lower += 1\n","  elif bleu_prediction['bleu'] == bleu_original['bleu']:\n","    bleu_equal += 1\n","  \n","  print(f\"ACC: {acc}\")\n","  print(f\"f1: {f1}\")\n","  print(f\"ORIGINAL : {bleu_original}\")\n","  print(f\"PREDICTED: {bleu_prediction}\")\n","\n","  print(\"\\n-----------------------\")\n","print(f\"AVG ACC: {float(totalacc/NUM_SAMPLE)}\")\n","print(f\"AVG f1: {float(total_f1/NUM_SAMPLE)}\")\n","print(f\"# HIGHER BLEU PREDICTION: {bleu_higher}\")\n","print(f\"# LOWER BLEU PREDICTION: {bleu_lower}\")\n","print(f\"# EQUAL BLEU PREDICTION: {bleu_equal}\")"],"metadata":{"id":"7_bXYO6kxYjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"z-13VnG_xb4L"},"execution_count":null,"outputs":[]}]}