{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23619,"status":"ok","timestamp":1657074422707,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"PpEJQHrF5Byi","outputId":"be708137-606f-4950-ec2e-a5385a1af648"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 7.6 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 53.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 52.0 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 38.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=fdf0aa832c893150ed3af26f227e1c6081c4681521302c2a49fc6ce774ad18b5\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.15.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets==1.17.0\n","  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n","\u001b[K     |████████████████████████████████| 306 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (21.3)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 52.5 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.70.13)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.8.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.64.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.3.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (0.3.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 55.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.17.0) (6.0.1)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 46.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.17.0) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.17.0) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.17.0) (1.24.3)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 39.3 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 44.8 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.17.0) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.17.0) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.17.0) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.17.0) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["!pip install transformers==4.15.0 sentencepiece\n","!pip install datasets==1.17.0 "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22137,"status":"ok","timestamp":1657074444837,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"zHFzMIqvsJxU","outputId":"46378c6b-81f9-466c-ddbc-660197bf7952"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1657075123289,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"eGkmLjsmINUK"},"outputs":[],"source":["from transformers import AutoModelForMaskedLM, pipeline\n","from transformers import AutoTokenizer, BertForTokenClassification\n","import pandas as pd\n","from datasets import load_dataset, load_metric, Dataset, DatasetDict\n","import torch\n","import pickle\n","import numpy as np"]},{"cell_type":"code","source":["# tokenizer = AutoTokenizer.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', model_max_length=512)\n","tokenizer = pickle.load(open('drive/MyDrive/AIBuilders/tpth/tokenizer_40k_nova.pkl', 'rb'))"],"metadata":{"id":"MMoBbaxHwGPI","executionInfo":{"status":"ok","timestamp":1657074837080,"user_tz":-420,"elapsed":356996,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["amodel = AutoModelForMaskedLM.from_pretrained(\"bookpanda/wangchanberta-base-att-spm-uncased-masking\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867,"referenced_widgets":["2b26d67ee49144ddaa7a968b21fcb271","992cd38899fb4d72813f721af8f57bdb","f82d72f405d44a1c815b376d4515a517","9994d5a29d72462cae0f2326cf60d274","1923362afb0d40b991be93c9e7eb3445","9b5ac575d2444a2684332632f4729f7d","f349705a4ac64e49ae66eca3578da471","fc1e6fe15a504b338a933e5ba34edfd2","6c2c40222afc4cfa8447e274be0c0a5b","4ef5e4456549494e9af9590932a1468c","16b304b8dc9a4aff959455b52544d3ed","c9021b39802e4207b876b3948f95876a","8c54a043cdb1428fb786fb77a3fbb2b2","b6e9d7b4904346e9bc4a645fe7ecab27","e6c6aa874cf543cc9dbc89e8f7427711","483158b39ae64f45b9c7ebe2e3668944","b97cb4a64688484683f928ed02533661","a4628aef19674546b9d09a2cf3a38d30","1a696d82a3994743898e129e77f4f8e2","0d7899b54ebc4002a1e93b9c89de1024","e30c266bf2b543f4a89859b02a59a2ec","bd5439d9bf8242089a6378ef45d85b0d"]},"id":"BIamB4jjpPDd","executionInfo":{"status":"ok","timestamp":1655636863194,"user_tz":-420,"elapsed":33798,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"99765bbc-4164-4ce9-9bb5-bd2623080f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpeyypael4\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b26d67ee49144ddaa7a968b21fcb271"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","creating metadata file for /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","loading configuration file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8d67990c57ad7c9a377a717b9e6fb6fbe625876c4c9781b591c91d90df72749f.2557f0f732e8aaba8f91e0a2524d25837aa0e1facac5cfefcfdf204769c20fa8\n","Model config CamembertConfig {\n","  \"_name_or_path\": \"bookpanda/wangchanberta-base-att-spm-uncased-masking\",\n","  \"architectures\": [\n","    \"CamembertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"camembert\",\n","  \"num_attention_head\": 12,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 33660\n","}\n","\n","https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe_9clcso\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9021b39802e4207b876b3948f95876a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","creating metadata file for /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","loading weights file https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/46c75644854dc9aaf27b979f062443e93422a14381fbf8e1f6dcb519ec3ba566.6bf7aed09fc9af5c1beef4b0c4ec485fb5139cae7309b85b7d8e6c9f8bb66fe0\n","All model checkpoint weights were used when initializing CamembertForMaskedLM.\n","\n","All the weights of CamembertForMaskedLM were initialized from the model checkpoint at bookpanda/wangchanberta-base-att-spm-uncased-masking.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForMaskedLM for predictions without further training.\n"]}]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","model_checkpoint = \"airesearch/wangchanberta-base-att-spm-uncased\"\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# FILE = \"drive/MyDrive/AIBuilders/mlm_nova.pth\"\n","# model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","# model = model.to(device)\n","# model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["e8ac8455368841d48f0660f2d0a36d11","73199248dd7c4649b9036a4e5144f984","4dda7658cd94442392f451962804e5c8","561be4d0f7134b8997930618ab695308","5a6201fa23284b33b52a8631f4bb7ee8","3fbab4d9a16844e8977c464aa01489b9","8bdf847adc0340c09c2a1714044a2ee4","87550d9c39024046813be2c420f6df75","18ecece870844c2db0064c21b99ac21a","5f15683a0311469bbe76a597da2a1148","2478891c047849f385f6f2ce2879a3de","2f36c3d0cc5c4717a3265ec38d568b84","c733b357f9b948b2a22e1070c3a417ca","aeb2fb61f861476a84287ba061173c2a","9d8c1ace52b440e284519ee9ecdb23d8","d55e34a59a3444839bc1e5c95ab384e8","271c02bdab6148d09e23dd1423e5f69b","bcf70d0088374a0fa1ef594b41af8b8c","3449f1d0d2c34b7a919dee903f07ba5c","def2009383904daaa34dfa6afd25c8a4","311c508ba69642a4bfa7f6e5d95eb4fc","b6fc0998060c460aad53d8b441299933"]},"id":"g0gJa-IuwIrS","executionInfo":{"status":"ok","timestamp":1657074849963,"user_tz":-420,"elapsed":12886,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"919b3175-c222-427c-be95-cfdaf4094194"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ac8455368841d48f0660f2d0a36d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/404M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f36c3d0cc5c4717a3265ec38d568b84"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Embedding(33660, 768)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657074849963,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"HuRt6oooIT25","outputId":"e0ec3875-60f7-4274-b9a3-ce5c1dcf6ce3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CamembertForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(33660, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=33660, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"mmzS6fR27EPj"},"source":["# Data Prep"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_z4fISZnPbgK","executionInfo":{"status":"ok","timestamp":1657075147402,"user_tz":-420,"elapsed":3638,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"d5f28aee-da0d-45bb-db08-4a24b3227e22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               input_ids  \\\n","42885  [5, 10, 10508, 102, 32729, 2306, 15933, 368, 1...   \n","42886  [5, 10, 1417, 26, 10980, 36, 491, 612, 21, 200...   \n","42887  [5, 10, 25004, 25004, 25004, 25004, 10, 2004, ...   \n","42888  [5, 13276, 5948, 320, 1259, 88, 154, 5364, 33,...   \n","42889  [5, 10, 25004, 25004, 25004, 25004, 4350, 33, ...   \n","\n","                                          attention_mask  \\\n","42885  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","42886  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","42887  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","42888  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","42889  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","\n","                                                  labels  \n","42885  [5, 10, 10508, 102, 32729, 2306, 15933, 368, 1...  \n","42886  [5, 10, 1417, 26, 10980, 36, 491, 612, 21, 200...  \n","42887  [5, 10, 6850, 1448, 265, 265, 10, 2004, 10, 22...  \n","42888  [5, 13276, 5948, 320, 1259, 88, 154, 5364, 33,...  \n","42889  [5, 10, 20302, 265, 265, 265, 4350, 33, 17960,...  "],"text/html":["\n","  <div id=\"df-7fe62ebd-8f3f-47f6-ae11-b0a9ca711f2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42885</th>\n","      <td>[5, 10, 10508, 102, 32729, 2306, 15933, 368, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 10508, 102, 32729, 2306, 15933, 368, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>42886</th>\n","      <td>[5, 10, 1417, 26, 10980, 36, 491, 612, 21, 200...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 1417, 26, 10980, 36, 491, 612, 21, 200...</td>\n","    </tr>\n","    <tr>\n","      <th>42887</th>\n","      <td>[5, 10, 25004, 25004, 25004, 25004, 10, 2004, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 6850, 1448, 265, 265, 10, 2004, 10, 22...</td>\n","    </tr>\n","    <tr>\n","      <th>42888</th>\n","      <td>[5, 13276, 5948, 320, 1259, 88, 154, 5364, 33,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 13276, 5948, 320, 1259, 88, 154, 5364, 33,...</td>\n","    </tr>\n","    <tr>\n","      <th>42889</th>\n","      <td>[5, 10, 25004, 25004, 25004, 25004, 4350, 33, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 20302, 265, 265, 265, 4350, 33, 17960,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fe62ebd-8f3f-47f6-ae11-b0a9ca711f2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7fe62ebd-8f3f-47f6-ae11-b0a9ca711f2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7fe62ebd-8f3f-47f6-ae11-b0a9ca711f2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["df = pickle.load(open('drive/MyDrive/AIBuilders/tpth/mlm_ds_40k_nova.pkl', 'rb'))\n","df.tail()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657075147403,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"OvG-tIqcP5DS"},"outputs":[],"source":["df_test = df[37890:]\n","df = df[:37890]\n","df_train, df_val = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.9 * len(df))])"]},{"cell_type":"code","source":["df_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"4E3vnGl3X-av","executionInfo":{"status":"ok","timestamp":1657075161344,"user_tz":-420,"elapsed":376,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"71121e89-35f3-4d6b-8079-a04c02f5a96d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               input_ids  \\\n","37250  [5, 2700, 2432, 9892, 10, 89, 13348, 10, 1149,...   \n","27081  [5, 10, 13054, 48, 4174, 52, 381, 17, 26489, 1...   \n","14908  [5, 10, 2004, 12609, 3879, 1204, 3590, 4300, 1...   \n","9306   [5, 10, 1417, 25004, 25004, 145, 478, 1809, 25...   \n","33724  [5, 8690, 26983, 2168, 12504, 3162, 18958, 20,...   \n","...                                                  ...   \n","16850  [5, 10, 5168, 29429, 10, 182, 181, 6148, 5089,...   \n","6265   [5, 6936, 10, 74, 10, 551, 5492, 7630, 15207, ...   \n","11284  [5, 206, 303, 2570, 690, 43, 12639, 25004, 66,...   \n","860    [5, 10167, 1105, 11, 85, 723, 894, 25004, 2500...   \n","15795  [5, 10, 2635, 13746, 70, 474, 1199, 18583, 190...   \n","\n","                                          attention_mask  \\\n","37250  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","27081  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","14908  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","9306   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","33724  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","...                                                  ...   \n","16850  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","6265   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","11284  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","860    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","15795  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","\n","                                                  labels  \n","37250  [5, 2700, 2432, 9892, 10, 89, 13348, 10, 1149,...  \n","27081  [5, 10, 13054, 48, 4174, 52, 381, 17, 26489, 1...  \n","14908  [5, 10, 2004, 12609, 3879, 1204, 3590, 4300, 1...  \n","9306   [5, 10, 1417, 4618, 265, 145, 478, 1809, 627, ...  \n","33724  [5, 8690, 26983, 2168, 12504, 3162, 18958, 20,...  \n","...                                                  ...  \n","16850  [5, 10, 5168, 29429, 10, 182, 181, 6148, 5089,...  \n","6265   [5, 6936, 10, 74, 10, 551, 5492, 7630, 15207, ...  \n","11284  [5, 206, 303, 2570, 690, 43, 12639, 28469, 66,...  \n","860    [5, 10167, 1105, 11, 85, 723, 894, 881, 265, 5...  \n","15795  [5, 10, 2635, 13746, 70, 474, 1199, 18583, 190...  \n","\n","[3789 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8e95d98c-b1f6-47a4-b053-462c4f4d7703\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>37250</th>\n","      <td>[5, 2700, 2432, 9892, 10, 89, 13348, 10, 1149,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 2700, 2432, 9892, 10, 89, 13348, 10, 1149,...</td>\n","    </tr>\n","    <tr>\n","      <th>27081</th>\n","      <td>[5, 10, 13054, 48, 4174, 52, 381, 17, 26489, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 13054, 48, 4174, 52, 381, 17, 26489, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>14908</th>\n","      <td>[5, 10, 2004, 12609, 3879, 1204, 3590, 4300, 1...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 2004, 12609, 3879, 1204, 3590, 4300, 1...</td>\n","    </tr>\n","    <tr>\n","      <th>9306</th>\n","      <td>[5, 10, 1417, 25004, 25004, 145, 478, 1809, 25...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 1417, 4618, 265, 145, 478, 1809, 627, ...</td>\n","    </tr>\n","    <tr>\n","      <th>33724</th>\n","      <td>[5, 8690, 26983, 2168, 12504, 3162, 18958, 20,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 8690, 26983, 2168, 12504, 3162, 18958, 20,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>16850</th>\n","      <td>[5, 10, 5168, 29429, 10, 182, 181, 6148, 5089,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 5168, 29429, 10, 182, 181, 6148, 5089,...</td>\n","    </tr>\n","    <tr>\n","      <th>6265</th>\n","      <td>[5, 6936, 10, 74, 10, 551, 5492, 7630, 15207, ...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 6936, 10, 74, 10, 551, 5492, 7630, 15207, ...</td>\n","    </tr>\n","    <tr>\n","      <th>11284</th>\n","      <td>[5, 206, 303, 2570, 690, 43, 12639, 25004, 66,...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 206, 303, 2570, 690, 43, 12639, 28469, 66,...</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>[5, 10167, 1105, 11, 85, 723, 894, 25004, 2500...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10167, 1105, 11, 85, 723, 894, 881, 265, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>15795</th>\n","      <td>[5, 10, 2635, 13746, 70, 474, 1199, 18583, 190...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>[5, 10, 2635, 13746, 70, 474, 1199, 18583, 190...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3789 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e95d98c-b1f6-47a4-b053-462c4f4d7703')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8e95d98c-b1f6-47a4-b053-462c4f4d7703 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8e95d98c-b1f6-47a4-b053-462c4f4d7703');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1657075175038,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"GH_XtzsDziSz","outputId":"4145b876-f74f-4271-f56c-6f1891b69f6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 636, 6262, 8560, 50, 30987, 10, 61, 241, 320, 19708, 4837, 11605, 241, 223, 233, 542, 3665, 70, 52, 14431, 125, 6892, 900, 7589, 1309, 2647, 504, 10, 5688, 21, 2768, 87, 1137, 48, 1290, 2338, 25004, 36, 241, 8623, 12115, 751, 64, 10092, 627, 9743, 3203, 1120, 895, 3203, 8704, 7899, 313, 1241, 310, 155, 3031, 329, 504, 29, 5951, 14408, 694, 64, 25004, 895, 200, 149, 200, 1553, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[5, 636, 6262, 8560, 50, 30987, 10, 61, 241, 320, 19708, 4837, 11605, 241, 223, 233, 542, 3665, 70, 52, 14431, 125, 6892, 900, 7589, 1309, 2647, 504, 10, 5688, 21, 2768, 87, 1137, 48, 1290, 2338, 25013, 36, 241, 8623, 12115, 751, 64, 10092, 627, 9743, 3203, 1120, 895, 3203, 8704, 7899, 313, 1241, 310, 155, 3031, 329, 504, 29, 5951, 14408, 694, 64, 27306, 895, 200, 149, 200, 1553, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["print(df_train.iloc[0]['input_ids'])\n","print(df_train.iloc[0]['attention_mask'])\n","print(df_train.iloc[0]['labels'])"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"81tgzMQ7rxSn","executionInfo":{"status":"ok","timestamp":1657075206207,"user_tz":-420,"elapsed":4224,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["df_train = Dataset.from_pandas(df_train)\n","df_val = Dataset.from_pandas(df_val)\n","df_test = Dataset.from_pandas(df_test)"]},{"cell_type":"code","source":["df_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cluQcvq8YRnk","executionInfo":{"status":"ok","timestamp":1657075214580,"user_tz":-420,"elapsed":3,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"e6ee2324-d0b9-4934-8981-8153ac511cb9"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","    num_rows: 34101\n","})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","execution_count":22,"metadata":{"id":"rsq-Zs_Lq4tI","executionInfo":{"status":"ok","timestamp":1657075215890,"user_tz":-420,"elapsed":1,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["combined_dataset = DatasetDict({\n","    'train': df_train,\n","    'test': df_val,\n","    'valid': df_test})"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1657075218380,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"ExAkoSqJtYz5","outputId":"4fb3b4b6-d957-4516-d3d7-9aba23b65d97"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 34101\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels', '__index_level_0__'],\n","        num_rows: 3789\n","    })\n","    valid: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 5000\n","    })\n","})"]},"metadata":{},"execution_count":23}],"source":["combined_dataset"]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","import gc\n","del df\n","del df_train\n","del df_val\n","del df_test\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TTkmtu7YpEf","executionInfo":{"status":"ok","timestamp":1657075498479,"user_tz":-420,"elapsed":2227,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"fba5d132-260e-446d-a256-c43ea1302a36"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300,"referenced_widgets":["1d9d423114e54c76a62f93857f4fb907","3fa932eee2c446928577da370e3486e3","2f1b142a2de443269895073c044e5451","a53e566fb41e4fe884974a77ff55bf60","e8aa95073c114cee984395c3bc9971ad","6009c346a6a5428ab5813cbf0c38261a","6722571754414e69855ad5a9f720a531","d23b63a3b1e648c2802dcc7dbcfa9eca","8eedf24027f54a7c9011b27363593afa","3a50a7589c9145f2ba27dcd29d24027a","cfb69d3c7a874659b270156d398fe654","5f5faf084cd24c5188a90623fcc00942","1ac674fe236141ba99b69677113ee2d8","6800547c8b3045c9954671da60c2b27f"]},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657075221766,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"bTtMT49atGOM","outputId":"90ab16fa-c6aa-4883-b725-4cc61e45f3e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login() # เอาไว้โยนโมเดลขึ้น hugging face ได้เลย"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"dy-jAg11qvgl","executionInfo":{"status":"ok","timestamp":1657075236108,"user_tz":-420,"elapsed":341,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","batch_size = 16\n","# Show the training loss with every epoch\n","logging_steps = len(combined_dataset[\"train\"]) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-masking\",\n","    overwrite_output_dir=True,\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    push_to_hub=True,\n","    num_train_epochs = 3,\n","    fp16=True, # สำหรับคนใช้ GPU\n","    logging_steps=logging_steps,\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["c866c962c3a24de39bf6b7129d458cd0","90dba0e38339496298e32252bd647f8c","fc9b0998075a46b6a11a539eeb9f3ab6","cd49f54643fc4c10864ece4ec7393c79","67cbd73b57b240b2b7fe2fd03ad41576","932a55d9cc0e41d4830fec74b83eb91e","a6b4558440794227968c0ec42e07f47e","bcd51d0f06fb4a07922ac38f5837ed5c","7bc229d67ada416eb5039cbc5dcc13c8","50d57db13343458ba6a63d0e81c5016b","b6a5336264bf4ff3af0a2a97f2a956af","4195f528f4e44495b5d3d24bcae07c68","cad860b1c8f44a7b8cb24bf216cc6e1f","bd2691bb8cac40a5acf48df3b923157f","9bb531a98d7a4284a995cf55ad67d01e","09c3262b07a3421aaca62d25d3255a44","807e12cf58b648f68866422aa67d1dcc","a7c650811dc84b16a79b306a51f91e30","813a622fcdef47b984214a94a21b0e1a","145ae38b819c4ab4a788b352de7aba05","3691d1fd4ad24b93b10afe477e6ce826","e437e35cafd34ce891a874d938bec950","c497fa8567354d62989520ae75b2a6b7","ab9465d108e942248f169c72d0afc9de","2f7f2aeb288a4f0fbfdc4eac56992aa5","dfa4aeb57a0146ed98383066a29a969c","52de66499e91455d95c0db7daeae8d0a","1d39e3f61f77465795aac9a56a58432e","4d981603a62f4964963e7d21a577261d","c92bc2c45e234554a7f080a9130ce334","17c98b704cc4485f852a8b59184d1e4b","0eac03999d2f4a089b2749d05955476c","a0a603f815e5448eb4c0d0c307114455","5160a6066ea34b2fb104536a696437f5","86521028407241648716e0f902348123","ffca6f78eace4e758860a14d74de1876","069c5c9984404dd08e53b1822f109eda","63414368eb5345529288d3eb4a85d5ed","2eeaab69f5a44f2eb9e72896531bd074","7cfcba13712d47b38311bb015cf65457","36360d5501aa48bfb989c86c12a43630","f175547ce9a04f38b499d021b96dcc49","544221eb74634fa49bb02096d411bad6","77b56133a8cb418ab1246303f64ddfb8"]},"id":"-tCZDaN8s05p","executionInfo":{"status":"ok","timestamp":1657075477204,"user_tz":-420,"elapsed":198550,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"92cc0f41-90a5-4f74-ea97-002edfa7609a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking into local empty directory.\n"]},{"output_type":"display_data","data":{"text/plain":["Download file pytorch_model.bin:   0%|          | 3.47k/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c866c962c3a24de39bf6b7129d458cd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Download file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4195f528f4e44495b5d3d24bcae07c68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Clean file training_args.bin:  34%|###4      | 1.00k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c497fa8567354d62989520ae75b2a6b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Clean file pytorch_model.bin:   0%|          | 1.00k/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5160a6066ea34b2fb104536a696437f5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using amp half precision backend\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=combined_dataset[\"train\"],\n","    eval_dataset=combined_dataset[\"valid\"],\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7338374,"status":"ok","timestamp":1657090474434,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"QvLik2xbwl5C","outputId":"fd2e5bb5-bba1-4316-82bb-d76602b8b7b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `CamembertForMaskedLM.forward` and have been ignored: __index_level_0__.\n","***** Running training *****\n","  Num examples = 34101\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6396\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6396' max='6396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6396/6396 2:02:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.119400</td>\n","      <td>0.162915</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.119600</td>\n","      <td>0.162915</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.119300</td>\n","      <td>0.162915</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1000/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-1500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-1500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-2000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-2000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-2000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-2500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-2500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-2500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-3000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-3000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-3000/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-3500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-3500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-3500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-4000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-4000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-4000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-4500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-4500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-4500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-5000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-5000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-5000/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-5500\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-5500/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-5500/pytorch_model.bin\n","Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking/checkpoint-6000\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-6000/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/checkpoint-6000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 5000\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6396, training_loss=0.11944847424433633, metrics={'train_runtime': 7337.521, 'train_samples_per_second': 13.942, 'train_steps_per_second': 0.872, 'total_flos': 2.692762815825101e+16, 'train_loss': 0.11944847424433633, 'epoch': 3.0})"]},"metadata":{},"execution_count":30}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"vo42h-y6sRPx","executionInfo":{"status":"ok","timestamp":1657091061490,"user_tz":-420,"elapsed":2476,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[],"source":["FILE = \"/content/drive/MyDrive/AIBuilders/tpth/mlm_tpth_6.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["a81d4bc96f8449208265c0d8b50ce959","da1f26a0c43e49beb2deb9327aa5a07d","042230d6d0c842a4b9bd8302a799597e","645f2aac90b04e95817a1eddf6e8afff","db2b75a4c4054eae852505b76ac0f69b","eb4545e74f564cc294bf4e400ff737f1","058520ac5e8d4be09bc0b62405b94d0a","49848535c2094cd4ac4c79ce765fb046","66ffcfaad7614879bc63e5ca4beae83e","9981e2a9842041f9b590f5205794e73b","651237317ea84458b9623a92d026fe81","cea9a81e93d84955b85fe2a5a40675da","8d812b10c2b04d3fa215e66a7cff2cea","278047df951041bd90fdd5e5d3871490","dd7f3b4d7e2a4efd9ac073ec34ded50b","b0ffc3d3d9754712b4e87487d06e397a","7ef1c8bffcdd4b098c1dcae97f2d63ad","9f00dd09c3884b5ca16014ba7620f462","d01bdae0448749c29a0dc6bc11e16e42","64a5ac383e4742268a87fd1a815c119b","287e857523eb41e1b103f448e4e97cde","d3b3fa08164c49d19e31aa4a355d7f4c"]},"executionInfo":{"elapsed":353890,"status":"ok","timestamp":1655636768996,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"gWlP9YgBxEnu","outputId":"3e35af19-cf51-4d13-cf15-699274fadc4e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-masking\n","Configuration saved in wangchanberta-base-att-spm-uncased-masking/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-masking/pytorch_model.bin\n"]},{"output_type":"display_data","data":{"text/plain":["Upload file pytorch_model.bin:   0%|          | 3.34k/427M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81d4bc96f8449208265c0d8b50ce959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Upload file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea9a81e93d84955b85fe2a5a40675da"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   0ad3488..042aaa7  main -> main\n","\n","Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n","To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking\n","   042aaa7..d124223  main -> main\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-masking/commit/042aaa7a82de0ea8414ca4f8eb1e486c59978c17'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}],"source":["trainer.push_to_hub()# โยนขึ้น hugging face"]},{"cell_type":"code","source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"],"metadata":{"id":"crQST5D-xj_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","if use_cuda:\n","    model = model.cuda()\n","FILE = \"drive/MyDrive/AIBuilders/mlm/tagging_nova_75.pth\"\n","loaded_model = BertModel()\n","loaded_model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","loaded_model.eval()"],"metadata":{"id":"0Cz7bvztxoW7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655628677930,"user_tz":-420,"elapsed":8153,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"f184a44a-5526-42b1-d364-49bad07c5f15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'classifier.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ids_to_labels = {0: 'f', 1: 'i'}\n","\n","def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","        else:\n","            try:\n","              label_ids.append(2)\n","            except:\n","                label_ids.append(-100)\n","\n","        previous_word_idx = word_idx\n","    return label_ids\n","\n","def evaluate_one_text(model, sentence):\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n","\n","    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","\n","    logits = model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    return prediction_label"],"metadata":{"id":"u65GCzVvxu8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1655628697373,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"dStVnDt6x9Nu","outputId":"e67bb371-92c9-4e9e-ca0b-8e9aa2a1563e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'i', 'i', 'i']\n","['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>']\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลก<mask>ป่าวคับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอะป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรื อป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลก จริง ๆป่าวคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกอ๊ะป่าวคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิง<mask>คับ</s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<pad>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงไหมคับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง<s>คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิง_คับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงอะคับ</s>'\n","<s> ประเทศเราผลิตและส่งออกยา สูบเยอะสุดในโลกจิงป่าว<mask></s>\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวครับ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนี่</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าววะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวนะ</s>'\n","'>>> <s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกจิงป่าวเนี่ย</s>'\n","{'input_ids': [5, 10, 136, 88, 932, 13, 3789, 30987, 10, 5204, 485, 7773, 3774, 2916, 801, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","<s>▁ประเทศเราผลิตและส่งออกยา▁สูบเยอะสุดในโลกหรือ<pad>ครับ</s>\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","# if use_cuda:\n","#     model = model.cuda()\n","\n","text = \"ประเทศเราผลิตและส่งออกยาสูบเยอะสุดในโลกจิงป่าวคับ\"\n","ans = []\n","i_f = evaluate_one_text(loaded_model, text)\n","print(i_f)\n","a = tokenizer(text)\n","b = a['input_ids']\n","c = tokenizer.convert_ids_to_tokens(b)\n","print(c)\n","i_f_len = len(i_f)\n","for j in range(i_f_len):\n","  if(i_f[j] == 'i'):\n","    ph = a['input_ids'][j+1]\n","    a['input_ids'][j+1] = 25004\n","    print(tokenizer.decode(a['input_ids']))\n","    b = {'input_ids': torch.Tensor([a['input_ids']]).type(torch.int64).to(device), 'attention_mask': torch.Tensor([a['attention_mask']]).type(torch.int64).to(device)}\n","    token_logits = model(**b).logits\n","    mask_token_index = torch.where(b[\"input_ids\"] == tokenizer.mask_token_id)[1]\n","    mask_token_logits = token_logits[0, mask_token_index, :]\n","    top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n","    ans.append((j, top_5_tokens[0]))\n","    text = ''.join(tokenizer.convert_ids_to_tokens(a['input_ids']))\n","    for token in top_5_tokens:\n","        print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n","    a['input_ids'][j+1] = ph\n","\n","print(a)\n","for x,y in ans:\n","  a['input_ids'][x+1] = y\n","print(''.join(tokenizer.convert_ids_to_tokens(a['input_ids'])))"]},{"cell_type":"code","source":["asdsf = pd.read_csv(\"drive/MyDrive/AIBuilders/final.csv\")"],"metadata":{"id":"nX5csn56T5_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(100,200):\n","  print(asdsf.iloc[i]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjXdABefT9VQ","executionInfo":{"status":"ok","timestamp":1655631575823,"user_tz":-420,"elapsed":5,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"90f27851-af69-4253-bb21-261ca3a8ed78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ต้องลอง555\n","อยากได้เตาอบบาบีก้อน จะเอามาทำขนมให้ลูกๆ ไปทานเล่นระหว่างวันค่ะ เป็นแม่บ้านว่างๆ ก็จะสรรหาเมนูใหม่ๆ ตามยูทูปเอามาลองทำ มีลูกนี่แหละเป็นหนูทดลอง 555 เห็นเตาก้อนแล้วอยากทำขนมคุ๊กกี้อบมากเลยค่ะ เอาเป็นรูปซานต้ากับต้นคริสมาส ฝึกทันพอดีก่อนเทศกาลเลย ❤️❤️❤️❤️❤️\n","เกิน 50 ไม่ไป!\n","แฟชั่นไอส์แลนด์ วันที่3/12ค่า\n","ลดพิเศษเเต่ของน้อยไม่ค่อยเติม\n","ฮื้ออออ เค้าสับเพร่า เค้าสับเพร่าาาาา เค้าจ่ายเต็มมมมม แต่อร่อยเด้ออออ ฮื้อออ\n","ผ่านนิเทศไปก่อนนะ\n","ไปคนเดียวดีฝ่าา\n","สาขาเพลินนารี่ ถ้าไม่อยากขายก้อปิดเถอะคับ ดูแลไม่ดีแล้วพนง.ยังไม่มีจิตใจในการขายด้วย เวลา1ชม.กับหลายๆอย่างไม่ไหวคับ หาคนมาดูบ้างนะครับ\n","ขาดเลยละ55 ไฮเนเก้น พอๆๆ 2 ขวด 555\n","ลอรีอัล รีไวทัลลิฟท์ เดอร์มาลิฟท์เดย์ครีม 50กรัม/ไนท์ ครีม 50กรัม ได้รับคูปองส่วนลด จากราคาเต็ม 599 บาท ลด 120บาท เหลือ 479บาท ในโปรโมชั่น watsons Beauty in Summer (29 มี.ค.-25 เม.ย. 61)\n","แล้วโครงการอื่นล่ะ??? แสนสิริเตรียมแจงกรณีปัญหาผนังห้องชุดโครงการเดอะ เบส สุขุมวิท 77 พรุ่งนี้ หลังพบใช้โฟมเป็นวัสดุก่อผนัง”\n","มีซูชิหรอ\n","นิสสันโน๊ตครับ\n","ขอบพระคุณคร้าบ\n","ขอสำรองได้มั้ยอ่า\n","ตอนนอนใส่แบบสอดฟินไม่เลอะที่นอน ตอนเช้าแบบผ้าอนามัยทั่วไป แต่แบบนี้ก็น่าลองนะคะคงสะดวกกว่าเยอะ\n","ป๊า เค้าอยากกินน 😁😁\n","ไป อยากจังแล้วนิ\n","สมองไหลตลอด\n","แอดมินขอส่งเรื่องให้หัวหน้างานตรวจสอบการทำงานของพนักงานที่สาขาให้นะคะ และขอน้อมรับคำแนะนำของลูกค้า เพื่อส่งต่อไปยังหน่วยงานที่เกี่ยวข้องเพื่อการพัฒนาและปรับปรุงการบริการของเราให้ดียิ่งๆขึ้นไปนะคะ\n","ซื้อไร ชวนไปแดร๊กส์\n","การได้สั่งลาวันอาทิตย์ ด้วย Jameson Ginger & Lime สักแก้วนี่มันดีจริงๆ นะ ถ้าไม่เชื่อ ก็ลองทำตามดูได้! #JamesonThailand #TwiceAsSmooth\n","นี่นิสสันยังดูไม่ใหญ่อีกเหรอครับ..ส่วนตัวคิดว่ารถกระบะนิสันออกแบบดูเทอะทะกว่าค่ายอื่นในยุคเดียวกัน(แต่ดูตัวเลขแล้วก็ไม่ได้ใหญ่นะ)ถ้าเขาเดินเกมแบบค่ายเจ้าตลาดทั้ง2ค่ายหรือออกตัวเท่ๆแบบฟอร์ดน่าตะไปได้ดีกว่านี้(ฟอร์ดยังไม่ใข่แรปเตอร์นะแรปเตอร์ส่วนตัวว่าแรปเตอร์เป็นปิคอัพหรูน่าจะเฉพาะกลุ่มที่เงินถึงๆ)\n","(‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’) http://www.jiggaban.com/97024-get1025-4/ ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่... ‘GET 102.5’ ร่วมสร้างปรากฏการณ์เรืองแสงสุดยิ่งใหญ่ เอาใจคนรักสุขภาพ ใน ‘HONDA GET GLOW RUN’ ​กลับมาอีกครั้งกับงาน “HONDA GET GLOW RUN” มหกรรมวิ่งเรืองแสง ณ สะพานพระราม 8 ที่จัดโดย “คลื่น GET 102.5” บอกได้คำเดียวว่า ครั้งนี้จัดเต็มยิ่งใหญ่อลังการกว่าเดิม รวมพลนักวิ่งทั้งมืออาชีพ และมือสมัครเล่นกว่\n","กูตื่นเต้นมากกกกกกกกกกกกกกกกจะหมดเวลาปิดหีบแล้ววววอีกไม่กี่นาที\n","http://www.steam-engine.org/\n","ประเทศอื่นเขาสนับสนุนให้ใช้แทนบุหรี่จริง แต่ประเทศไทยมันยากหน่อยเพราะลงทุนสร้างโรงงานยาสูบใหม่ไปหลายร้อยล้าน\n","เลิกซื้อ หันมาขอเพื่อนสูบแทนใช่มั้ยครับ\n","แม้ว่า Nissan Maxima และ Murano ในปัจจุบันทำยอดขายดีขึ้นกว่ารุ่นเดิมแค่ระดับหนึ่ง แต่ในจีน Maxima กลับล้มเหลว Murano แค่พอไปได้ นี่อาจจะเป็นเหตุผลหลักที่ทำให้การปรับโฉม Minorchange ต้องดูสง่างามขึ้น\n","ชิ\n","หน้าพี่แบคตอนโดนเพื่อนลากไปตีคือกุวงวารมาก ฮือ หน้าแบบนี่กุต้องโดนเหรอ สติหลุดไปแล้ว5555555555555555555\n","เลือกได้ 2 ซุป และน้ำจิ้มท่านละ 1 รสชาติค่ะ ^^\n","มีโปรบุฟเฟต์หรือค่ะถึงวันที่เท่าไรค่ะ\n","นิสสันโน๊ต รถประหยัดน้ำมัน ราคาเบา ดีไซร์เลิศ ขับขี่ดีมากๆ ใครๆก้อชอบ มีหลายสีให้เลือกด้วยครับ\n","พลาดเพราะรีโว่นั่นแหละ\n","5555เดะบอกอีกทีสอบเสร็จก่อน\n","ดูข่าวที่ชวนปราศรัย เหมือนแกยังไม่รู้ว่า ทักษิณไม่ได้เป็นนายกแล้ว\n","ถ้าทำประตูเปิดเหมือนRX8 เจ้า CHR จะเป็นผู้บุกเบิกรถทรงนี้อย่างเต็มตัว..เพราะมันจะเข้ากับบุคลิกรถแคปทึบสปอร์ต..น่าเสียดาย\n","หิวพี่ก้อนอีกแล้ว\n","ก็ต้องไง จะใครละ\n","รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” เมื่อวันเสาร์ที่ 9 ธันวาคม 2560 รพ.กรุงเทพพัทยา จัด Workshop : ไขความลับสุขภาพดีด้วยเทคนิค “ชะลอวัย” ชวนคุณมาไขความลับชะลอวัย โดย พญ.พันธลี ชื่นสัมพันธ์ แพทย์สาขาเวชศาสตร์ชะลอวัย ด้านโภชนาการและเมตาบอลิสึม รพ.กรุงเทพพัทยา และ คุณวิสสุตา กฤติยานิธิ นักกำหนดอาหาร และทีมนักโภชนาการ รพ.กรุงเทพพัทยา มาให้ความรู้แก่ผู้ร่วมกิจกรรม รวมถึงการทำอาหารเมนูสุขภาพด้วยตัวเองแบบง่าย ๆ โดยมีการให้ความรู้ในหัวข้อ ดังนี้ • วิธีดูแลสุขภาพคุณผู้ชาย คุณผู้หญิงให้กลับมาดูหนุ่มสาวขึ้นอีกครั้ง • ลองเช็คสัญญาณความเสื่อม คุณเข้าสู่วัยทองก่อนวัยหรือไม่? • เคล็ดลับกายฟิต หุ่นเฟริ์มเหมือนตอนหนุ่มสาว • DIY : Menu Lunch Box กินชะลอวัย ป้องกันโรคภัย ห่างไกลความอ้วน โดยในเดือนธันวาคมนี้ รพ.กรุงเทพพัทยา ได้มีการจัดแพ็กเกจตรวจสุขภาพ ในชื่อ แพ็กเกจสุขภาพดีรับปีใหม่ 2561 ราคาประหยัด ให้กับผู้ใส่ใจสุขภาพได้เลือกซื้อแพ้กเกจตรวจสุขภาพเป็นของขวัญมอบให้กับคนที่ท่านรัก โดยสามารถสอบถามรายละเอียดของแพ็กเกจตรวจสุขภาพได้ที่ รพ.กรุงเทพพัทยา หรือ โทร. 0 3333 3333\n","มีลิปเมลินดาเบอร์03ไหมค่ะ\n","Ba hao 八號 บาร์จีนดีๆ ในซอยนานา เบียร์นุ่ม อาหารอร่อย นี่สั่ง Jian Bing กับเกี๊ยวเป็ดไป น้ำซอสคือดีมาก เป็นซิกเนเจอร์ของร้านเลย บรรยากาศร้านก็ดี ให้อารมณ์หว่องเข้ากับบรรยากาศในคืนฝนตก จะกลับไปอีกแน่นอน\n","พยามบอกเขาว่า ไอน้ำนะ ไม่ใช่ควัน\n","ไม่ทันและ...กุมาฮาจิบังและ\n","พาลูกหนูไปกินด้วย\n","ของหวาน ก็ฮันนี่โทส ของคาวก็บาบีก้อน\n","ศรีจันทร์คือชอบเนื้อรองพื้นมาก แต่แบบนุแพ้ ฮรือ\n","งานช้างงงงครัช!!! วันเสาร์ที่ 24/2/2561 พบกันที่ แตงโมทะเลเผา อาหารสด ดนตรีเพราะ เบียร์เย็นๆ...\n","พาไปกินหน่อยเจ้าค่ะ\n","งานแสงโสม\n","ผลการตรวจสอบไปสัมภาษณ์กับสแตนด์บาบีก้อนหน้าร้านนะครับ\n","พี่เพิ่งรู้ว่าร้านกอล์ฟ เดี๋ยวไปอุดหนุนบ้าง\n","14 เมษายนของทุกปี คือ วันครอบครัว ค่ะ #สวยกล้าทุกแสง #คู่หูท้าแดด #kmacosmetics\n","พี่โชคคคคคคค น้องทานเอ็มเคอยู่ เด๋วมาเล่นด้วยนะ\n","แพ้ผ้าอนามัยอีกแล้วควายจัด\n","- สำหรับร้าน MK Gold buffet ที่เปิดขายทุกวัน มีสองสาขาคือ - สาขาศาลาแดง - สาขาEsplanade รัชดา - สำหรับร้าน MK Gold buffet ที่เปิดขายเฉพาะวันจันทร์ - ศุกร์ มีรายชื่อสาขา ดังต่อไปนี้ 1.สาขาเอกมัย 2.สาขาเซ็นทรัล เวิล์ดค่ะ ^^\n","เด็กเอ๋ยเด็กดี ต้องกิน ดีกรี ลีโอ เหล้าขาว 🍻🍃😜🙊 #แคปชั่นคอวอยอ #แคปชั่นเสี่ยว #แคปชั่นอ่อย #แคปชั่นเด็ด #แคปชั่นน่ารัก #คำคม #แคปชั่นกวนตีน\n","เมื่อ “ปรากฏการณ์จันทร์เต็มดวง” ถูก “ตีความใหม่” โดย 3 ศิลปิน Duangrit x Dudesweet x Trimode กลายเป็นประสบการณ์ ‘The North Full Moon ปาร์ตี้แสงเหนือ’ เสมือนอยู่บนดวงจันทร์ เตรียมชมความล้ำและมันส์ จากมนุษย์พวกแรกที่ได้ไปถึง 18 พ.ย. นี้ #SangSom #RedefineFullMoon #TheNorthFullmoonParty\n","ทุกวันนี้รีโว่รอกโค่. ทำไวเเทกหงายได้ยังครับ 😝\n","งอนบาบีก้อนถึง2020\n","ก้อนมีรายละเอียดกาต้มน้ำเพิ่มเติมตามรูปนะคร้าบบ^^\n","รำ😑\n","หลอนจัดเลยครับ 55555\n","10 พย : ยโสธร 11 พย : หนองคายBike Week 15 พย : งานช้างสุรินทร์ 17: พย : ตะวันแดงพัทยา 18: พย : ลานเบียร์สิงห์ กบินทร์บุรี\n","กินไก่ KFC กับ เบียร์ช้าง ????\n","เออแบบอะไรก็ฮอตพอท!555\n","ใช้รุ่นนี้ไหมที่เขาจะเอามาทำแท็กซี่แทน..อัลติส\n","วันนี้นะ ที่ลานโตโยต้า คุณวาสี ถนนชัยภูมิ-บ้านเขว้า\n","แบรนด์sivannaมีของปลอมมั้ยคะ\n","มีเงินหรอ\n","รีเจนซี่ ตื่นสบายจริงเหรอ 555\n","ชาวกรุงตื่นเต้น รถบ้านสุดฮิป U Motel ที่ถูกเนรมิตขึ้นมาจาก U Beer #SleepWithU #UMotel อย่าลืมติดดาวเพจ https://www.facebook.com/UBeerThai/ เพื่อไม่พลาดเรื่องราวและกิจกรรม\n","safe series 2018 จาก netflix เรื่องเกี่ยวกับลูกสาวหายตัวไป พ่อเธอจึงออกตามหา เล่าเรื่องได้สูตรสำเร็จของนิยายฮาลาน โคเบนมาก การสืบต่อไปเรื่อยจนพบความจริง ที่ชอบก็คือแม่งเก่งที่ทำให้ทุกตัวละครน่าสงสัยไปหมดได้ ถือว่าเป็น 8ep ที่ไม่น่าเบื่อเลยสนุกมาก #ชิตพลรีวิว\n","บุหรี่ไฟฟ้านะ ไม่ใช่ยาบ้า มึงก้บ้า เกินไป\n","แต่งหน้าง่ายๆแต่กันน้ำขั้นสุด https://www.youtube.com/watch?v=Ywm0RT8Kqjo #แป้งเจ้านาง #แป้งพัฟเจ้านาง #Chaonangthailand #Chaonangthailandofficial #แป้งพัฟ #แป้ง #แป้งพัพถูกและดี #แป้งผสมกันแดดที่ดีที่สุดในยุค #แป้งผสมรองพื้น #แป้งพัฟคุมมัน #ลิปเจ้านาง #ลิปแมทเจ้านาง #ลิปแมท สอบถาม-สั่งซื้อ-สมัครตัวแทน โทร. 088-888-8888 📲Line : @chaonangth 📩Inbox : m.me/chaonangthailandofficial\n","น้อยใจแฟนหนุ่มมารับช้า ด.ญ.14 โดดสะพานลอยหวังฆ่าตัว อาการสาหัส\n","18.21น. ภูเก็ต เขต1 พลังประชารัฐ2,397 ประชาธิปัตย์1,818คะแนน ผลสังเกตการณ์นับคะแนนหน้าหน่วยจากอาสาสมัครTNN(อย่างไม่เป็นทางการ ) คลิก>https://www.tnnthailand.com/\n","หลังจากลบsocial media appทุกอันออกจากมือถือและตั้งกฏกับตัวเองไม่ให้เข้ามาเช็คอะไรทั้งสิ้น (ยกเว้น HBD เพื่อน พิมพ์ก่อนและเข้าโพส เวลาทั้งหมดห้ามเกิน 1 นาที) และตั้ง habit ใหม่คือทำโจทย์เลข ผลคือหลัง 30 วัน cognitive functioningดีขึ้นมาก คิดอะไรเร็ว งานเสร็จ เครียดน้อยลง หลับสบาย\n","แล้วตอนนี้มึงก็แดกอะไรไม่ได้เลยอ้อ\n","4x4 ไหมครับ รุ่นนี้\n","พี่ก้อนน่ารักมาก ยิ้มตลอดทาง กำลังใจและคู่คิดของกันและกันแท้ๆ\n","จันทร์ Shock โลก The Return คืนนี้ ดีเจโอ๊ต ปราโมทย์ เปิดบ้านต้อนรับดีเจคุณพ่อลูกหนึ่ง เจ็ม ณัฏฐ์ปวินท์ มาระเบิดความฮากับคำถามสุดช๊อกและของรางวัลสุดกวน 3-5 ทุ่มที่ EFM104.5 และชมสดพร้อมๆกันผ่าน Facebook Live & Youtube Live ลงทะเบียนเล่นเกมส์ได้แล้วตอนนี้ที่เบอร์ 02-222-2222 . สนับสนุนความ Shockkkkk โดย Centerpoint of Siam Square https://www.facebook.com/centerpointofsiamsquare BarBQ Plaza http://www.11street.co.th/store/MiniMallAction/getMiniMallHome.do?sellerHmpgUrl=barbqplaza MG http://mgcars.com/th/mg-models/mgzs/detail/overview รู้ใจดอทคอม https://www.roojai.com/ Traveloka https://www.traveloka.com/th-th/?utm_source=THFlightHotel&utm_medium=radio&utm_campaign=EOY-011117 CP https://www.facebook.com/dimsum.jadedragon/ Enchanter https://www.facebook.com/EnchanteurThailand/ #จันทร์ShockโลกTheReturn\n","ใจเยนนนน กูชักอ้วนใหญ่แล้ว\n","Civic ทุกรุ่นใช้ระบบกันสะเทือนหน้าแบบคอยล์สปริง ด้านหลังทอร์ชั่นบาร์พร้อมคอยล์สปริง เครื่องยนต์ยังคงใช้รหัส D และเพิ่มรุ่นใหม่ 1,500 ซีซี CVCC โดยในปี 1984 ได้เพิ่มรุ่นแรงรหัส Si สำหรับทำตลาดญี่ปุ่น ปรับปรุงระบบกันสะเทือน และใช้เครื่องยนต์ DOHC ZC ความจุ 1,600 ซีซี กำลังสูงสุด 130 แรงม้า ส่วนรุ่นที่ทำตลาดในสหรัฐอเมริกาในชื่อ Civic Si 3 ประตู และ CRX Si ใช้เครื่องยนต์หัวฉีด 12 วาล์ว กำลังสูงสุด 91 แรงม้า เดือนพฤศจิกายน 1984 ฮอนด้าเพิ่มระบบขับเคลื่อน 4 ล้อให้ Civic เป็นครั้งแรกในรุ่น Shuttle ช่วงแรกมีปุ่มกดสำหรับเข้า-ออกจากระบบขับเคลื่อน 4 ล้อที่เรียกว่า \"Realtime\" เพราะสามารถทำได้ขณะรถวิ่ง จากนั้นในเดือนกุมภาพันธ์ 1985 จึงเพิ่มรุ่น Quint Integra ตัวถังแฮทช์แบ็ก 3 ประตู ฐานล้อ 2,450 มิลลิเมตร และในเดือนพฤศจิกายน 1986 เพิ่มรุ่น 5 ประตูแฮทช์แบค พร้อมขยายขนาดฐานล้อเป็น 2,520 มม.\n","ไม่อยากกินลีโอ อยากกินฝรั่ง\n","ขี้มอไซไปไง ที่โฮมโปรมีจะไปปะละ ใจๆ5555หิวด้วย\n","Nissan X-trail ขับนิ่ม เสียงเงียบ สบาย คล่องตัว\n","Nissan Note. ดาวน์เท่าไรค่ะ\n","น่าสนใจค่ะMGเป็นรถที่ออกแบบเพื่อความปลอดภัยรูปแบบทรงสวยทันสมัย\n","กลับไปจัดเลย\n","พี่ต้าไง\n","ก้อมันจริงนิ\n","แนะนำให้เริ่มต้นจากการล้างหน้าด้วย Hada Labo Deep Clean & Pore Refining Face Wash โฟมสูตรอ่อนโยนที่จะช่วยลดความมันส่วนเกินเพื่อรูขุมขนกระชับนะคะ\n","นะ\n","เผยรถต้นแบบ Small Rs Concept ที่คาดว่าจะเป็น All New Honda Brio รุ่น RS\n","หนูอยากกินมากนะค่ะ ที่รัก 😗😗😗\n","อะไรคือความรัก.... . เตรียมตัวให้พร้อม แล้วมาพบกับคืนนี้ Stamp (เเสตมป์ อภิวัชร์) .... . ในวันพฤหัสบดีที่ 28 ธันวาคมนี้ที่ DND Ekkamai . •Ticket : . Pre-sale ราคาเพียง 400 บาท เท่านั้น !! Front Door: 500 บาท . 🍺First 250 people who come first will get FREE BEER (a bottle of Singha light each) . ติดต่อซื้อบัตรได้ทาง Line: @untoldproject Call :088-888-8888 IG & FB: @untoldproject.bkk . #DNDDoNotDisturb #DNDBoutiquePlayhouse #ChivasExtra #Singhalight #untoldproject\n","ขอเสียของบุหรี่ไฟฟ้าคือ...รัฐบาลขาดทุนจบ!!!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"U2r4sIe_UTID"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"mlm_tpth.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b26d67ee49144ddaa7a968b21fcb271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_992cd38899fb4d72813f721af8f57bdb","IPY_MODEL_f82d72f405d44a1c815b376d4515a517","IPY_MODEL_9994d5a29d72462cae0f2326cf60d274"],"layout":"IPY_MODEL_1923362afb0d40b991be93c9e7eb3445"}},"992cd38899fb4d72813f721af8f57bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5ac575d2444a2684332632f4729f7d","placeholder":"​","style":"IPY_MODEL_f349705a4ac64e49ae66eca3578da471","value":"Downloading: 100%"}},"f82d72f405d44a1c815b376d4515a517":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1e6fe15a504b338a933e5ba34edfd2","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c2c40222afc4cfa8447e274be0c0a5b","value":772}},"9994d5a29d72462cae0f2326cf60d274":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ef5e4456549494e9af9590932a1468c","placeholder":"​","style":"IPY_MODEL_16b304b8dc9a4aff959455b52544d3ed","value":" 772/772 [00:00&lt;00:00, 25.8kB/s]"}},"1923362afb0d40b991be93c9e7eb3445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b5ac575d2444a2684332632f4729f7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f349705a4ac64e49ae66eca3578da471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1e6fe15a504b338a933e5ba34edfd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2c40222afc4cfa8447e274be0c0a5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ef5e4456549494e9af9590932a1468c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b304b8dc9a4aff959455b52544d3ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9021b39802e4207b876b3948f95876a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c54a043cdb1428fb786fb77a3fbb2b2","IPY_MODEL_b6e9d7b4904346e9bc4a645fe7ecab27","IPY_MODEL_e6c6aa874cf543cc9dbc89e8f7427711"],"layout":"IPY_MODEL_483158b39ae64f45b9c7ebe2e3668944"}},"8c54a043cdb1428fb786fb77a3fbb2b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b97cb4a64688484683f928ed02533661","placeholder":"​","style":"IPY_MODEL_a4628aef19674546b9d09a2cf3a38d30","value":"Downloading: 100%"}},"b6e9d7b4904346e9bc4a645fe7ecab27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a696d82a3994743898e129e77f4f8e2","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d7899b54ebc4002a1e93b9c89de1024","value":447792171}},"e6c6aa874cf543cc9dbc89e8f7427711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e30c266bf2b543f4a89859b02a59a2ec","placeholder":"​","style":"IPY_MODEL_bd5439d9bf8242089a6378ef45d85b0d","value":" 427M/427M [00:28&lt;00:00, 18.0MB/s]"}},"483158b39ae64f45b9c7ebe2e3668944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97cb4a64688484683f928ed02533661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4628aef19674546b9d09a2cf3a38d30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a696d82a3994743898e129e77f4f8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d7899b54ebc4002a1e93b9c89de1024":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e30c266bf2b543f4a89859b02a59a2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5439d9bf8242089a6378ef45d85b0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a81d4bc96f8449208265c0d8b50ce959":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da1f26a0c43e49beb2deb9327aa5a07d","IPY_MODEL_042230d6d0c842a4b9bd8302a799597e","IPY_MODEL_645f2aac90b04e95817a1eddf6e8afff"],"layout":"IPY_MODEL_db2b75a4c4054eae852505b76ac0f69b"}},"da1f26a0c43e49beb2deb9327aa5a07d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4545e74f564cc294bf4e400ff737f1","placeholder":"​","style":"IPY_MODEL_058520ac5e8d4be09bc0b62405b94d0a","value":"Upload file pytorch_model.bin: 100%"}},"042230d6d0c842a4b9bd8302a799597e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49848535c2094cd4ac4c79ce765fb046","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66ffcfaad7614879bc63e5ca4beae83e","value":447792171}},"645f2aac90b04e95817a1eddf6e8afff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9981e2a9842041f9b590f5205794e73b","placeholder":"​","style":"IPY_MODEL_651237317ea84458b9623a92d026fe81","value":" 427M/427M [05:30&lt;00:00, 642kB/s]"}},"db2b75a4c4054eae852505b76ac0f69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4545e74f564cc294bf4e400ff737f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058520ac5e8d4be09bc0b62405b94d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49848535c2094cd4ac4c79ce765fb046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ffcfaad7614879bc63e5ca4beae83e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9981e2a9842041f9b590f5205794e73b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651237317ea84458b9623a92d026fe81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cea9a81e93d84955b85fe2a5a40675da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d812b10c2b04d3fa215e66a7cff2cea","IPY_MODEL_278047df951041bd90fdd5e5d3871490","IPY_MODEL_dd7f3b4d7e2a4efd9ac073ec34ded50b"],"layout":"IPY_MODEL_b0ffc3d3d9754712b4e87487d06e397a"}},"8d812b10c2b04d3fa215e66a7cff2cea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ef1c8bffcdd4b098c1dcae97f2d63ad","placeholder":"​","style":"IPY_MODEL_9f00dd09c3884b5ca16014ba7620f462","value":"Upload file training_args.bin: 100%"}},"278047df951041bd90fdd5e5d3871490":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01bdae0448749c29a0dc6bc11e16e42","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a5ac383e4742268a87fd1a815c119b","value":2991}},"dd7f3b4d7e2a4efd9ac073ec34ded50b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_287e857523eb41e1b103f448e4e97cde","placeholder":"​","style":"IPY_MODEL_d3b3fa08164c49d19e31aa4a355d7f4c","value":" 2.92k/2.92k [05:30&lt;?, ?B/s]"}},"b0ffc3d3d9754712b4e87487d06e397a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ef1c8bffcdd4b098c1dcae97f2d63ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f00dd09c3884b5ca16014ba7620f462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01bdae0448749c29a0dc6bc11e16e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a5ac383e4742268a87fd1a815c119b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"287e857523eb41e1b103f448e4e97cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b3fa08164c49d19e31aa4a355d7f4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8ac8455368841d48f0660f2d0a36d11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73199248dd7c4649b9036a4e5144f984","IPY_MODEL_4dda7658cd94442392f451962804e5c8","IPY_MODEL_561be4d0f7134b8997930618ab695308"],"layout":"IPY_MODEL_5a6201fa23284b33b52a8631f4bb7ee8"}},"73199248dd7c4649b9036a4e5144f984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fbab4d9a16844e8977c464aa01489b9","placeholder":"​","style":"IPY_MODEL_8bdf847adc0340c09c2a1714044a2ee4","value":"Downloading: 100%"}},"4dda7658cd94442392f451962804e5c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87550d9c39024046813be2c420f6df75","max":546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18ecece870844c2db0064c21b99ac21a","value":546}},"561be4d0f7134b8997930618ab695308":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f15683a0311469bbe76a597da2a1148","placeholder":"​","style":"IPY_MODEL_2478891c047849f385f6f2ce2879a3de","value":" 546/546 [00:00&lt;00:00, 16.3kB/s]"}},"5a6201fa23284b33b52a8631f4bb7ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fbab4d9a16844e8977c464aa01489b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bdf847adc0340c09c2a1714044a2ee4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87550d9c39024046813be2c420f6df75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18ecece870844c2db0064c21b99ac21a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f15683a0311469bbe76a597da2a1148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2478891c047849f385f6f2ce2879a3de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f36c3d0cc5c4717a3265ec38d568b84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c733b357f9b948b2a22e1070c3a417ca","IPY_MODEL_aeb2fb61f861476a84287ba061173c2a","IPY_MODEL_9d8c1ace52b440e284519ee9ecdb23d8"],"layout":"IPY_MODEL_d55e34a59a3444839bc1e5c95ab384e8"}},"c733b357f9b948b2a22e1070c3a417ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_271c02bdab6148d09e23dd1423e5f69b","placeholder":"​","style":"IPY_MODEL_bcf70d0088374a0fa1ef594b41af8b8c","value":"Downloading: 100%"}},"aeb2fb61f861476a84287ba061173c2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3449f1d0d2c34b7a919dee903f07ba5c","max":423498558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_def2009383904daaa34dfa6afd25c8a4","value":423498558}},"9d8c1ace52b440e284519ee9ecdb23d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_311c508ba69642a4bfa7f6e5d95eb4fc","placeholder":"​","style":"IPY_MODEL_b6fc0998060c460aad53d8b441299933","value":" 404M/404M [00:09&lt;00:00, 44.0MB/s]"}},"d55e34a59a3444839bc1e5c95ab384e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"271c02bdab6148d09e23dd1423e5f69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf70d0088374a0fa1ef594b41af8b8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3449f1d0d2c34b7a919dee903f07ba5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def2009383904daaa34dfa6afd25c8a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"311c508ba69642a4bfa7f6e5d95eb4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6fc0998060c460aad53d8b441299933":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d9d423114e54c76a62f93857f4fb907":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_3fa932eee2c446928577da370e3486e3","IPY_MODEL_2f1b142a2de443269895073c044e5451","IPY_MODEL_a53e566fb41e4fe884974a77ff55bf60","IPY_MODEL_e8aa95073c114cee984395c3bc9971ad"],"layout":"IPY_MODEL_6009c346a6a5428ab5813cbf0c38261a"}},"3fa932eee2c446928577da370e3486e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6722571754414e69855ad5a9f720a531","placeholder":"​","style":"IPY_MODEL_d23b63a3b1e648c2802dcc7dbcfa9eca","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"2f1b142a2de443269895073c044e5451":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_8eedf24027f54a7c9011b27363593afa","placeholder":"​","style":"IPY_MODEL_3a50a7589c9145f2ba27dcd29d24027a","value":""}},"a53e566fb41e4fe884974a77ff55bf60":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_cfb69d3c7a874659b270156d398fe654","style":"IPY_MODEL_5f5faf084cd24c5188a90623fcc00942","tooltip":""}},"e8aa95073c114cee984395c3bc9971ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac674fe236141ba99b69677113ee2d8","placeholder":"​","style":"IPY_MODEL_6800547c8b3045c9954671da60c2b27f","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"6009c346a6a5428ab5813cbf0c38261a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"6722571754414e69855ad5a9f720a531":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d23b63a3b1e648c2802dcc7dbcfa9eca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eedf24027f54a7c9011b27363593afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a50a7589c9145f2ba27dcd29d24027a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb69d3c7a874659b270156d398fe654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f5faf084cd24c5188a90623fcc00942":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"1ac674fe236141ba99b69677113ee2d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6800547c8b3045c9954671da60c2b27f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c866c962c3a24de39bf6b7129d458cd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90dba0e38339496298e32252bd647f8c","IPY_MODEL_fc9b0998075a46b6a11a539eeb9f3ab6","IPY_MODEL_cd49f54643fc4c10864ece4ec7393c79"],"layout":"IPY_MODEL_67cbd73b57b240b2b7fe2fd03ad41576"}},"90dba0e38339496298e32252bd647f8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_932a55d9cc0e41d4830fec74b83eb91e","placeholder":"​","style":"IPY_MODEL_a6b4558440794227968c0ec42e07f47e","value":"Download file pytorch_model.bin: 100%"}},"fc9b0998075a46b6a11a539eeb9f3ab6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcd51d0f06fb4a07922ac38f5837ed5c","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bc229d67ada416eb5039cbc5dcc13c8","value":447792171}},"cd49f54643fc4c10864ece4ec7393c79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d57db13343458ba6a63d0e81c5016b","placeholder":"​","style":"IPY_MODEL_b6a5336264bf4ff3af0a2a97f2a956af","value":" 427M/427M [02:54&lt;00:00, 189kB/s]"}},"67cbd73b57b240b2b7fe2fd03ad41576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"932a55d9cc0e41d4830fec74b83eb91e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6b4558440794227968c0ec42e07f47e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcd51d0f06fb4a07922ac38f5837ed5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc229d67ada416eb5039cbc5dcc13c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50d57db13343458ba6a63d0e81c5016b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a5336264bf4ff3af0a2a97f2a956af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4195f528f4e44495b5d3d24bcae07c68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cad860b1c8f44a7b8cb24bf216cc6e1f","IPY_MODEL_bd2691bb8cac40a5acf48df3b923157f","IPY_MODEL_9bb531a98d7a4284a995cf55ad67d01e"],"layout":"IPY_MODEL_09c3262b07a3421aaca62d25d3255a44"}},"cad860b1c8f44a7b8cb24bf216cc6e1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_807e12cf58b648f68866422aa67d1dcc","placeholder":"​","style":"IPY_MODEL_a7c650811dc84b16a79b306a51f91e30","value":"Download file training_args.bin: 100%"}},"bd2691bb8cac40a5acf48df3b923157f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_813a622fcdef47b984214a94a21b0e1a","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_145ae38b819c4ab4a788b352de7aba05","value":2991}},"9bb531a98d7a4284a995cf55ad67d01e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3691d1fd4ad24b93b10afe477e6ce826","placeholder":"​","style":"IPY_MODEL_e437e35cafd34ce891a874d938bec950","value":" 2.92k/2.92k [02:54&lt;?, ?B/s]"}},"09c3262b07a3421aaca62d25d3255a44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807e12cf58b648f68866422aa67d1dcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7c650811dc84b16a79b306a51f91e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813a622fcdef47b984214a94a21b0e1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"145ae38b819c4ab4a788b352de7aba05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3691d1fd4ad24b93b10afe477e6ce826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e437e35cafd34ce891a874d938bec950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c497fa8567354d62989520ae75b2a6b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab9465d108e942248f169c72d0afc9de","IPY_MODEL_2f7f2aeb288a4f0fbfdc4eac56992aa5","IPY_MODEL_dfa4aeb57a0146ed98383066a29a969c"],"layout":"IPY_MODEL_52de66499e91455d95c0db7daeae8d0a"}},"ab9465d108e942248f169c72d0afc9de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d39e3f61f77465795aac9a56a58432e","placeholder":"​","style":"IPY_MODEL_4d981603a62f4964963e7d21a577261d","value":"Clean file training_args.bin: 100%"}},"2f7f2aeb288a4f0fbfdc4eac56992aa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c92bc2c45e234554a7f080a9130ce334","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17c98b704cc4485f852a8b59184d1e4b","value":2991}},"dfa4aeb57a0146ed98383066a29a969c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eac03999d2f4a089b2749d05955476c","placeholder":"​","style":"IPY_MODEL_a0a603f815e5448eb4c0d0c307114455","value":" 2.92k/2.92k [02:54&lt;00:00, 11.3B/s]"}},"52de66499e91455d95c0db7daeae8d0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d39e3f61f77465795aac9a56a58432e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d981603a62f4964963e7d21a577261d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c92bc2c45e234554a7f080a9130ce334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c98b704cc4485f852a8b59184d1e4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eac03999d2f4a089b2749d05955476c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0a603f815e5448eb4c0d0c307114455":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5160a6066ea34b2fb104536a696437f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86521028407241648716e0f902348123","IPY_MODEL_ffca6f78eace4e758860a14d74de1876","IPY_MODEL_069c5c9984404dd08e53b1822f109eda"],"layout":"IPY_MODEL_63414368eb5345529288d3eb4a85d5ed"}},"86521028407241648716e0f902348123":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eeaab69f5a44f2eb9e72896531bd074","placeholder":"​","style":"IPY_MODEL_7cfcba13712d47b38311bb015cf65457","value":"Clean file pytorch_model.bin: 100%"}},"ffca6f78eace4e758860a14d74de1876":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36360d5501aa48bfb989c86c12a43630","max":447792171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f175547ce9a04f38b499d021b96dcc49","value":447792171}},"069c5c9984404dd08e53b1822f109eda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_544221eb74634fa49bb02096d411bad6","placeholder":"​","style":"IPY_MODEL_77b56133a8cb418ab1246303f64ddfb8","value":" 427M/427M [00:59&lt;00:00, 9.08MB/s]"}},"63414368eb5345529288d3eb4a85d5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eeaab69f5a44f2eb9e72896531bd074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cfcba13712d47b38311bb015cf65457":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36360d5501aa48bfb989c86c12a43630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f175547ce9a04f38b499d021b96dcc49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"544221eb74634fa49bb02096d411bad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77b56133a8cb418ab1246303f64ddfb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}