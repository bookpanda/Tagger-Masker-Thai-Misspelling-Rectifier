{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13038,"status":"ok","timestamp":1661922300658,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"IwEI9jZ9yb8G","outputId":"461bf8f1-b3fe-49ea-c09b-958ad186e8c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 14.7 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 52.8 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 62.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 67.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.12.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 70.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b69b4b41cf6b250cd64ffdaf0de9b46d43e16b9cc51dfab1783f85184d6ea718\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","Successfully installed huggingface-hub-0.9.1 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.10.3 transformers-4.15.0\n"]}],"source":["# BERT\n","!pip install transformers==4.15.0 sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2844,"status":"ok","timestamp":1661922303497,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"YbwI_6aWu49u"},"outputs":[],"source":["import pandas as pd\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch \n","import numpy as np\n","from transformers import BertTokenizerFast, BertForTokenClassification, AutoTokenizer\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torch.optim import SGD\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"rcSzaFGhvuna"},"source":["# Read CSV Data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167065,"status":"ok","timestamp":1661922470557,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"_S6FWxqDicRZ","outputId":"14a0ce10-1b8b-48b4-ae9c-58d8a16539af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22030,"status":"ok","timestamp":1661922492582,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"f8cnvMNLu7CO","outputId":"43d3367c-7e79-4891-c397-ad3f1b1d8cb9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    text  \\\n","42885  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","42886  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","42887  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","42888  {'input_ids': [[tensor(5), tensor(13276), tens...   \n","42889  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","\n","                                                  labels  \n","42885  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","42886  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","42887  [tensor(0), tensor(0), tensor(1), tensor(1), t...  \n","42888  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","42889  [tensor(0), tensor(0), tensor(1), tensor(1), t...  "],"text/html":["\n","  <div id=\"df-780e913a-41d6-43f9-9490-338554ccf7ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42885</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>42886</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>42887</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(1), tensor(1), t...</td>\n","    </tr>\n","    <tr>\n","      <th>42888</th>\n","      <td>{'input_ids': [[tensor(5), tensor(13276), tens...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>42889</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(1), tensor(1), t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-780e913a-41d6-43f9-9490-338554ccf7ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-780e913a-41d6-43f9-9490-338554ccf7ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-780e913a-41d6-43f9-9490-338554ccf7ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df = pickle.load(open('drive/MyDrive/AIBuilders/tpth/ner_ds_40k_nova.pkl', 'rb'))\n","df.tail()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1661922497074,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"HUdcW2Rbv-5d"},"outputs":[],"source":["df_test = df[37890:]\n","df = df[:37890]\n","df_train, df_val = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.9 * len(df))])"]},{"cell_type":"code","source":["print(len(df_train), len(df_val))"],"metadata":{"id":"B0ym4iwGTIDh","executionInfo":{"status":"ok","timestamp":1661922498527,"user_tz":-420,"elapsed":2,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"533176e0-d966-423f-c92d-0d66a69f0aa4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["34101 3789\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1657010111560,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"MzZEQxj94gwC","outputId":"e60cf6f8-8b1f-4480-96ae-ae48eb7c410c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    1,    1,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100])"]},"metadata":{},"execution_count":17}],"source":["df.iloc[0]['labels']"]},{"cell_type":"markdown","metadata":{"id":"mosLtuxwv2hm"},"source":["# Initialize Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdHlzKiIvyI-"},"outputs":[],"source":["tokenizer_th = pickle.load(open('drive/MyDrive/AIBuilders/tpth/tokenizer_40k_nova.pkl', 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"ZwRa6UmDv6g4"},"source":["# Create Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uz8ru0XEv0yd"},"outputs":[],"source":["class DataSequence(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        # lb = [i.split() for i in df['labels'].values.tolist()]\n","        # txt = df['text'].values.tolist()\n","        # self.texts = [tokenizer_th(str(i),\n","        #                        padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n","        # self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n","        self.texts = [df.iloc[i]['text'] for i in range(df.shape[0])]\n","        self.labels = [df.iloc[i]['labels'] for i in range(df.shape[0])]\n","\n","    def __len__(self):\n","\n","        return len(self.labels)\n","\n","    def get_batch_data(self, idx):\n","\n","        return self.texts[idx]\n","\n","    def get_batch_labels(self, idx):\n","\n","        return torch.LongTensor(self.labels[idx])\n","\n","    def __getitem__(self, idx):\n","\n","        batch_data = self.get_batch_data(idx)\n","        batch_labels = self.get_batch_labels(idx)\n","\n","        return batch_data, batch_labels\n"]},{"cell_type":"markdown","metadata":{"id":"BY7BgOzRwBeQ"},"source":["# Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3261,"status":"ok","timestamp":1656862294284,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"sDVQGS1YVZtn","outputId":"ed9fc3b3-1419-4c69-ac79-b3b584c415be"},"outputs":[{"data":{"text/plain":["({'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0]]),\n","  'input_ids': tensor([[    5,    10, 11254,    50, 30987,    10,    61,   234,   176,    20,\n","            2004,    83,  6080,  3287,    88,    70,    10, 11128,  3841,  5742,\n","            8235,  2417,   122,  5742, 13394,   437, 25372,    10,   153,  5540,\n","            2693, 26946,  2700,    23,  1063,   895,  5716,   674,   279, 10936,\n","              21,  2860, 30987,    10,    61,   780,  8685,    15,   185,  3206,\n","             169,   431, 30401,    10,   122, 10437,   207,   706,   202,    10,\n","            5464, 18962,   102, 32729,    10,  2663,   839,   700,   202,    10,\n","             883,    50, 30987,    10,    61,  1073, 10454,    70,    10, 29251,\n","              10,  5742,   165,     6,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1]])},\n"," tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100]))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["asdf = DataSequence(df_train)\n","asdf.__getitem__(1)"]},{"cell_type":"markdown","metadata":{"id":"N12N752nwGin"},"source":["# Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDSbpnWtwEmo"},"outputs":[],"source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer_th))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210,"referenced_widgets":["ac3ed02f64b34b8faba4eba2b7733a7a","a73ebf39547441468846fb754d7cbcbb","06c89f016a444e98a588620ad20bdbe2","874fd99c6bc24d8ebfe169932ccb226b","5be9b6d313224089abc3993e45c8c031","2859815c2a1242b8849efedb840c11ed","f34a3933d2a940a9badacfca81e7d30a","6242447021994c8fa5301c490d1c51bc","1609e2c779b04439a4cf23710ac7e4b7","72c39c3a0b2947b4ab31b108263169f6","72fd7b3aa8f243ecbdb2ac15486b97cb","339c029e150249ff868a2d1768dd52bf","2a112a5335f14d5daf8692e7b36eea3e","b578793d8916482d9ab95e661c3e4888","c3a888010b6b48c480f3e0bfa51819e1","06d1f1031fe04715aed3c61bae7f1414","d4e4095e536640af90fb8786af022b6f","f320b56cdb7446fbbb8c0b8573d4dc7b","18c15b4d75d542da8affa64f64484b02","cd1ecd4e88c645189512cca65dc76bc5","95618dc48baf44d69768ea8ddd57d5f4","d72ce03154364c7ca6c4e9fba259c4f2"]},"executionInfo":{"elapsed":11384,"status":"ok","timestamp":1657010604596,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"Epie4o66Reup","outputId":"7b4d1c56-597a-4425-f5cf-1746d8257064"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3ed02f64b34b8faba4eba2b7733a7a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/404M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"339c029e150249ff868a2d1768dd52bf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'lm_head.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.11.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'classifier.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'classifier.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertModel()\n","# model = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","# model.resize_token_embeddings(len(tokenizer_th))\n","\n","# FILE = \"drive/MyDrive/AIBuilders/tagging.pth\"\n","# FILE = \"drive/MyDrive/AIBuilders/tagging_nova_75.pth\"\n","# model.load_state_dict(torch.load(FILE, map_location=torch.device('cpu')))\n","# model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1655650258480,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"sqMWGt1MnH_w","outputId":"7bb2640f-705c-4d57-d681-d261b7569c04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login() # เอาไว้โยนโมเดลขึ้น hugging face ได้เลย"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1655651567919,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"vDm03Vdhopos","outputId":"c8a6b85a-17ab-4165-8961-005911abae32"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from transformers import TrainingArguments\n","\n","model_checkpoint = \"airesearch/wangchanberta-base-att-spm-uncased\"\n","\n","batch_size = 32\n","# Show the training loss with every epoch\n","logging_steps = len(df_train) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-tagging\",\n","    overwrite_output_dir=True,\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    push_to_hub=True,\n","    num_train_epochs = 75,\n","    fp16=True, # สำหรับคนใช้ GPU\n","    logging_steps=logging_steps,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6136,"status":"ok","timestamp":1655651574576,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"LbTQONglp2Su","outputId":"dc5801ce-a374-448d-d1ce-f6ac853af042"},"outputs":[{"name":"stderr","output_type":"stream","text":["/content/wangchanberta-base-att-spm-uncased-tagging is already a clone of https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-tagging. Make sure you pull the latest changes with `repo.git_pull()`.\n","Using amp half precision backend\n"]}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=df_train,\n","    eval_dataset=df_test,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["00fd55d320cc43daa84d9128f243e217","4f657ca9ea6f40d596e438a8397a6164","37c30ad614fa4d7e92f0f56c8d83e03e","41ba46ad8168442ba5c97804e64c537c","8150574dae9a4e8e9f01c943f81cf48a","91f2805cdea443579516a4fd448bcec5","deb791c8e7bc4b49be62c6bf8272cf21","b862d06dab204371b1d19697fee092a9","755dc07041ef41808382ce856b28c114","5c54bd59f2cc44d2a2a31690e03fbda4","a1ad8789a4324143a7a442c111b18a2a","d627bbabb1bb4e10b6cf745d65075366","53cfe0ced88745219f05407caceea7db","89fc3fa575f14c78a6f915cba663e665","c62c380001fe400bbf780d3a322a08a5","a7f6d4c051f249748a18b68cad564765","a525cda209b64daba6d85f4f75fc0e50","cd27b78f3b694baeaab64120681bedf3","8585b55f4bb44dce8cc5fba495d4c48d","5c9139ad997e4421bce56c88197e3dc5","fcb2a9558f4c457fb0402fec760dd7f3","fbe141af7c004fef9d04f410eb6901b7"]},"executionInfo":{"elapsed":417581,"status":"ok","timestamp":1655651996877,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"nlabWhS4n_Gf","outputId":"f8b869f4-8d49-4063-f6bb-2a2d2df40cd5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to wangchanberta-base-att-spm-uncased-tagging\n","Configuration saved in wangchanberta-base-att-spm-uncased-tagging/config.json\n","Model weights saved in wangchanberta-base-att-spm-uncased-tagging/pytorch_model.bin\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00fd55d320cc43daa84d9128f243e217","version_major":2,"version_minor":0},"text/plain":["Upload file pytorch_model.bin:   0%|          | 3.34k/425M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d627bbabb1bb4e10b6cf745d65075366","version_major":2,"version_minor":0},"text/plain":["Upload file training_args.bin: 100%|##########| 2.92k/2.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-tagging\n","   3c3ed19..daa973a  main -> main\n","\n","Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}}\n","To https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-tagging\n","   daa973a..712de4d  main -> main\n","\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'https://huggingface.co/bookpanda/wangchanberta-base-att-spm-uncased-tagging/commit/daa973a5e4f9d4068f6ffab57f3a3af8d9f1b64a'"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":637,"status":"ok","timestamp":1657010613041,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"emyGME48RA4a","outputId":"f0114227-63ee-4516-d0d3-b62703e75544"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":30}],"source":["model"]},{"cell_type":"markdown","metadata":{"id":"C6zDk8yQwLqq"},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0jSoWhNwJpN"},"outputs":[],"source":["BATCH_SIZE = 32\n","\n","def train_loop(model, df_train, df_val):\n","\n","    train_dataset = DataSequence(df_train)\n","    val_dataset = DataSequence(df_val)\n","\n","    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n","    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    best_acc = 0\n","    best_loss = 1000\n","    \n","    for epoch_num in range(EPOCHS):\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        model.train()\n","        \n","        for train_data, train_label in tqdm(train_dataloader):\n","            train_label = train_label[0].to(device)\n","            mask = train_data['attention_mask'][0].to(device)\n","            input_id = train_data['input_ids'][0].to(device)\n","            optimizer.zero_grad()\n","            loss, logits = model(input_id, mask, train_label)\n","\n","            logits_clean = logits[0][train_label != -100]\n","            label_clean = train_label[train_label != -100]\n","            predictions = logits_clean.argmax(dim=1)\n","            pred_len = len(predictions)\n","            for i in range(pred_len):\n","                if predictions[i] == 0:\n","                    predictions[i] = -100\n","            \n","            # print(predictions)\n","            # print(label_clean)\n","            numer = 0\n","            denom = 0\n","            for i in range(pred_len):\n","                if label_clean[i] == 1:\n","                    denom += 1\n","                    if predictions[i] == 1:\n","                        numer += 1\n","                elif label_clean[i] == 0 and predictions[i] == 1:\n","                    denom += 1\n","\n","            if denom == 0:\n","              acc = 0\n","            else:\n","              acc = float(numer)/float(denom)\n","            # print(f\"train acc: {acc}\")\n","            total_acc_train += acc * BATCH_SIZE\n","            total_loss_train += loss.item() * BATCH_SIZE\n","\n","            loss.backward()\n","            optimizer.step()\n","        \n","        model.eval()\n","\n","        total_acc_val = 0\n","        total_loss_val = 0\n","\n","        for val_data, val_label in val_dataloader:\n","\n","            val_label = val_label[0].to(device)\n","            mask = val_data['attention_mask'][0].to(device)\n","\n","            input_id = val_data['input_ids'][0].to(device)\n","\n","            loss, logits = model(input_id, mask, val_label)\n","\n","            logits_clean = logits[0][val_label != -100]\n","            label_clean = val_label[val_label != -100]\n","            predictions = logits_clean.argmax(dim=1)   \n","            pred_len = len(predictions)\n","            for i in range(pred_len):\n","                if predictions[i] == 0:\n","                    predictions[i] = -100       \n","\n","            numer = 0\n","            denom = 0\n","            for i in range(pred_len):\n","                if label_clean[i] == 1:\n","                    denom += 1\n","                    if predictions[i] == 1:\n","                        numer += 1\n","                elif label_clean[i] == 0 and predictions[i] == 1:\n","                    denom += 1\n","        \n","            if denom == 0:\n","              acc = 0\n","            else:\n","              acc = float(numer)/float(denom)\n","            # print(f\"valid acc: {acc}\")\n","            total_acc_val += acc * BATCH_SIZE\n","            total_loss_val += loss.item() * BATCH_SIZE\n","\n","        val_accuracy = total_acc_val / len(df_val)\n","        val_loss = total_loss_val / len(df_val)\n","\n","        print(\n","            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n","\n","LEARNING_RATE = 1e-3\n","EPOCHS = 100\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzqsWQ0xOXU1","outputId":"ee0cafe0-7aba-43d1-a906-af20700e2581","executionInfo":{"status":"ok","timestamp":1657039046284,"user_tz":-420,"elapsed":3224976,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 1066/1066 [02:09<00:00,  8.21it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 1 | Loss:  0.132 | Accuracy:  0.454 | Val_Loss:  0.138 | Accuracy:  0.479\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.18it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 2 | Loss:  0.134 | Accuracy:  0.459 | Val_Loss:  0.136 | Accuracy:  0.471\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 3 | Loss:  0.130 | Accuracy:  0.464 | Val_Loss:  0.140 | Accuracy:  0.457\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 4 | Loss:  0.131 | Accuracy:  0.476 | Val_Loss:  0.135 | Accuracy:  0.483\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.21it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 5 | Loss:  0.132 | Accuracy:  0.469 | Val_Loss:  0.137 | Accuracy:  0.465\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.17it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 6 | Loss:  0.133 | Accuracy:  0.470 | Val_Loss:  0.143 | Accuracy:  0.455\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 7 | Loss:  0.135 | Accuracy:  0.460 | Val_Loss:  0.135 | Accuracy:  0.479\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 8 | Loss:  0.133 | Accuracy:  0.458 | Val_Loss:  0.134 | Accuracy:  0.485\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 9 | Loss:  0.137 | Accuracy:  0.457 | Val_Loss:  0.134 | Accuracy:  0.505\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 10 | Loss:  0.136 | Accuracy:  0.467 | Val_Loss:  0.133 | Accuracy:  0.500\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 11 | Loss:  0.133 | Accuracy:  0.454 | Val_Loss:  0.134 | Accuracy:  0.477\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 12 | Loss:  0.133 | Accuracy:  0.472 | Val_Loss:  0.129 | Accuracy:  0.515\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 13 | Loss:  0.138 | Accuracy:  0.455 | Val_Loss:  0.134 | Accuracy:  0.475\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 14 | Loss:  0.128 | Accuracy:  0.463 | Val_Loss:  0.130 | Accuracy:  0.488\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 15 | Loss:  0.135 | Accuracy:  0.468 | Val_Loss:  0.132 | Accuracy:  0.491\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 16 | Loss:  0.135 | Accuracy:  0.453 | Val_Loss:  0.139 | Accuracy:  0.460\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 17 | Loss:  0.132 | Accuracy:  0.460 | Val_Loss:  0.133 | Accuracy:  0.478\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 18 | Loss:  0.136 | Accuracy:  0.463 | Val_Loss:  0.130 | Accuracy:  0.492\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 19 | Loss:  0.128 | Accuracy:  0.476 | Val_Loss:  0.133 | Accuracy:  0.496\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 20 | Loss:  0.137 | Accuracy:  0.457 | Val_Loss:  0.130 | Accuracy:  0.502\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 21 | Loss:  0.134 | Accuracy:  0.470 | Val_Loss:  0.136 | Accuracy:  0.484\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.20it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 22 | Loss:  0.133 | Accuracy:  0.468 | Val_Loss:  0.135 | Accuracy:  0.472\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 23 | Loss:  0.128 | Accuracy:  0.473 | Val_Loss:  0.142 | Accuracy:  0.452\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 24 | Loss:  0.130 | Accuracy:  0.466 | Val_Loss:  0.129 | Accuracy:  0.525\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 25 | Loss:  0.127 | Accuracy:  0.472 | Val_Loss:  0.130 | Accuracy:  0.509\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.19it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 26 | Loss:  0.129 | Accuracy:  0.467 | Val_Loss:  0.131 | Accuracy:  0.490\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 27 | Loss:  0.134 | Accuracy:  0.461 | Val_Loss:  0.128 | Accuracy:  0.504\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 28 | Loss:  0.132 | Accuracy:  0.455 | Val_Loss:  0.132 | Accuracy:  0.501\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.21it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 29 | Loss:  0.134 | Accuracy:  0.448 | Val_Loss:  0.129 | Accuracy:  0.499\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.18it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 30 | Loss:  0.130 | Accuracy:  0.475 | Val_Loss:  0.134 | Accuracy:  0.492\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:09<00:00,  8.22it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 31 | Loss:  0.131 | Accuracy:  0.473 | Val_Loss:  0.141 | Accuracy:  0.466\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:10<00:00,  8.14it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 32 | Loss:  0.135 | Accuracy:  0.468 | Val_Loss:  0.129 | Accuracy:  0.508\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.11it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 33 | Loss:  0.132 | Accuracy:  0.480 | Val_Loss:  0.128 | Accuracy:  0.510\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.09it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 34 | Loss:  0.132 | Accuracy:  0.467 | Val_Loss:  0.131 | Accuracy:  0.495\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.09it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 35 | Loss:  0.131 | Accuracy:  0.490 | Val_Loss:  0.128 | Accuracy:  0.524\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 36 | Loss:  0.131 | Accuracy:  0.468 | Val_Loss:  0.129 | Accuracy:  0.506\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 37 | Loss:  0.131 | Accuracy:  0.464 | Val_Loss:  0.129 | Accuracy:  0.502\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 38 | Loss:  0.129 | Accuracy:  0.475 | Val_Loss:  0.129 | Accuracy:  0.508\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 39 | Loss:  0.132 | Accuracy:  0.459 | Val_Loss:  0.132 | Accuracy:  0.503\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 40 | Loss:  0.130 | Accuracy:  0.475 | Val_Loss:  0.129 | Accuracy:  0.519\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 41 | Loss:  0.126 | Accuracy:  0.475 | Val_Loss:  0.127 | Accuracy:  0.525\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 42 | Loss:  0.130 | Accuracy:  0.484 | Val_Loss:  0.130 | Accuracy:  0.497\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 43 | Loss:  0.127 | Accuracy:  0.473 | Val_Loss:  0.129 | Accuracy:  0.513\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 44 | Loss:  0.133 | Accuracy:  0.469 | Val_Loss:  0.129 | Accuracy:  0.509\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 45 | Loss:  0.130 | Accuracy:  0.480 | Val_Loss:  0.128 | Accuracy:  0.527\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.04it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 46 | Loss:  0.132 | Accuracy:  0.475 | Val_Loss:  0.138 | Accuracy:  0.456\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 47 | Loss:  0.127 | Accuracy:  0.465 | Val_Loss:  0.136 | Accuracy:  0.467\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 48 | Loss:  0.124 | Accuracy:  0.475 | Val_Loss:  0.128 | Accuracy:  0.521\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 49 | Loss:  0.128 | Accuracy:  0.478 | Val_Loss:  0.135 | Accuracy:  0.472\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 50 | Loss:  0.130 | Accuracy:  0.482 | Val_Loss:  0.132 | Accuracy:  0.476\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 51 | Loss:  0.132 | Accuracy:  0.453 | Val_Loss:  0.128 | Accuracy:  0.504\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 52 | Loss:  0.132 | Accuracy:  0.478 | Val_Loss:  0.126 | Accuracy:  0.520\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 53 | Loss:  0.128 | Accuracy:  0.481 | Val_Loss:  0.128 | Accuracy:  0.530\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 54 | Loss:  0.128 | Accuracy:  0.492 | Val_Loss:  0.126 | Accuracy:  0.510\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 55 | Loss:  0.122 | Accuracy:  0.485 | Val_Loss:  0.136 | Accuracy:  0.462\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 56 | Loss:  0.127 | Accuracy:  0.483 | Val_Loss:  0.130 | Accuracy:  0.496\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 57 | Loss:  0.130 | Accuracy:  0.471 | Val_Loss:  0.129 | Accuracy:  0.506\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 58 | Loss:  0.129 | Accuracy:  0.453 | Val_Loss:  0.127 | Accuracy:  0.495\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 59 | Loss:  0.131 | Accuracy:  0.480 | Val_Loss:  0.127 | Accuracy:  0.514\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 60 | Loss:  0.122 | Accuracy:  0.477 | Val_Loss:  0.127 | Accuracy:  0.524\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 61 | Loss:  0.128 | Accuracy:  0.482 | Val_Loss:  0.126 | Accuracy:  0.528\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 62 | Loss:  0.122 | Accuracy:  0.489 | Val_Loss:  0.133 | Accuracy:  0.499\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 63 | Loss:  0.127 | Accuracy:  0.479 | Val_Loss:  0.126 | Accuracy:  0.514\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 64 | Loss:  0.128 | Accuracy:  0.481 | Val_Loss:  0.144 | Accuracy:  0.446\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 65 | Loss:  0.129 | Accuracy:  0.479 | Val_Loss:  0.131 | Accuracy:  0.477\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 66 | Loss:  0.126 | Accuracy:  0.488 | Val_Loss:  0.138 | Accuracy:  0.456\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.04it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 67 | Loss:  0.131 | Accuracy:  0.455 | Val_Loss:  0.129 | Accuracy:  0.502\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 68 | Loss:  0.124 | Accuracy:  0.493 | Val_Loss:  0.129 | Accuracy:  0.503\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 69 | Loss:  0.131 | Accuracy:  0.477 | Val_Loss:  0.127 | Accuracy:  0.511\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 70 | Loss:  0.125 | Accuracy:  0.474 | Val_Loss:  0.136 | Accuracy:  0.476\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.03it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 71 | Loss:  0.130 | Accuracy:  0.478 | Val_Loss:  0.127 | Accuracy:  0.516\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 72 | Loss:  0.124 | Accuracy:  0.488 | Val_Loss:  0.128 | Accuracy:  0.501\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 73 | Loss:  0.132 | Accuracy:  0.478 | Val_Loss:  0.130 | Accuracy:  0.541\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 74 | Loss:  0.127 | Accuracy:  0.476 | Val_Loss:  0.125 | Accuracy:  0.531\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 75 | Loss:  0.125 | Accuracy:  0.482 | Val_Loss:  0.125 | Accuracy:  0.517\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 1066/1066 [02:13<00:00,  8.01it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epochs: 76 | Loss:  0.128 | Accuracy:  0.480 | Val_Loss:  0.126 | Accuracy:  0.509\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 77 | Loss:  0.128 | Accuracy:  0.477 | Val_Loss:  0.127 | Accuracy:  0.500\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 78 | Loss:  0.131 | Accuracy:  0.484 | Val_Loss:  0.124 | Accuracy:  0.519\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 79 | Loss:  0.123 | Accuracy:  0.495 | Val_Loss:  0.130 | Accuracy:  0.503\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 80 | Loss:  0.126 | Accuracy:  0.492 | Val_Loss:  0.126 | Accuracy:  0.503\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 81 | Loss:  0.120 | Accuracy:  0.491 | Val_Loss:  0.128 | Accuracy:  0.534\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 82 | Loss:  0.129 | Accuracy:  0.484 | Val_Loss:  0.127 | Accuracy:  0.538\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 83 | Loss:  0.127 | Accuracy:  0.484 | Val_Loss:  0.124 | Accuracy:  0.520\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:13<00:00,  8.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 84 | Loss:  0.127 | Accuracy:  0.492 | Val_Loss:  0.125 | Accuracy:  0.506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 85 | Loss:  0.128 | Accuracy:  0.479 | Val_Loss:  0.124 | Accuracy:  0.535\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 86 | Loss:  0.127 | Accuracy:  0.474 | Val_Loss:  0.127 | Accuracy:  0.523\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 87 | Loss:  0.129 | Accuracy:  0.479 | Val_Loss:  0.124 | Accuracy:  0.527\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 88 | Loss:  0.126 | Accuracy:  0.476 | Val_Loss:  0.125 | Accuracy:  0.506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 89 | Loss:  0.126 | Accuracy:  0.490 | Val_Loss:  0.129 | Accuracy:  0.491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 90 | Loss:  0.130 | Accuracy:  0.500 | Val_Loss:  0.125 | Accuracy:  0.512\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 91 | Loss:  0.127 | Accuracy:  0.467 | Val_Loss:  0.129 | Accuracy:  0.509\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 92 | Loss:  0.121 | Accuracy:  0.491 | Val_Loss:  0.132 | Accuracy:  0.500\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 93 | Loss:  0.124 | Accuracy:  0.500 | Val_Loss:  0.125 | Accuracy:  0.507\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 94 | Loss:  0.124 | Accuracy:  0.477 | Val_Loss:  0.130 | Accuracy:  0.493\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 95 | Loss:  0.124 | Accuracy:  0.482 | Val_Loss:  0.125 | Accuracy:  0.515\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 96 | Loss:  0.127 | Accuracy:  0.480 | Val_Loss:  0.124 | Accuracy:  0.540\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:11<00:00,  8.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 97 | Loss:  0.122 | Accuracy:  0.490 | Val_Loss:  0.135 | Accuracy:  0.484\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 98 | Loss:  0.124 | Accuracy:  0.482 | Val_Loss:  0.124 | Accuracy:  0.513\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 99 | Loss:  0.124 | Accuracy:  0.495 | Val_Loss:  0.130 | Accuracy:  0.515\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [02:12<00:00,  8.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 100 | Loss:  0.124 | Accuracy:  0.490 | Val_Loss:  0.124 | Accuracy:  0.515\n"]}],"source":["train_loop(model, df_train, df_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvzoFdbk8duB"},"outputs":[],"source":["FILE = \"drive/MyDrive/AIBuilders/tagging_tpth_100.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0ebNG0yP9zU"},"outputs":[],"source":["train_loop(model, df_train, df_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXoMghwgP-no"},"outputs":[],"source":["FILE = \"drive/MyDrive/AIBuilders/tagging_tpth_200.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"markdown","metadata":{"id":"4wQtjsdlxrQH"},"source":["# Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2363,"status":"ok","timestamp":1655188124824,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"hYGHTi-cwPtA","outputId":"af2ed5a2-20be-4d32-b093-ee62b9a1fc39"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"name":"stdout","output_type":"stream","text":["input: <s>▁แต่ก่อนสนใจการเมืองเพราะเพื่อนพ่อเป็นสสเวลาฟัวดิเบตได้ความรู้แนวคิดคําคมแต่หลังจากไม่มีการเลือกตั้งไม่ได้ติดตามห่างหายจนปีนี้มีรู้สึกตื่นเต้นที่จะได้ฟังแง่คิดแต่ละคนมุมมอง#พรรคอนาคตใหม่คนรุ่นใหม่อยากหนีจากวงจรอุบาทของการเมือง▁อยากเห็น▁ประเทศไทยเดินหน้ามีกินมีใช้▁#ไทยรัฐเลือกตั้ง62</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","สส\n","ดิ\n","LABELS\n","สส\n","ฟั\n","ว\n","ดิ\n","เบ\n","ต\n","อุ\n","บาท\n","ACC: 0.25\n","-----------------------------------\n","input: <s>▁#จะรักใครก็รักไป▁เป็นนิยายการเมือง▁ปรัชญา▁ใครชอบนอ.ฟาดๆ▁ก็ควรโดนอยู่▁เก่งและฉลาด▁พอ.เหมือนหมารอเจ้าของแต่หมาดันดุนิดๆ▁ไม่เหมาะกับสายนิยายใสมากมีสาระเยอะ▁มีบางประโยคนํามาใช้ได้ในปัจจุบันด้วย▁ไม่ใช่หนังสือที่วางไม่ลง▁โทนเรื่องอ่านเรื่อยๆ▁ให้▁8/10▁พล็อตไม่มีช่วงพีคสุดเลย▁จบสุขนิยมจ้า</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","นอ\n","เรื่อยๆ\n","พีค\n","จ้า\n","LABELS\n","นอ\n",".\n","ฟาด\n","ๆ\n","พอ\n",".\n","นิดๆ\n","เรื่อยๆ\n","พีค\n","ACC: 0.3\n","-----------------------------------\n","input: <s>▁ขอบคุณทุกแรงสนับสนุนจากบ้านตาหวานทุกคนที่ช่วยผลักดันหวานให้ยืนมาถึงจุดๆ▁นี้▁เรายังรักหวานเสมอและจะคอยมองการเติบโตของหวานต่อไป▁อันดับที่▁11▁อาจไม่ใช่อันดับที่ดีที่สุดแต่ก็ไม่สูญเปล่ากับทุกคะแนนที่ทุ่มไป▁#ดีใจด้วยนะหวาน▁#bnk48▁#tarwaanbnk48▁at▁impact▁muang▁thong▁thani▁(อิมแพ็ค▁เมืองทองธานี)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","แพ็ค\n","LABELS\n","จุด\n","ๆ\n","ACC: 0.0\n","-----------------------------------\n","input: <s>▁#ตุ๊ดเข้าครัว▁วันนี้ขอพามาทานร้านห่านในตํานาน▁ฉั่ว▁คิม▁เฮง▁สาขาเลียบมอเตอร์เวย์▁ห่านพะโล้นุ่มๆ▁กับน้ําพะโล้รสเค็ม▁ต้มมะระตามสูตรของที่ร้าน▁ขมนิด▁หวานหน่อย▁ตับผัดต้นกระเทียม▁ตับนุ่มๆ▁ต้นกระเทียมกรอบๆ▁ข้าวสวยนึ่ง▁แข็งนิดๆเหมาะกับการราดน้ําห่านและทาน▁#ตุ๊ดแนะนํา▁#เจ๊คอนเฟิร์ม▁at▁ฉั่ว▁คิม▁เฮง▁ห่านพะโล้</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","มะ\n","นึ่ง\n","LABELS\n","นุ่ม\n","ๆ\n","นุ่ม\n","ๆ\n","กรอบ\n","ๆ\n","นิดๆ\n","ACC: 0.0\n","-----------------------------------\n","input: <s>▁อะโลฮ่า2!!!▁งานจับมือเดือนเมษาที่ผ่านมาเป็นครั้งแรกที่ได้คุยกับหนู▁เป็น8วิที่ฟินพอแล้วสําหรับพี่▁ขอบคุณที่เข้ามาเป็น1ใน▁bnk48▁นะคะ▁สุดท้ายขอให้หนูได้ทําในสิ่งที่รักต่อไปนานๆนะจ๊ะ▁#ขอบคุณทุกโปรเจ็คท์ที่ทําให้น้องด้วยค่ะ▁#jennisbnk48▁#jennishbd18th▁#เต็นเป็นสาวแล้ว▁at▁iberry▁garden▁(ไอเบอร์รี่▁การ์เด้น)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","โล\n","วิ\n","นานๆ\n","โปร\n","เจ็\n","ค\n","ท์\n","การ์\n","LABELS\n","อะ\n","โล\n","ฮ่า\n","เมษ\n","า\n","วิ\n","นานๆ\n","ACC: 0.25\n","-----------------------------------\n","input: <s>▁ส่วนแฟนเก่าเราไม่ได้เสียใจเลย▁อาจจะเหงาๆ▁แต่เราคบกันแค่▁3▁เดือนไม่ได้ผูกพันกันถึงต้องมานั่งเสียน้ําตา▁เพราะคงแค่ชอบ▁คงไม่ได้รักกันขนาดนั้น▁ทวีตไว้เตือนตัวเอง▁ถ้าวันนึงที่ต้องเจอแบบนี้อีก▁ก็ต้องรู้ทันความรู้สึก▁อย่าโง่▁คิดดีๆ▁#ขอบคุณที่เผื่อใจตัวเองไว้▁และวันนึงเราจะไม่เจอแบบนี้อีก</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ๆ\n","ทวีต\n","นึง\n","ดีๆ\n","นึง\n","LABELS\n","เหงา\n","ๆ\n","นึง\n","ดีๆ\n","นึง\n","ACC: 0.6666666666666666\n","-----------------------------------\n","input: <s>▁ก่อนเข้าบ้านไปห้างอีกรอบไปสํารวจมาทุกประตู▁ทุกจุด▁หนังรอบสุดท้ายจบหมด▁พี่รปภ.ปิดประตูแล้ว▁เคลียร์รถทุกชั้นแล้ว▁ถามมาจนสบายใจกลับบ้านมาอาบน้ํา▁นี่กําลังจะเข้านอนแวะมาเลื่อนทวิตสาดด▁ห้างกุคนจะอุปทานลุกไปต่อคิวกันตอนตี2ตี3มั้ยเนี่ย▁กระแสต่อคิวในทวิตโหดมาก▁รู้สึกไม่ปลอดภัย▁#nestival2018</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ชั้น\n","กุ\n","มั้ย\n","เนี่ย\n","LABELS\n","สาด\n","ด\n","กุ\n","มั้ย\n","ACC: 0.3333333333333333\n","-----------------------------------\n","input: <s>▁แล้วที่บอกว่าพ่อค้าแม่ค้าซื้อเอาไปเก็งก็จริงอยู่▁แต่ลองคิดดีๆ▁เรื่องเลือกตั้งนี่มันไม่ใช่เรื่องที่จะปุ้ปปั้ปทําได้เลย▁ของแบบนี้มันแทบจะเทเงินที่มีมาเปย์เลย▁พวกด้อมใหญ่น่าจะเตรียมนานแล้วๆตอนนี้มันถึงเวลา▁ส่วนใหญ่ที่ได้อาจจะไม่ใช่พ่อค้าแม่ค้าก็ได้▁#bnk48▁#bnk485thsingle▁#bnkfestival</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เก็\n","ดีๆ\n","ปุ\n","้\n","ปั\n","้\n","ๆ\n","LABELS\n","ดีๆ\n","ปุ\n","้\n","ป\n","ปั\n","้\n","ป\n","แล้ว\n","ๆ\n","ACC: 0.6\n","-----------------------------------\n","input: <s>▁กระแสดีขนาดนี้▁ดีงามทุกองค์ประกอบ▁ตั้งแต่นิยาย▁บทละคร▁เครื่องแต่งกาย▁เพลงประกอบ▁โลเกชั่น▁ซีจี▁คือดีงามทุกอย่าง▁อยากให้เรตติ้งพุ่งขึ้นทุกตอน▁ให้สมกับความสนุก▁มันส์หยดทุกep▁แบบลุกไปไหนไม่ได้▁ถึงพระเอกนางเอกจะยังเป็นดาวรุ่ง▁ยังไม่แมสมาก▁แต่ก็อยากเป็นกําลังใจให้ปังๆ▁#เพลิงพรางเทียนep5</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เก\n","ชั่น\n","เรตติ้ง\n","มันส์\n","แมส\n","LABELS\n","โล\n","เก\n","ชั่น\n","เรตติ้ง\n","มันส์\n","ปัง\n","ๆ\n","ACC: 0.5\n","-----------------------------------\n","input: <s>▁ตอนปี1เราก็เข้าพิธีบายศรีสู่ขวัญคณะ▁ตอนนั้นไอ้เราก็ดันปวดท้องน้อยๆก็เลยอาศัยช่วงพราหมณ์สวดดังๆตดออกไปดังปู๊ด!ไอ้สัสพราหมณ์หยุดสวดพอดิบพอดีแล้วคือนั่งวงกลมสามวงกูดันอยู่วงแรกทําไงล่ะทีนี่▁แกล้งหลับแม่งงง▁คนเชี้ยไรหลับแต่ตด▁ไอ้เพื่อนที่อยู่ข้างหลังกลั้นขํากันกิกิ▁#เรื่องมันช่างน่าอาย</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","บาย\n","น้อยๆ\n","ดังๆ\n","ู๊ด\n","สัส\n","ี้ย\n","ไร\n","LABELS\n","1\n","น้อยๆ\n","ดังๆ\n","สัส\n","ที\n","นี่\n","แม่ง\n","งง\n","เช\n","ี้ย\n","ไร\n","ACC: 0.38461538461538464\n","-----------------------------------\n","input: <s>▁เอาจริงๆ▁เห็นข่าว▁แต่งงาน▁lgbt▁ต่างชาติ▁แล้วก็คิดว่าในไทยก็ไม่น่ายากนะ▁แต่พอมาเจอพวกสันดานหมาดูถูก▁ส.ส.▁ของพรรคส้มแล้ว▁จริงๆเนี่ย▁การศึกษาไทยมันเหลื่อมล้ําจริงๆ▁เผลอคนในสภาก็ด้วย▁แค่ไม่แสดงออก▁ไม่ให้รู้หรอก▁เก็บคําพูดนี้ไว้▁ฝืนทําในสิ่งที่ยากจริงๆ▁สวนทางหัวใจ▁รักนะแต่ไม่จําเป็นหรอก..</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","LABELS\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","ACC: 1.0\n","-----------------------------------\n","input: <s>▁รีรันจ้าใกล้ถึงเวลาแล้วเริ่มเบรคสุดท้าย▁staff▁ถือเค้กและเริ่มร้องเพลง▁hbdหลังร้องเพลง▁hbdจบทางด้านหลังจะเริ่มชูไวนิลและสุดท้ายให้ร้องเพลง▁rebornส่งรินะหลังไลฟ์จบตอนตั้งแถวส่งน้อง▁เนื่องจากสตาฟบอกว่า▁เพลงเปิดไมไ่ด้และคนที่ตู้ปลาเสนอมาเพราะร้องกันไม่ได้จริงๆอันนี้ไฟนอลแล้วนะ▁#bnk48</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","จ้า\n","เบรค\n","ไม\n","ด้\n","จริงๆ\n","LABELS\n","จ้า\n","เบรค\n","สตาฟ\n","จริงๆ\n","ACC: 0.5\n","-----------------------------------\n","input: <s>▁แต่อยากรีวิวอันนี้มาก▁สั่งจากร้านเป็ดย่างน้ําผึ้ง▁ชื่อเมนูว่าหมูกรอบผัดกระเทียมแต่ว่านี่เพิ่มเป็ดด้วย▁ปกติจะเห็นร้านใช้คําว่าหมูทอดกระเทียมตอนแรกจินตนาการว่ามันคือหมูกระเทียมแบบร้านทั่วไป▁สรุปคือเป็นผัดใส่พริกขี้หนูอะ▁ผัดแห้งๆเค็มๆเผ็ดๆ▁ใส่กระเทียมเยอะๆ▁อร่อยมาก▁ไม่รู้จะชมยังไงละ▁at▁เป็ดย่างน้ําผึ้ง▁หลัง▁มช.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เยอะๆ\n","ยังไง\n","ละ\n","ม\n","LABELS\n","อะ\n","แห้ง\n","ๆ\n","เค็ม\n","ๆ\n","เผ็ด\n","ๆ\n","เยอะๆ\n","ACC: 0.09090909090909091\n","-----------------------------------\n","input: <s>▁จริง▁มันไม่ใช่เรื่องเหยียดไม่เหยียดผิวอะ▁มันคือเรื่องภาพลักษณ์ตัวละครที่เราจํามันมาแต่เด็ก▁หนังหรือละครที่สร้างมาจากนิยายยังพยายามอิงรูปลักษณ์ให้ตรงตามที่บรรยายในนิยายเลย▁นี่การ์ตูนที่มีภาพโชว์ให้เห็นชัดขนาดนี้มันก็ไม่ได้ปะ▁จะมาว่าคนอื่นเหยียดผิวอะไร▁ตลก▁แอเรียลนังผิวสีเมื่อไหร่อะ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ปะ\n","นัง\n","LABELS\n","ปะ\n","นัง\n","ACC: 1.0\n","-----------------------------------\n","input: <s>▁รีวิว▁#appwar▁by▁ข้ส▁เนื้อหาหนังแปลกดีนะ▁มันเหมาะกับทุกคนเลยแหละแต่คิดว่าคนที่สนใจด้านสตาร์ทอัพหรือกําลังทําอยู่น่าจะได้เข้าไปดู▁ตัวเอกแสดงลื่นดีนะ▁แต่เนื้อเรื่องท้ายๆมันยืดไปหน่อย▁ส่วน▁#ornbnk48▁ของน้อง▁หนังเรื่องแรกยังแอบฝืนไปนิดในฉากพีค▁แต่ตอนอื่นน่ารักจนยิ้มไม่หุบ▁ให้7/10อ่ะจ้า</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ข้\n","ส\n","สตาร์ท\n","อัพ\n","อ่ะ\n","จ้า\n","LABELS\n","ข้\n","ส\n","สตาร์ท\n","อัพ\n","ท้าย\n","ๆ\n","อ่ะ\n","ACC: 0.625\n","-----------------------------------\n","input: <s>▁รีวิว▁#thequake▁วินาศภัยแห่งแผ่นดินไหวในนอร์เวย์▁หนังสําหรับคนชอบสายภัยพิบัติ▁ให้▁6/10▁ที่มาของพล็อตเรื่องเยี่ยม▁ต้นเรื่องแอบเบื่อนิด▁กลางๆตื่นเต้น▁ท้ายๆหายนะ▁ภาพสวยcgระทึก▁ใจตัองแข็งนิดนึงก่อนมาดู▁ไม่ตายแต่ระหว่างทางมีจุดที่เจ็บปวดกับความเสียหายและสิ่งที่เกิดขึ้นโหดไป▁#movietwit▁at▁esplanade▁cineplex▁ratchadapisek▁(เอสพลานาด▁ซีนีเพล็กซ์▁รัชดาภิเษก)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ตั\n","นิดนึง\n","LABELS\n","กลางๆ\n","ท้าย\n","ๆ\n","ตั\n","อง\n","ACC: 0.16666666666666666\n","-----------------------------------\n","input: <s>▁เคยเดิน▁อยู่เจเจกรีน▁มีผญ.ข้างหน้ายื่นมือมาจับเฉย▁นี่ก็งง▁หันมองข้างหลังต่อเลย▁ใช่แน่ๆ▁ผัวนาง▁นี่ก็ยิ้มให้ผัวนาง▁อะแล้วยังไง▁เดินไปงี้ก็ไม่น่าใช่▁นี่ก็เลยตัดสินใจ▁สะบัดออก▁พอนางหันมาเจอเราก็ตกใจ▁แล้วแฟนนางก็คว้าตัวเดินไปต่ออย่างเร็ว▁#เรื่องมันช่างน่าอาย▁#จริงๆคนอายไม่น่าใช่กูด้วย</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ผญ\n","แน่ๆ\n","ยังไง\n","งี้\n","จริงๆ\n","LABELS\n","ผญ\n",".\n","แน่ๆ\n","ACC: 0.3333333333333333\n","-----------------------------------\n","input: <s>▁เราก็ยิ้มรับนะเราคิดว่ายังไงก็คือบ้าน▁ภาษาแรกที่เกิดมาก็ภาษานี้▁ที่แรกที่เกิดก็ที่นี่▁ไม่ว่าจะมีคนกี่คนที่นิสัยยังไง▁โกงเลวยังไง▁เราคิดว่าเรายังมีทัศนคติที่ดีต่อประเทศอ่ะ▁เวลาเราออกความคิดเห็นในด้านการเมืองเราไม่อยากพูดว่าประเทศไทยแม่งล้าหลังไม่มีวันพัฒนาหรอก▁แต่จะพูดถึงคนๆไปต่อ-</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ยังไง\n","ยังไง\n","อ่ะ\n","LABELS\n","อ่ะ\n","คน\n","ๆ\n","ACC: 0.2\n","-----------------------------------\n","input: <s>▁คือผู้บริโภคสมัยนี้ถูกชักจูงกันง่ายเพราะกูรูต่างๆจริงเหรอคะ▁อ่ะยอมรับส่วนนึงก็ได้▁เพราะมาจากรีวิว▁รีวิวเสร็จ▁คนมีความต้องการอยากใช้ตาม▁ไปซื้อมาใช้...สรุปสภาพผิวคนเราไม่เหมือนกัน▁บางคนใช้ดีไม่ดี▁ใช้ครั้งแรกก็รู้แล้วค่ะ▁คนใช่ดีเขาก็อาจกลับไปซื้อซ้ํา▁แต่คนใช้ไม่ถูก..ก็ครั้งเดียวจบป่ะ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ต่างๆ\n","อ่ะ\n","ป่ะ\n","LABELS\n","ต่างๆ\n","อ่ะ\n","ส่วนนึง\n","ใช่\n","ป่ะ\n","ACC: 0.6\n","-----------------------------------\n","input: <s>▁don▁don▁donki▁จากญี่ปุ่น▁เปิดแล้วที่ทองหล่อ▁ซ.10▁-22กุมภาที่ผ่านมา▁น้องไปมาวันนี้▁คนเยอะมากๆ▁ไฮไลท์ที่นี่คือเนื้อ▁เนื้อ▁เนื้อ!▁มีทั้งถูกและแพง▁แพงสุดกิโลละ▁5,990.-▁มีเนื้อ▁kobe▁และ▁saga▁คนรักเนื้อไม่ควรพลาด!!▁#bonappetitbkk▁#อร่อยไปแดก▁#อร่อยนะรู้ยัง▁#อร่อยบอกต่อ▁#รีวิว▁aroii▁at▁don▁don▁donki▁(ดอง▁ดอง▁ดองกิ)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","มากๆ\n","ไฮไลท์\n","กิโล\n","LABELS\n","กุมภ\n","า\n","มากๆ\n","ACC: 0.2\n","-----------------------------------\n","Test Accuracy:  0.400\n"]}],"source":["def evaluate(model, df_test):\n","\n","    test_dataset = DataSequence(df_test)\n","\n","    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    total_acc_test = 0.0\n","\n","    cou = 0\n","    for test_data, test_label in test_dataloader:\n","        if cou == 20:\n","            break\n","        cou+=1\n","\n","        test_label = test_label[0].to(device)\n","        mask = test_data['attention_mask'][0].to(device)\n","        input_id = test_data['input_ids'][0].to(device)\n","          \n","        loss, logits = model(input_id, mask, test_label.long())\n","        # print(test_data)\n","        # print(test_label)\n","        # print(loss)\n","        # print(logits)\n","\n","        logits_clean = logits[0][test_label != -100]\n","        label_clean = test_label[test_label != -100]\n","        predictions = logits_clean.argmax(dim=1)\n","        pred_len = len(predictions)\n","        for i in range(pred_len):\n","            if predictions[i] == 0:\n","                predictions[i] = -100\n","        # print(logits_clean)\n","        # print(label_clean)\n","        # print(predictions)\n","\n","  \n","        a = tokenizer_th.convert_ids_to_tokens(input_id.squeeze())\n","        print(f\"input: {''.join(a)}\")\n","        # print(label_clean)\n","        # print(len(input_id[0]), len(label_clean))\n","        # print(\"________________________\")\n","\n","        ids_to_labels = {0:'f', 1:'i', -100:'f'}\n","        prediction_label = [ids_to_labels[i] for i in predictions.tolist()]\n","        print(\"PREDICTIONS\")\n","        for i in range(len(predictions)):\n","          if prediction_label[i] == 'i':\n","            print(a[i])\n","        print(\"LABELS\")\n","        for i in range(len(label_clean)):\n","          if label_clean[i] == 1:\n","            print(a[i])   \n","\n","        # acc = (predictions == label_clean).float().mean()\n","\n","        numer = 0\n","        denom = 0\n","        for i in range(pred_len):\n","            if label_clean[i] == 1:\n","                denom += 1\n","                if predictions[i] == 1:\n","                    numer += 1\n","            elif label_clean[i] == 0 and predictions[i] == 1:\n","                denom += 1\n","        \n","        acc = float(numer)/float(denom)\n","        print(f\"ACC: {acc}\")\n","        print(\"-----------------------------------\")\n","        total_acc_test += acc\n","\n","    val_accuracy = total_acc_test / len(df_test)\n","    # print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n","    print(f'Test Accuracy: {total_acc_test / cou: .3f}')\n","\n","\n","evaluate(model, df_test)"]},{"cell_type":"markdown","metadata":{"id":"EyK8C2_fxvk6"},"source":["# Predict One Sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1655188472122,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"T99Q2GKQxtzK","outputId":"7029341a-d823-428f-aff2-b883a207b02f"},"outputs":[{"name":"stdout","output_type":"stream","text":["ids_to_tokens: ['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'i', 'i', 'i']\n","['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","สุดในโลก จิง ป่าว\n","จิง ป่าว คับ\n","ป่าว คับ </s>\n"]}],"source":["def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer_th(texts, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer_th.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    print(f\"ids_to_tokens: {c}\")\n","\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","\n","        else:\n","            try:\n","              label_ids.append(2)\n","            except:\n","                label_ids.append(-100)\n","\n","        previous_word_idx = word_idx\n","\n","    return label_ids\n","\n","\n","def evaluate_one_text(model, sentence):\n","\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer_th(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n","   \n","    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","   \n","    logits = model(input_id, mask, None)\n","    # print(input_id)\n","    # print(mask)\n","    # print(label_ids)\n","    logits_clean = logits[0][label_ids != -100]\n","    # print(logits_clean)\n","    # print(len(logits[0][0]), len(logits_clean))\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    ids_to_labels = {0:'f', 1:'i'}\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    print(prediction_label)\n","\n","    tokenized_inputs = tokenizer_th(sentence, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer_th.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    print(c)\n","    for i, j in enumerate(prediction_label):\n","        if j == 'i':\n","            print(c[i], c[i+1], c[i+2])\n","            \n","evaluate_one_text(model, 'ประเทศเราผลิตและส่งออกยาสูบเยอะสุดในโลกจิงป่าวคับ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-o6XaM5xzLR"},"outputs":[],"source":["FILE = \"tagging.pth\"\n","torch.save(model.bert.state_dict(), FILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhWcAJXUVNU-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"tagging_tpth.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00fd55d320cc43daa84d9128f243e217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f657ca9ea6f40d596e438a8397a6164","IPY_MODEL_37c30ad614fa4d7e92f0f56c8d83e03e","IPY_MODEL_41ba46ad8168442ba5c97804e64c537c"],"layout":"IPY_MODEL_8150574dae9a4e8e9f01c943f81cf48a"}},"37c30ad614fa4d7e92f0f56c8d83e03e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b862d06dab204371b1d19697fee092a9","max":445293041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_755dc07041ef41808382ce856b28c114","value":445293041}},"41ba46ad8168442ba5c97804e64c537c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c54bd59f2cc44d2a2a31690e03fbda4","placeholder":"​","style":"IPY_MODEL_a1ad8789a4324143a7a442c111b18a2a","value":" 425M/425M [06:36&lt;00:00, 697kB/s]"}},"4f657ca9ea6f40d596e438a8397a6164":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91f2805cdea443579516a4fd448bcec5","placeholder":"​","style":"IPY_MODEL_deb791c8e7bc4b49be62c6bf8272cf21","value":"Upload file pytorch_model.bin: 100%"}},"53cfe0ced88745219f05407caceea7db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a525cda209b64daba6d85f4f75fc0e50","placeholder":"​","style":"IPY_MODEL_cd27b78f3b694baeaab64120681bedf3","value":"Upload file training_args.bin: 100%"}},"5c54bd59f2cc44d2a2a31690e03fbda4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c9139ad997e4421bce56c88197e3dc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"755dc07041ef41808382ce856b28c114":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8150574dae9a4e8e9f01c943f81cf48a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8585b55f4bb44dce8cc5fba495d4c48d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89fc3fa575f14c78a6f915cba663e665":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8585b55f4bb44dce8cc5fba495d4c48d","max":2991,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c9139ad997e4421bce56c88197e3dc5","value":2991}},"91f2805cdea443579516a4fd448bcec5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1ad8789a4324143a7a442c111b18a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a525cda209b64daba6d85f4f75fc0e50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7f6d4c051f249748a18b68cad564765":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b862d06dab204371b1d19697fee092a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62c380001fe400bbf780d3a322a08a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcb2a9558f4c457fb0402fec760dd7f3","placeholder":"​","style":"IPY_MODEL_fbe141af7c004fef9d04f410eb6901b7","value":" 2.92k/2.92k [06:35&lt;?, ?B/s]"}},"cd27b78f3b694baeaab64120681bedf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d627bbabb1bb4e10b6cf745d65075366":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53cfe0ced88745219f05407caceea7db","IPY_MODEL_89fc3fa575f14c78a6f915cba663e665","IPY_MODEL_c62c380001fe400bbf780d3a322a08a5"],"layout":"IPY_MODEL_a7f6d4c051f249748a18b68cad564765"}},"deb791c8e7bc4b49be62c6bf8272cf21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbe141af7c004fef9d04f410eb6901b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcb2a9558f4c457fb0402fec760dd7f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac3ed02f64b34b8faba4eba2b7733a7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a73ebf39547441468846fb754d7cbcbb","IPY_MODEL_06c89f016a444e98a588620ad20bdbe2","IPY_MODEL_874fd99c6bc24d8ebfe169932ccb226b"],"layout":"IPY_MODEL_5be9b6d313224089abc3993e45c8c031"}},"a73ebf39547441468846fb754d7cbcbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2859815c2a1242b8849efedb840c11ed","placeholder":"​","style":"IPY_MODEL_f34a3933d2a940a9badacfca81e7d30a","value":"Downloading: 100%"}},"06c89f016a444e98a588620ad20bdbe2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6242447021994c8fa5301c490d1c51bc","max":546,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1609e2c779b04439a4cf23710ac7e4b7","value":546}},"874fd99c6bc24d8ebfe169932ccb226b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72c39c3a0b2947b4ab31b108263169f6","placeholder":"​","style":"IPY_MODEL_72fd7b3aa8f243ecbdb2ac15486b97cb","value":" 546/546 [00:00&lt;00:00, 13.8kB/s]"}},"5be9b6d313224089abc3993e45c8c031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2859815c2a1242b8849efedb840c11ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f34a3933d2a940a9badacfca81e7d30a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6242447021994c8fa5301c490d1c51bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1609e2c779b04439a4cf23710ac7e4b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72c39c3a0b2947b4ab31b108263169f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72fd7b3aa8f243ecbdb2ac15486b97cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"339c029e150249ff868a2d1768dd52bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a112a5335f14d5daf8692e7b36eea3e","IPY_MODEL_b578793d8916482d9ab95e661c3e4888","IPY_MODEL_c3a888010b6b48c480f3e0bfa51819e1"],"layout":"IPY_MODEL_06d1f1031fe04715aed3c61bae7f1414"}},"2a112a5335f14d5daf8692e7b36eea3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4e4095e536640af90fb8786af022b6f","placeholder":"​","style":"IPY_MODEL_f320b56cdb7446fbbb8c0b8573d4dc7b","value":"Downloading: 100%"}},"b578793d8916482d9ab95e661c3e4888":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c15b4d75d542da8affa64f64484b02","max":423498558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd1ecd4e88c645189512cca65dc76bc5","value":423498558}},"c3a888010b6b48c480f3e0bfa51819e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95618dc48baf44d69768ea8ddd57d5f4","placeholder":"​","style":"IPY_MODEL_d72ce03154364c7ca6c4e9fba259c4f2","value":" 404M/404M [00:07&lt;00:00, 61.8MB/s]"}},"06d1f1031fe04715aed3c61bae7f1414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4e4095e536640af90fb8786af022b6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f320b56cdb7446fbbb8c0b8573d4dc7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18c15b4d75d542da8affa64f64484b02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1ecd4e88c645189512cca65dc76bc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95618dc48baf44d69768ea8ddd57d5f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d72ce03154364c7ca6c4e9fba259c4f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}