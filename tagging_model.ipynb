{"cells":[{"cell_type":"code","source":["# BERT\n","!pip install transformers==4.15.0 sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwEI9jZ9yb8G","executionInfo":{"status":"ok","timestamp":1655187283176,"user_tz":-420,"elapsed":9189,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"4ab28067-31ef-4344-b93a-074086c1a1d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 7.8 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (1.21.6)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 80.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (3.7.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0) (2022.5.18.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=45c87eeeffb4840f6ae20e45562b4cbcd5c21cc102574317dcaa591195749765\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbwI_6aWu49u"},"outputs":[],"source":["import pandas as pd\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","import torch \n","import numpy as np\n","from transformers import BertTokenizerFast, BertForTokenClassification, AutoTokenizer\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torch.optim import SGD\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"rcSzaFGhvuna"},"source":["# Read CSV Data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S6FWxqDicRZ","executionInfo":{"status":"ok","timestamp":1655187309199,"user_tz":-420,"elapsed":17070,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"722f97a0-25be-415b-c8d8-3c6be30c9f88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14952,"status":"ok","timestamp":1655187324147,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"},"user_tz":-420},"id":"f8cnvMNLu7CO","outputId":"fc62b3ad-7ea5-44a7-b017-cff3e48030f3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  \\\n","0  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","1  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","2  {'input_ids': [[tensor(5), tensor(984), tensor...   \n","3  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","4  {'input_ids': [[tensor(5), tensor(10), tensor(...   \n","\n","                                              labels  \n","0  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","1  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","2  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","3  [tensor(0), tensor(0), tensor(0), tensor(0), t...  \n","4  [tensor(0), tensor(0), tensor(0), tensor(0), t...  "],"text/html":["\n","  <div id=\"df-82ceec14-80de-459e-8f8d-5ab2a01f51bc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'input_ids': [[tensor(5), tensor(984), tensor...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'input_ids': [[tensor(5), tensor(10), tensor(...</td>\n","      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82ceec14-80de-459e-8f8d-5ab2a01f51bc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82ceec14-80de-459e-8f8d-5ab2a01f51bc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82ceec14-80de-459e-8f8d-5ab2a01f51bc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["# change the input directory to your own preferences\n","df = pickle.load(open('drive/MyDrive/AIBuilders/tagging_ds.pkl', 'rb'))\n","df.head()"]},{"cell_type":"code","source":["df.iloc[0]['labels']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzZEQxj94gwC","executionInfo":{"status":"ok","timestamp":1655187324147,"user_tz":-420,"elapsed":5,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"873978d2-1736-48e1-dd79-0ada80b807fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    1,    1,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","        -100, -100, -100, -100, -100, -100, -100, -100])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"mosLtuxwv2hm"},"source":["# Initialize Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdHlzKiIvyI-"},"outputs":[],"source":["# change the input directory to your own preferences\n","tokenizer_th = pickle.load(open('drive/MyDrive/AIBuilders/tokenizer.pkl', 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"ZwRa6UmDv6g4"},"source":["# Create Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uz8ru0XEv0yd"},"outputs":[],"source":["class DataSequence(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","        self.texts = [df.iloc[i]['text'] for i in range(df.shape[0])]\n","        self.labels = [df.iloc[i]['labels'] for i in range(df.shape[0])]\n","\n","    def __len__(self):\n","\n","        return len(self.labels)\n","\n","    def get_batch_data(self, idx):\n","\n","        return self.texts[idx]\n","\n","    def get_batch_labels(self, idx):\n","\n","        return torch.LongTensor(self.labels[idx])\n","\n","    def __getitem__(self, idx):\n","\n","        batch_data = self.get_batch_data(idx)\n","        batch_labels = self.get_batch_labels(idx)\n","\n","        return batch_data, batch_labels\n"]},{"cell_type":"markdown","metadata":{"id":"BY7BgOzRwBeQ"},"source":["# Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUdcW2Rbv-5d"},"outputs":[],"source":["df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n","                            [int(.8 * len(df)), int(.9 * len(df))])"]},{"cell_type":"code","source":["asdf = DataSequence(df_train)\n","asdf.__getitem__(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDVQGS1YVZtn","executionInfo":{"status":"ok","timestamp":1655091641627,"user_tz":-420,"elapsed":581,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"b1aa735c-051c-4628-8b0a-1adb8cdfc4d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","           1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","           0, 0, 0, 0, 0, 0, 0, 0]]),\n","  'input_ids': tensor([[    5,    10,  9909,    10, 18349,  5016,   253,    15,  1813,    10,\n","            5882,    10,    28,    10,    65, 15011,    10,   227,   253,   353,\n","            3677, 10234,   511,   818,   185,  8472,  6502,    10,    65,   450,\n","              10,   516, 14748,   600,    24,  2155,   436,  6767, 10083,    37,\n","            1640,    10,    65,   450,    10,   754,    86,  1677,  5528,   277,\n","             601,    12,   253,    23,  1141,    83,   814, 25119,   627,   363,\n","            2164,   274,  6097,   101, 16448,    10,    31,   100, 18794,    15,\n","             636,  7994,  2316,   198,  8107,     6,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","               1,     1]])},\n"," tensor([   0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100]))"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"N12N752nwGin"},"source":["# Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDSbpnWtwEmo"},"outputs":[],"source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","        self.bert = BertForTokenClassification.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', num_labels=2)\n","        self.bert.resize_token_embeddings(len(tokenizer_th))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"]},{"cell_type":"code","source":["model = BertModel()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Epie4o66Reup","executionInfo":{"status":"ok","timestamp":1655187734212,"user_tz":-420,"elapsed":9536,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"8fbf2d3b-7562-408d-9f0b-0110c207e2c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertForTokenClassification: ['roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'lm_head.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'classifier.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'classifier.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emyGME48RA4a","executionInfo":{"status":"ok","timestamp":1655187653107,"user_tz":-420,"elapsed":12,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"5e982e36-db32-4ac1-ec3b-945fefddfbec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (bert): BertForTokenClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(33660, 768)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"C6zDk8yQwLqq"},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0jSoWhNwJpN"},"outputs":[],"source":["BATCH_SIZE = 32\n","\n","def train_loop(model, df_train, df_val):\n","\n","    train_dataset = DataSequence(df_train)\n","    val_dataset = DataSequence(df_val)\n","\n","    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n","    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    best_acc = 0\n","    best_loss = 1000\n","    \n","    for epoch_num in range(EPOCHS):\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        model.train()\n","        \n","        for train_data, train_label in tqdm(train_dataloader):\n","            train_label = train_label[0].to(device)\n","            mask = train_data['attention_mask'][0].to(device)\n","            input_id = train_data['input_ids'][0].to(device)\n","            optimizer.zero_grad()\n","            loss, logits = model(input_id, mask, train_label)\n","\n","            logits_clean = logits[0][train_label != -100]\n","            label_clean = train_label[train_label != -100]\n","            predictions = logits_clean.argmax(dim=1)\n","            pred_len = len(predictions)\n","            for i in range(pred_len):\n","                if predictions[i] == 0:\n","                    predictions[i] = -100\n","            \n","            numer = 0\n","            denom = 0\n","            for i in range(pred_len):\n","                if label_clean[i] == 1:\n","                    denom += 1\n","                    if predictions[i] == 1:\n","                        numer += 1\n","                elif label_clean[i] == 0 and predictions[i] == 1:\n","                    denom += 1\n","        \n","            acc = float(numer)/float(denom)\n","            # print(f\"train acc: {acc}\")\n","            total_acc_train += acc * BATCH_SIZE\n","            total_loss_train += loss.item() * BATCH_SIZE\n","\n","            loss.backward()\n","            optimizer.step()\n","        \n","        model.eval()\n","\n","        total_acc_val = 0\n","        total_loss_val = 0\n","\n","        for val_data, val_label in val_dataloader:\n","\n","            val_label = val_label[0].to(device)\n","            mask = val_data['attention_mask'][0].to(device)\n","\n","            input_id = val_data['input_ids'][0].to(device)\n","\n","            loss, logits = model(input_id, mask, val_label)\n","\n","            logits_clean = logits[0][val_label != -100]\n","            label_clean = val_label[val_label != -100]\n","            predictions = logits_clean.argmax(dim=1)   \n","            pred_len = len(predictions)\n","            for i in range(pred_len):\n","                if predictions[i] == 0:\n","                    predictions[i] = -100       \n","\n","            numer = 0\n","            denom = 0\n","            for i in range(pred_len):\n","                if label_clean[i] == 1:\n","                    denom += 1\n","                    if predictions[i] == 1:\n","                        numer += 1\n","                elif label_clean[i] == 0 and predictions[i] == 1:\n","                    denom += 1\n","        \n","            acc = float(numer)/float(denom)\n","            # print(f\"valid acc: {acc}\")\n","            total_acc_val += acc * BATCH_SIZE\n","            total_loss_val += loss.item() * BATCH_SIZE\n","\n","        val_accuracy = total_acc_val / len(df_val)\n","        val_loss = total_loss_val / len(df_val)\n","\n","        print(\n","            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n","\n","LEARNING_RATE = 1e-2\n","EPOCHS = 400\n","\n"]},{"cell_type":"code","source":["train_loop(model, df_train, df_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzqsWQ0xOXU1","executionInfo":{"status":"ok","timestamp":1655093585538,"user_tz":-420,"elapsed":1922732,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"6e04daa6-6a0d-4f87-a3b6-f7ed6ad2c189"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 25/25 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Loss:  0.467 | Accuracy:  0.004 | Val_Loss:  0.859 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Loss:  0.317 | Accuracy:  0.007 | Val_Loss:  0.479 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Loss:  0.261 | Accuracy:  0.000 | Val_Loss:  0.474 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Loss:  0.330 | Accuracy:  0.002 | Val_Loss:  0.464 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Loss:  0.238 | Accuracy:  0.000 | Val_Loss:  0.401 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 6 | Loss:  0.242 | Accuracy:  0.001 | Val_Loss:  0.455 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 7 | Loss:  0.192 | Accuracy:  0.000 | Val_Loss:  0.426 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 8 | Loss:  0.218 | Accuracy:  0.006 | Val_Loss:  0.434 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 9 | Loss:  0.250 | Accuracy:  0.007 | Val_Loss:  0.459 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 10 | Loss:  0.189 | Accuracy:  0.010 | Val_Loss:  0.412 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 11 | Loss:  0.526 | Accuracy:  0.022 | Val_Loss:  0.419 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 12 | Loss:  0.243 | Accuracy:  0.000 | Val_Loss:  0.389 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 13 | Loss:  0.248 | Accuracy:  0.008 | Val_Loss:  0.389 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:03<00:00,  6.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 14 | Loss:  0.268 | Accuracy:  0.000 | Val_Loss:  0.386 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 15 | Loss:  0.292 | Accuracy:  0.002 | Val_Loss:  0.387 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 16 | Loss:  0.219 | Accuracy:  0.000 | Val_Loss:  0.391 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 17 | Loss:  0.304 | Accuracy:  0.006 | Val_Loss:  0.464 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 18 | Loss:  0.516 | Accuracy:  0.035 | Val_Loss:  0.662 | Accuracy:  0.100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 19 | Loss:  0.233 | Accuracy:  0.055 | Val_Loss:  0.433 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 20 | Loss:  0.246 | Accuracy:  0.023 | Val_Loss:  0.382 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 21 | Loss:  0.227 | Accuracy:  0.046 | Val_Loss:  0.411 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 22 | Loss:  0.194 | Accuracy:  0.119 | Val_Loss:  0.451 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 23 | Loss:  0.165 | Accuracy:  0.158 | Val_Loss:  0.462 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 24 | Loss:  0.208 | Accuracy:  0.140 | Val_Loss:  0.438 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 25 | Loss:  0.310 | Accuracy:  0.085 | Val_Loss:  0.383 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 26 | Loss:  0.475 | Accuracy:  0.023 | Val_Loss:  0.519 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 27 | Loss:  0.320 | Accuracy:  0.004 | Val_Loss:  0.406 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 28 | Loss:  0.259 | Accuracy:  0.000 | Val_Loss:  0.397 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 29 | Loss:  0.228 | Accuracy:  0.117 | Val_Loss:  0.526 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 30 | Loss:  0.209 | Accuracy:  0.082 | Val_Loss:  0.387 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 31 | Loss:  0.152 | Accuracy:  0.080 | Val_Loss:  0.436 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 32 | Loss:  0.202 | Accuracy:  0.100 | Val_Loss:  0.418 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 33 | Loss:  0.212 | Accuracy:  0.061 | Val_Loss:  0.386 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 34 | Loss:  0.182 | Accuracy:  0.099 | Val_Loss:  0.420 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 35 | Loss:  0.264 | Accuracy:  0.149 | Val_Loss:  0.395 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 36 | Loss:  0.460 | Accuracy:  0.242 | Val_Loss:  0.471 | Accuracy:  0.000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 37 | Loss:  0.219 | Accuracy:  0.062 | Val_Loss:  0.407 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 38 | Loss:  0.180 | Accuracy:  0.107 | Val_Loss:  0.393 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 39 | Loss:  0.208 | Accuracy:  0.106 | Val_Loss:  0.459 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 40 | Loss:  0.242 | Accuracy:  0.113 | Val_Loss:  0.373 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 41 | Loss:  0.208 | Accuracy:  0.125 | Val_Loss:  0.398 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 42 | Loss:  0.262 | Accuracy:  0.280 | Val_Loss:  0.380 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 43 | Loss:  0.217 | Accuracy:  0.171 | Val_Loss:  0.386 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 44 | Loss:  0.195 | Accuracy:  0.146 | Val_Loss:  0.389 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 45 | Loss:  0.176 | Accuracy:  0.216 | Val_Loss:  0.481 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 46 | Loss:  0.190 | Accuracy:  0.168 | Val_Loss:  0.382 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 47 | Loss:  0.178 | Accuracy:  0.157 | Val_Loss:  0.406 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 48 | Loss:  0.147 | Accuracy:  0.158 | Val_Loss:  0.431 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 49 | Loss:  0.193 | Accuracy:  0.182 | Val_Loss:  0.373 | Accuracy:  0.281\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 50 | Loss:  0.171 | Accuracy:  0.266 | Val_Loss:  0.358 | Accuracy:  0.252\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 51 | Loss:  0.171 | Accuracy:  0.218 | Val_Loss:  0.372 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 52 | Loss:  0.212 | Accuracy:  0.210 | Val_Loss:  0.421 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 53 | Loss:  0.194 | Accuracy:  0.244 | Val_Loss:  0.362 | Accuracy:  0.107\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 54 | Loss:  0.170 | Accuracy:  0.198 | Val_Loss:  0.361 | Accuracy:  0.165\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 55 | Loss:  0.191 | Accuracy:  0.244 | Val_Loss:  0.376 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 56 | Loss:  0.181 | Accuracy:  0.251 | Val_Loss:  0.386 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 57 | Loss:  0.172 | Accuracy:  0.249 | Val_Loss:  0.378 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 58 | Loss:  0.142 | Accuracy:  0.326 | Val_Loss:  0.434 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 59 | Loss:  0.184 | Accuracy:  0.273 | Val_Loss:  0.370 | Accuracy:  0.206\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 60 | Loss:  0.157 | Accuracy:  0.208 | Val_Loss:  0.374 | Accuracy:  0.241\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 61 | Loss:  0.120 | Accuracy:  0.299 | Val_Loss:  0.387 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 62 | Loss:  0.147 | Accuracy:  0.250 | Val_Loss:  0.412 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 63 | Loss:  0.194 | Accuracy:  0.268 | Val_Loss:  0.408 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 64 | Loss:  0.178 | Accuracy:  0.294 | Val_Loss:  0.434 | Accuracy:  0.160\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 65 | Loss:  0.209 | Accuracy:  0.227 | Val_Loss:  0.369 | Accuracy:  0.228\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 66 | Loss:  0.187 | Accuracy:  0.268 | Val_Loss:  0.371 | Accuracy:  0.209\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 67 | Loss:  0.177 | Accuracy:  0.283 | Val_Loss:  0.374 | Accuracy:  0.220\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 68 | Loss:  0.171 | Accuracy:  0.410 | Val_Loss:  0.363 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 69 | Loss:  0.136 | Accuracy:  0.440 | Val_Loss:  0.377 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 70 | Loss:  0.162 | Accuracy:  0.344 | Val_Loss:  0.374 | Accuracy:  0.277\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 71 | Loss:  0.184 | Accuracy:  0.310 | Val_Loss:  0.365 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 72 | Loss:  0.129 | Accuracy:  0.304 | Val_Loss:  0.396 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 73 | Loss:  0.175 | Accuracy:  0.259 | Val_Loss:  0.344 | Accuracy:  0.218\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 74 | Loss:  0.163 | Accuracy:  0.349 | Val_Loss:  0.345 | Accuracy:  0.239\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 75 | Loss:  0.137 | Accuracy:  0.287 | Val_Loss:  0.384 | Accuracy:  0.196\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 76 | Loss:  0.164 | Accuracy:  0.327 | Val_Loss:  0.349 | Accuracy:  0.206\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 77 | Loss:  0.168 | Accuracy:  0.374 | Val_Loss:  0.350 | Accuracy:  0.206\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 78 | Loss:  0.169 | Accuracy:  0.318 | Val_Loss:  0.321 | Accuracy:  0.322\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 79 | Loss:  0.166 | Accuracy:  0.319 | Val_Loss:  0.378 | Accuracy:  0.196\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 80 | Loss:  0.169 | Accuracy:  0.372 | Val_Loss:  0.322 | Accuracy:  0.279\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 81 | Loss:  0.143 | Accuracy:  0.364 | Val_Loss:  0.338 | Accuracy:  0.295\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 82 | Loss:  0.151 | Accuracy:  0.382 | Val_Loss:  0.371 | Accuracy:  0.245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 83 | Loss:  0.190 | Accuracy:  0.298 | Val_Loss:  0.341 | Accuracy:  0.238\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 84 | Loss:  0.136 | Accuracy:  0.273 | Val_Loss:  0.364 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 85 | Loss:  0.148 | Accuracy:  0.321 | Val_Loss:  0.371 | Accuracy:  0.183\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 86 | Loss:  0.249 | Accuracy:  0.278 | Val_Loss:  0.333 | Accuracy:  0.185\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 87 | Loss:  0.158 | Accuracy:  0.407 | Val_Loss:  0.336 | Accuracy:  0.325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 88 | Loss:  0.125 | Accuracy:  0.452 | Val_Loss:  0.351 | Accuracy:  0.299\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 89 | Loss:  0.158 | Accuracy:  0.329 | Val_Loss:  0.344 | Accuracy:  0.254\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 90 | Loss:  0.106 | Accuracy:  0.410 | Val_Loss:  0.338 | Accuracy:  0.277\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 91 | Loss:  0.156 | Accuracy:  0.356 | Val_Loss:  0.351 | Accuracy:  0.308\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 92 | Loss:  0.118 | Accuracy:  0.470 | Val_Loss:  0.382 | Accuracy:  0.241\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 93 | Loss:  0.095 | Accuracy:  0.356 | Val_Loss:  0.365 | Accuracy:  0.267\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 94 | Loss:  0.178 | Accuracy:  0.440 | Val_Loss:  0.327 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 95 | Loss:  0.149 | Accuracy:  0.422 | Val_Loss:  0.332 | Accuracy:  0.308\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 96 | Loss:  0.142 | Accuracy:  0.400 | Val_Loss:  0.330 | Accuracy:  0.294\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 97 | Loss:  0.139 | Accuracy:  0.333 | Val_Loss:  0.307 | Accuracy:  0.277\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 98 | Loss:  0.123 | Accuracy:  0.399 | Val_Loss:  0.308 | Accuracy:  0.325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 99 | Loss:  0.137 | Accuracy:  0.376 | Val_Loss:  0.342 | Accuracy:  0.272\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 100 | Loss:  0.159 | Accuracy:  0.282 | Val_Loss:  0.342 | Accuracy:  0.378\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 101 | Loss:  0.139 | Accuracy:  0.331 | Val_Loss:  0.341 | Accuracy:  0.267\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 102 | Loss:  0.126 | Accuracy:  0.432 | Val_Loss:  0.337 | Accuracy:  0.327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 103 | Loss:  0.155 | Accuracy:  0.409 | Val_Loss:  0.317 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 104 | Loss:  0.128 | Accuracy:  0.406 | Val_Loss:  0.336 | Accuracy:  0.291\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 105 | Loss:  0.144 | Accuracy:  0.451 | Val_Loss:  0.323 | Accuracy:  0.274\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 106 | Loss:  0.183 | Accuracy:  0.401 | Val_Loss:  0.371 | Accuracy:  0.302\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 107 | Loss:  0.142 | Accuracy:  0.281 | Val_Loss:  0.338 | Accuracy:  0.231\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 108 | Loss:  0.115 | Accuracy:  0.376 | Val_Loss:  0.337 | Accuracy:  0.213\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 109 | Loss:  0.118 | Accuracy:  0.342 | Val_Loss:  0.336 | Accuracy:  0.178\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 110 | Loss:  0.163 | Accuracy:  0.459 | Val_Loss:  0.300 | Accuracy:  0.421\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 111 | Loss:  0.149 | Accuracy:  0.420 | Val_Loss:  0.353 | Accuracy:  0.178\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 112 | Loss:  0.095 | Accuracy:  0.437 | Val_Loss:  0.332 | Accuracy:  0.283\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 113 | Loss:  0.126 | Accuracy:  0.436 | Val_Loss:  0.359 | Accuracy:  0.235\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 114 | Loss:  0.149 | Accuracy:  0.338 | Val_Loss:  0.334 | Accuracy:  0.243\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 115 | Loss:  0.158 | Accuracy:  0.381 | Val_Loss:  0.318 | Accuracy:  0.251\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 116 | Loss:  0.170 | Accuracy:  0.361 | Val_Loss:  0.331 | Accuracy:  0.265\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 117 | Loss:  0.156 | Accuracy:  0.481 | Val_Loss:  0.315 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 118 | Loss:  0.139 | Accuracy:  0.477 | Val_Loss:  0.334 | Accuracy:  0.337\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 119 | Loss:  0.104 | Accuracy:  0.508 | Val_Loss:  0.375 | Accuracy:  0.274\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 120 | Loss:  0.139 | Accuracy:  0.460 | Val_Loss:  0.330 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 121 | Loss:  0.138 | Accuracy:  0.485 | Val_Loss:  0.317 | Accuracy:  0.344\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 122 | Loss:  0.171 | Accuracy:  0.489 | Val_Loss:  0.343 | Accuracy:  0.267\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 123 | Loss:  0.160 | Accuracy:  0.462 | Val_Loss:  0.332 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 124 | Loss:  0.122 | Accuracy:  0.491 | Val_Loss:  0.340 | Accuracy:  0.245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 125 | Loss:  0.138 | Accuracy:  0.385 | Val_Loss:  0.322 | Accuracy:  0.419\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 126 | Loss:  0.155 | Accuracy:  0.398 | Val_Loss:  0.338 | Accuracy:  0.290\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 127 | Loss:  0.125 | Accuracy:  0.472 | Val_Loss:  0.387 | Accuracy:  0.240\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 128 | Loss:  0.117 | Accuracy:  0.291 | Val_Loss:  0.327 | Accuracy:  0.222\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 129 | Loss:  0.142 | Accuracy:  0.497 | Val_Loss:  0.315 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 130 | Loss:  0.105 | Accuracy:  0.484 | Val_Loss:  0.347 | Accuracy:  0.292\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 131 | Loss:  0.117 | Accuracy:  0.409 | Val_Loss:  0.337 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 132 | Loss:  0.118 | Accuracy:  0.403 | Val_Loss:  0.323 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 133 | Loss:  0.119 | Accuracy:  0.463 | Val_Loss:  0.354 | Accuracy:  0.325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 134 | Loss:  0.143 | Accuracy:  0.413 | Val_Loss:  0.351 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 135 | Loss:  0.114 | Accuracy:  0.472 | Val_Loss:  0.349 | Accuracy:  0.350\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 136 | Loss:  0.125 | Accuracy:  0.459 | Val_Loss:  0.349 | Accuracy:  0.351\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 137 | Loss:  0.153 | Accuracy:  0.452 | Val_Loss:  0.336 | Accuracy:  0.265\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 138 | Loss:  0.115 | Accuracy:  0.493 | Val_Loss:  0.378 | Accuracy:  0.249\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 139 | Loss:  0.116 | Accuracy:  0.453 | Val_Loss:  0.383 | Accuracy:  0.249\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 140 | Loss:  0.143 | Accuracy:  0.423 | Val_Loss:  0.317 | Accuracy:  0.325\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 141 | Loss:  0.090 | Accuracy:  0.431 | Val_Loss:  0.341 | Accuracy:  0.401\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 142 | Loss:  0.158 | Accuracy:  0.429 | Val_Loss:  0.290 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 143 | Loss:  0.104 | Accuracy:  0.501 | Val_Loss:  0.309 | Accuracy:  0.272\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 144 | Loss:  0.105 | Accuracy:  0.490 | Val_Loss:  0.324 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 145 | Loss:  0.104 | Accuracy:  0.522 | Val_Loss:  0.329 | Accuracy:  0.436\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 146 | Loss:  0.163 | Accuracy:  0.460 | Val_Loss:  0.334 | Accuracy:  0.302\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 147 | Loss:  0.096 | Accuracy:  0.430 | Val_Loss:  0.343 | Accuracy:  0.436\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 148 | Loss:  0.122 | Accuracy:  0.356 | Val_Loss:  0.341 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 149 | Loss:  0.136 | Accuracy:  0.479 | Val_Loss:  0.330 | Accuracy:  0.542\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 150 | Loss:  0.152 | Accuracy:  0.385 | Val_Loss:  0.310 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 151 | Loss:  0.130 | Accuracy:  0.465 | Val_Loss:  0.312 | Accuracy:  0.282\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 152 | Loss:  0.129 | Accuracy:  0.507 | Val_Loss:  0.327 | Accuracy:  0.323\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 153 | Loss:  0.143 | Accuracy:  0.351 | Val_Loss:  0.297 | Accuracy:  0.409\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 154 | Loss:  0.118 | Accuracy:  0.421 | Val_Loss:  0.309 | Accuracy:  0.454\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 155 | Loss:  0.100 | Accuracy:  0.489 | Val_Loss:  0.326 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 156 | Loss:  0.138 | Accuracy:  0.324 | Val_Loss:  0.322 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 157 | Loss:  0.109 | Accuracy:  0.479 | Val_Loss:  0.344 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 158 | Loss:  0.105 | Accuracy:  0.461 | Val_Loss:  0.343 | Accuracy:  0.511\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 159 | Loss:  0.119 | Accuracy:  0.562 | Val_Loss:  0.332 | Accuracy:  0.511\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 160 | Loss:  0.085 | Accuracy:  0.569 | Val_Loss:  0.333 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 161 | Loss:  0.087 | Accuracy:  0.544 | Val_Loss:  0.361 | Accuracy:  0.536\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 162 | Loss:  0.100 | Accuracy:  0.456 | Val_Loss:  0.331 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 163 | Loss:  0.104 | Accuracy:  0.523 | Val_Loss:  0.341 | Accuracy:  0.416\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 164 | Loss:  0.134 | Accuracy:  0.541 | Val_Loss:  0.331 | Accuracy:  0.359\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 165 | Loss:  0.115 | Accuracy:  0.548 | Val_Loss:  0.358 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 166 | Loss:  0.107 | Accuracy:  0.544 | Val_Loss:  0.326 | Accuracy:  0.429\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 167 | Loss:  0.105 | Accuracy:  0.498 | Val_Loss:  0.322 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 168 | Loss:  0.128 | Accuracy:  0.527 | Val_Loss:  0.321 | Accuracy:  0.314\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 169 | Loss:  0.131 | Accuracy:  0.586 | Val_Loss:  0.338 | Accuracy:  0.329\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 170 | Loss:  0.100 | Accuracy:  0.545 | Val_Loss:  0.336 | Accuracy:  0.329\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 171 | Loss:  0.152 | Accuracy:  0.413 | Val_Loss:  0.299 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 172 | Loss:  0.121 | Accuracy:  0.496 | Val_Loss:  0.285 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 173 | Loss:  0.104 | Accuracy:  0.538 | Val_Loss:  0.312 | Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 174 | Loss:  0.102 | Accuracy:  0.538 | Val_Loss:  0.311 | Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 175 | Loss:  0.101 | Accuracy:  0.561 | Val_Loss:  0.351 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 176 | Loss:  0.132 | Accuracy:  0.512 | Val_Loss:  0.329 | Accuracy:  0.309\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 177 | Loss:  0.083 | Accuracy:  0.482 | Val_Loss:  0.379 | Accuracy:  0.323\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 178 | Loss:  0.169 | Accuracy:  0.462 | Val_Loss:  0.343 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 179 | Loss:  0.097 | Accuracy:  0.478 | Val_Loss:  0.357 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 180 | Loss:  0.105 | Accuracy:  0.479 | Val_Loss:  0.349 | Accuracy:  0.295\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 181 | Loss:  0.093 | Accuracy:  0.541 | Val_Loss:  0.328 | Accuracy:  0.356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 182 | Loss:  0.105 | Accuracy:  0.445 | Val_Loss:  0.349 | Accuracy:  0.369\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 183 | Loss:  0.128 | Accuracy:  0.447 | Val_Loss:  0.348 | Accuracy:  0.335\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 184 | Loss:  0.145 | Accuracy:  0.463 | Val_Loss:  0.378 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 185 | Loss:  0.120 | Accuracy:  0.503 | Val_Loss:  0.332 | Accuracy:  0.395\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 186 | Loss:  0.130 | Accuracy:  0.512 | Val_Loss:  0.328 | Accuracy:  0.340\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 187 | Loss:  0.122 | Accuracy:  0.553 | Val_Loss:  0.334 | Accuracy:  0.429\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 188 | Loss:  0.166 | Accuracy:  0.366 | Val_Loss:  0.298 | Accuracy:  0.317\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 189 | Loss:  0.146 | Accuracy:  0.543 | Val_Loss:  0.302 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 190 | Loss:  0.164 | Accuracy:  0.492 | Val_Loss:  0.314 | Accuracy:  0.329\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 191 | Loss:  0.114 | Accuracy:  0.572 | Val_Loss:  0.305 | Accuracy:  0.414\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 192 | Loss:  0.084 | Accuracy:  0.575 | Val_Loss:  0.318 | Accuracy:  0.309\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 193 | Loss:  0.128 | Accuracy:  0.439 | Val_Loss:  0.312 | Accuracy:  0.548\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 194 | Loss:  0.090 | Accuracy:  0.602 | Val_Loss:  0.322 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 195 | Loss:  0.121 | Accuracy:  0.550 | Val_Loss:  0.306 | Accuracy:  0.417\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 196 | Loss:  0.119 | Accuracy:  0.564 | Val_Loss:  0.291 | Accuracy:  0.377\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 197 | Loss:  0.094 | Accuracy:  0.495 | Val_Loss:  0.339 | Accuracy:  0.405\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 198 | Loss:  0.102 | Accuracy:  0.547 | Val_Loss:  0.321 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 199 | Loss:  0.101 | Accuracy:  0.603 | Val_Loss:  0.340 | Accuracy:  0.340\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 200 | Loss:  0.085 | Accuracy:  0.586 | Val_Loss:  0.353 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 201 | Loss:  0.113 | Accuracy:  0.498 | Val_Loss:  0.332 | Accuracy:  0.380\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 202 | Loss:  0.123 | Accuracy:  0.491 | Val_Loss:  0.304 | Accuracy:  0.401\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 203 | Loss:  0.099 | Accuracy:  0.554 | Val_Loss:  0.283 | Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 204 | Loss:  0.114 | Accuracy:  0.409 | Val_Loss:  0.317 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 205 | Loss:  0.109 | Accuracy:  0.556 | Val_Loss:  0.310 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 206 | Loss:  0.115 | Accuracy:  0.535 | Val_Loss:  0.322 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 207 | Loss:  0.103 | Accuracy:  0.480 | Val_Loss:  0.339 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 208 | Loss:  0.080 | Accuracy:  0.513 | Val_Loss:  0.329 | Accuracy:  0.356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 209 | Loss:  0.107 | Accuracy:  0.497 | Val_Loss:  0.344 | Accuracy:  0.352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 210 | Loss:  0.077 | Accuracy:  0.534 | Val_Loss:  0.348 | Accuracy:  0.357\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 211 | Loss:  0.112 | Accuracy:  0.538 | Val_Loss:  0.328 | Accuracy:  0.320\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 212 | Loss:  0.114 | Accuracy:  0.538 | Val_Loss:  0.308 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 213 | Loss:  0.109 | Accuracy:  0.581 | Val_Loss:  0.346 | Accuracy:  0.429\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 214 | Loss:  0.107 | Accuracy:  0.455 | Val_Loss:  0.298 | Accuracy:  0.353\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 215 | Loss:  0.117 | Accuracy:  0.531 | Val_Loss:  0.298 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 216 | Loss:  0.102 | Accuracy:  0.536 | Val_Loss:  0.310 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 217 | Loss:  0.120 | Accuracy:  0.544 | Val_Loss:  0.314 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 218 | Loss:  0.133 | Accuracy:  0.422 | Val_Loss:  0.305 | Accuracy:  0.342\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 219 | Loss:  0.121 | Accuracy:  0.552 | Val_Loss:  0.293 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 220 | Loss:  0.080 | Accuracy:  0.558 | Val_Loss:  0.345 | Accuracy:  0.378\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 221 | Loss:  0.089 | Accuracy:  0.503 | Val_Loss:  0.328 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 222 | Loss:  0.131 | Accuracy:  0.561 | Val_Loss:  0.305 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 223 | Loss:  0.122 | Accuracy:  0.476 | Val_Loss:  0.312 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 224 | Loss:  0.103 | Accuracy:  0.491 | Val_Loss:  0.306 | Accuracy:  0.430\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 225 | Loss:  0.094 | Accuracy:  0.504 | Val_Loss:  0.308 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 226 | Loss:  0.103 | Accuracy:  0.637 | Val_Loss:  0.331 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 227 | Loss:  0.104 | Accuracy:  0.504 | Val_Loss:  0.312 | Accuracy:  0.342\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 228 | Loss:  0.126 | Accuracy:  0.542 | Val_Loss:  0.303 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 229 | Loss:  0.100 | Accuracy:  0.474 | Val_Loss:  0.300 | Accuracy:  0.287\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 230 | Loss:  0.108 | Accuracy:  0.536 | Val_Loss:  0.304 | Accuracy:  0.420\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 231 | Loss:  0.095 | Accuracy:  0.599 | Val_Loss:  0.320 | Accuracy:  0.410\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 232 | Loss:  0.106 | Accuracy:  0.598 | Val_Loss:  0.313 | Accuracy:  0.308\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 233 | Loss:  0.110 | Accuracy:  0.605 | Val_Loss:  0.295 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 234 | Loss:  0.100 | Accuracy:  0.495 | Val_Loss:  0.327 | Accuracy:  0.429\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 235 | Loss:  0.095 | Accuracy:  0.519 | Val_Loss:  0.324 | Accuracy:  0.336\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 236 | Loss:  0.083 | Accuracy:  0.572 | Val_Loss:  0.350 | Accuracy:  0.536\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 237 | Loss:  0.103 | Accuracy:  0.498 | Val_Loss:  0.303 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 238 | Loss:  0.098 | Accuracy:  0.508 | Val_Loss:  0.311 | Accuracy:  0.359\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 239 | Loss:  0.103 | Accuracy:  0.421 | Val_Loss:  0.321 | Accuracy:  0.442\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 240 | Loss:  0.103 | Accuracy:  0.510 | Val_Loss:  0.311 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 241 | Loss:  0.098 | Accuracy:  0.571 | Val_Loss:  0.313 | Accuracy:  0.337\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 242 | Loss:  0.113 | Accuracy:  0.495 | Val_Loss:  0.299 | Accuracy:  0.408\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 243 | Loss:  0.068 | Accuracy:  0.587 | Val_Loss:  0.327 | Accuracy:  0.423\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 244 | Loss:  0.097 | Accuracy:  0.621 | Val_Loss:  0.306 | Accuracy:  0.445\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 245 | Loss:  0.085 | Accuracy:  0.576 | Val_Loss:  0.306 | Accuracy:  0.437\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 246 | Loss:  0.070 | Accuracy:  0.634 | Val_Loss:  0.316 | Accuracy:  0.453\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 247 | Loss:  0.088 | Accuracy:  0.549 | Val_Loss:  0.299 | Accuracy:  0.352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 248 | Loss:  0.105 | Accuracy:  0.619 | Val_Loss:  0.282 | Accuracy:  0.405\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 249 | Loss:  0.088 | Accuracy:  0.555 | Val_Loss:  0.355 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 250 | Loss:  0.106 | Accuracy:  0.620 | Val_Loss:  0.301 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 251 | Loss:  0.123 | Accuracy:  0.606 | Val_Loss:  0.393 | Accuracy:  0.363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 252 | Loss:  0.094 | Accuracy:  0.635 | Val_Loss:  0.328 | Accuracy:  0.310\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 253 | Loss:  0.118 | Accuracy:  0.510 | Val_Loss:  0.342 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 254 | Loss:  0.083 | Accuracy:  0.659 | Val_Loss:  0.338 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 255 | Loss:  0.091 | Accuracy:  0.598 | Val_Loss:  0.360 | Accuracy:  0.405\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 256 | Loss:  0.093 | Accuracy:  0.465 | Val_Loss:  0.341 | Accuracy:  0.393\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 257 | Loss:  0.106 | Accuracy:  0.566 | Val_Loss:  0.357 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 258 | Loss:  0.102 | Accuracy:  0.593 | Val_Loss:  0.340 | Accuracy:  0.433\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 259 | Loss:  0.111 | Accuracy:  0.579 | Val_Loss:  0.349 | Accuracy:  0.331\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 260 | Loss:  0.101 | Accuracy:  0.640 | Val_Loss:  0.345 | Accuracy:  0.368\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 261 | Loss:  0.092 | Accuracy:  0.506 | Val_Loss:  0.316 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 262 | Loss:  0.113 | Accuracy:  0.553 | Val_Loss:  0.343 | Accuracy:  0.347\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 263 | Loss:  0.073 | Accuracy:  0.541 | Val_Loss:  0.389 | Accuracy:  0.328\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 264 | Loss:  0.068 | Accuracy:  0.617 | Val_Loss:  0.433 | Accuracy:  0.505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 265 | Loss:  0.083 | Accuracy:  0.486 | Val_Loss:  0.380 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 266 | Loss:  0.077 | Accuracy:  0.629 | Val_Loss:  0.357 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 267 | Loss:  0.120 | Accuracy:  0.584 | Val_Loss:  0.339 | Accuracy:  0.401\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 268 | Loss:  0.090 | Accuracy:  0.569 | Val_Loss:  0.371 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 269 | Loss:  0.091 | Accuracy:  0.549 | Val_Loss:  0.377 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 270 | Loss:  0.097 | Accuracy:  0.493 | Val_Loss:  0.350 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 271 | Loss:  0.085 | Accuracy:  0.643 | Val_Loss:  0.353 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 272 | Loss:  0.086 | Accuracy:  0.493 | Val_Loss:  0.365 | Accuracy:  0.396\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 273 | Loss:  0.093 | Accuracy:  0.573 | Val_Loss:  0.332 | Accuracy:  0.396\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 274 | Loss:  0.084 | Accuracy:  0.629 | Val_Loss:  0.316 | Accuracy:  0.287\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 275 | Loss:  0.081 | Accuracy:  0.658 | Val_Loss:  0.359 | Accuracy:  0.310\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 276 | Loss:  0.081 | Accuracy:  0.552 | Val_Loss:  0.385 | Accuracy:  0.356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 277 | Loss:  0.076 | Accuracy:  0.633 | Val_Loss:  0.357 | Accuracy:  0.324\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 278 | Loss:  0.097 | Accuracy:  0.672 | Val_Loss:  0.333 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 279 | Loss:  0.109 | Accuracy:  0.640 | Val_Loss:  0.346 | Accuracy:  0.333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 280 | Loss:  0.091 | Accuracy:  0.555 | Val_Loss:  0.341 | Accuracy:  0.502\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 281 | Loss:  0.076 | Accuracy:  0.591 | Val_Loss:  0.345 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 282 | Loss:  0.059 | Accuracy:  0.585 | Val_Loss:  0.356 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 283 | Loss:  0.065 | Accuracy:  0.633 | Val_Loss:  0.384 | Accuracy:  0.342\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 284 | Loss:  0.091 | Accuracy:  0.531 | Val_Loss:  0.364 | Accuracy:  0.327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 285 | Loss:  0.061 | Accuracy:  0.677 | Val_Loss:  0.389 | Accuracy:  0.396\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 286 | Loss:  0.065 | Accuracy:  0.694 | Val_Loss:  0.367 | Accuracy:  0.324\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 287 | Loss:  0.106 | Accuracy:  0.655 | Val_Loss:  0.331 | Accuracy:  0.313\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 288 | Loss:  0.124 | Accuracy:  0.588 | Val_Loss:  0.338 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 289 | Loss:  0.115 | Accuracy:  0.488 | Val_Loss:  0.316 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 290 | Loss:  0.093 | Accuracy:  0.543 | Val_Loss:  0.344 | Accuracy:  0.416\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 291 | Loss:  0.077 | Accuracy:  0.607 | Val_Loss:  0.355 | Accuracy:  0.505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 292 | Loss:  0.071 | Accuracy:  0.597 | Val_Loss:  0.350 | Accuracy:  0.522\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 293 | Loss:  0.094 | Accuracy:  0.487 | Val_Loss:  0.350 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 294 | Loss:  0.091 | Accuracy:  0.537 | Val_Loss:  0.334 | Accuracy:  0.416\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 295 | Loss:  0.115 | Accuracy:  0.523 | Val_Loss:  0.344 | Accuracy:  0.327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 296 | Loss:  0.053 | Accuracy:  0.717 | Val_Loss:  0.366 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 297 | Loss:  0.068 | Accuracy:  0.564 | Val_Loss:  0.330 | Accuracy:  0.380\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 298 | Loss:  0.103 | Accuracy:  0.587 | Val_Loss:  0.297 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 299 | Loss:  0.124 | Accuracy:  0.537 | Val_Loss:  0.323 | Accuracy:  0.377\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 300 | Loss:  0.076 | Accuracy:  0.529 | Val_Loss:  0.344 | Accuracy:  0.405\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 301 | Loss:  0.089 | Accuracy:  0.703 | Val_Loss:  0.338 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 302 | Loss:  0.092 | Accuracy:  0.659 | Val_Loss:  0.330 | Accuracy:  0.526\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 303 | Loss:  0.095 | Accuracy:  0.602 | Val_Loss:  0.373 | Accuracy:  0.350\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 304 | Loss:  0.072 | Accuracy:  0.633 | Val_Loss:  0.371 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 305 | Loss:  0.089 | Accuracy:  0.603 | Val_Loss:  0.353 | Accuracy:  0.441\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 306 | Loss:  0.090 | Accuracy:  0.554 | Val_Loss:  0.346 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 307 | Loss:  0.070 | Accuracy:  0.650 | Val_Loss:  0.364 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 308 | Loss:  0.096 | Accuracy:  0.552 | Val_Loss:  0.352 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 309 | Loss:  0.087 | Accuracy:  0.525 | Val_Loss:  0.306 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 310 | Loss:  0.086 | Accuracy:  0.643 | Val_Loss:  0.345 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 311 | Loss:  0.081 | Accuracy:  0.616 | Val_Loss:  0.374 | Accuracy:  0.348\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 312 | Loss:  0.083 | Accuracy:  0.618 | Val_Loss:  0.354 | Accuracy:  0.320\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 313 | Loss:  0.076 | Accuracy:  0.682 | Val_Loss:  0.367 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 314 | Loss:  0.093 | Accuracy:  0.562 | Val_Loss:  0.377 | Accuracy:  0.378\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 315 | Loss:  0.065 | Accuracy:  0.672 | Val_Loss:  0.346 | Accuracy:  0.377\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 316 | Loss:  0.118 | Accuracy:  0.571 | Val_Loss:  0.306 | Accuracy:  0.339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 317 | Loss:  0.080 | Accuracy:  0.636 | Val_Loss:  0.336 | Accuracy:  0.391\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 318 | Loss:  0.095 | Accuracy:  0.570 | Val_Loss:  0.350 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 319 | Loss:  0.075 | Accuracy:  0.613 | Val_Loss:  0.346 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 320 | Loss:  0.082 | Accuracy:  0.658 | Val_Loss:  0.342 | Accuracy:  0.339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 321 | Loss:  0.083 | Accuracy:  0.573 | Val_Loss:  0.342 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 322 | Loss:  0.072 | Accuracy:  0.629 | Val_Loss:  0.358 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 323 | Loss:  0.093 | Accuracy:  0.518 | Val_Loss:  0.363 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 324 | Loss:  0.092 | Accuracy:  0.609 | Val_Loss:  0.342 | Accuracy:  0.327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 325 | Loss:  0.102 | Accuracy:  0.517 | Val_Loss:  0.320 | Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 326 | Loss:  0.059 | Accuracy:  0.651 | Val_Loss:  0.359 | Accuracy:  0.359\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 327 | Loss:  0.063 | Accuracy:  0.680 | Val_Loss:  0.347 | Accuracy:  0.350\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 328 | Loss:  0.071 | Accuracy:  0.579 | Val_Loss:  0.328 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 329 | Loss:  0.081 | Accuracy:  0.672 | Val_Loss:  0.335 | Accuracy:  0.385\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 330 | Loss:  0.067 | Accuracy:  0.676 | Val_Loss:  0.376 | Accuracy:  0.352\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 331 | Loss:  0.099 | Accuracy:  0.571 | Val_Loss:  0.337 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 332 | Loss:  0.072 | Accuracy:  0.639 | Val_Loss:  0.384 | Accuracy:  0.344\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 333 | Loss:  0.066 | Accuracy:  0.729 | Val_Loss:  0.431 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 334 | Loss:  0.075 | Accuracy:  0.633 | Val_Loss:  0.388 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 335 | Loss:  0.077 | Accuracy:  0.673 | Val_Loss:  0.363 | Accuracy:  0.368\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 336 | Loss:  0.089 | Accuracy:  0.562 | Val_Loss:  0.328 | Accuracy:  0.309\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 337 | Loss:  0.109 | Accuracy:  0.696 | Val_Loss:  0.355 | Accuracy:  0.295\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 338 | Loss:  0.071 | Accuracy:  0.716 | Val_Loss:  0.369 | Accuracy:  0.405\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 339 | Loss:  0.090 | Accuracy:  0.551 | Val_Loss:  0.364 | Accuracy:  0.319\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 340 | Loss:  0.102 | Accuracy:  0.590 | Val_Loss:  0.352 | Accuracy:  0.345\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 341 | Loss:  0.084 | Accuracy:  0.718 | Val_Loss:  0.355 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 342 | Loss:  0.076 | Accuracy:  0.523 | Val_Loss:  0.315 | Accuracy:  0.461\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 343 | Loss:  0.085 | Accuracy:  0.617 | Val_Loss:  0.345 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 344 | Loss:  0.117 | Accuracy:  0.605 | Val_Loss:  0.310 | Accuracy:  0.369\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 345 | Loss:  0.074 | Accuracy:  0.639 | Val_Loss:  0.306 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 346 | Loss:  0.091 | Accuracy:  0.611 | Val_Loss:  0.320 | Accuracy:  0.413\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 347 | Loss:  0.080 | Accuracy:  0.699 | Val_Loss:  0.330 | Accuracy:  0.334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 348 | Loss:  0.065 | Accuracy:  0.639 | Val_Loss:  0.346 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 349 | Loss:  0.061 | Accuracy:  0.670 | Val_Loss:  0.361 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 350 | Loss:  0.088 | Accuracy:  0.653 | Val_Loss:  0.334 | Accuracy:  0.362\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 351 | Loss:  0.058 | Accuracy:  0.691 | Val_Loss:  0.351 | Accuracy:  0.330\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 352 | Loss:  0.091 | Accuracy:  0.623 | Val_Loss:  0.305 | Accuracy:  0.377\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 353 | Loss:  0.075 | Accuracy:  0.632 | Val_Loss:  0.329 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 354 | Loss:  0.070 | Accuracy:  0.652 | Val_Loss:  0.354 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 355 | Loss:  0.065 | Accuracy:  0.597 | Val_Loss:  0.369 | Accuracy:  0.350\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 356 | Loss:  0.059 | Accuracy:  0.675 | Val_Loss:  0.358 | Accuracy:  0.424\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 357 | Loss:  0.072 | Accuracy:  0.684 | Val_Loss:  0.405 | Accuracy:  0.391\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 358 | Loss:  0.073 | Accuracy:  0.633 | Val_Loss:  0.412 | Accuracy:  0.410\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 359 | Loss:  0.083 | Accuracy:  0.642 | Val_Loss:  0.341 | Accuracy:  0.478\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 360 | Loss:  0.074 | Accuracy:  0.588 | Val_Loss:  0.364 | Accuracy:  0.441\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 361 | Loss:  0.072 | Accuracy:  0.698 | Val_Loss:  0.398 | Accuracy:  0.548\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 362 | Loss:  0.078 | Accuracy:  0.584 | Val_Loss:  0.376 | Accuracy:  0.324\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 363 | Loss:  0.060 | Accuracy:  0.605 | Val_Loss:  0.387 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 364 | Loss:  0.075 | Accuracy:  0.701 | Val_Loss:  0.384 | Accuracy:  0.420\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 365 | Loss:  0.061 | Accuracy:  0.624 | Val_Loss:  0.407 | Accuracy:  0.342\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 366 | Loss:  0.071 | Accuracy:  0.634 | Val_Loss:  0.339 | Accuracy:  0.376\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 367 | Loss:  0.072 | Accuracy:  0.589 | Val_Loss:  0.346 | Accuracy:  0.356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 368 | Loss:  0.092 | Accuracy:  0.623 | Val_Loss:  0.359 | Accuracy:  0.462\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 369 | Loss:  0.050 | Accuracy:  0.695 | Val_Loss:  0.384 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 370 | Loss:  0.093 | Accuracy:  0.595 | Val_Loss:  0.356 | Accuracy:  0.356\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 371 | Loss:  0.082 | Accuracy:  0.658 | Val_Loss:  0.378 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 372 | Loss:  0.078 | Accuracy:  0.625 | Val_Loss:  0.372 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 373 | Loss:  0.077 | Accuracy:  0.647 | Val_Loss:  0.344 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 374 | Loss:  0.083 | Accuracy:  0.632 | Val_Loss:  0.341 | Accuracy:  0.402\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 375 | Loss:  0.055 | Accuracy:  0.747 | Val_Loss:  0.311 | Accuracy:  0.409\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 376 | Loss:  0.065 | Accuracy:  0.654 | Val_Loss:  0.306 | Accuracy:  0.487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 377 | Loss:  0.076 | Accuracy:  0.669 | Val_Loss:  0.332 | Accuracy:  0.447\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 378 | Loss:  0.097 | Accuracy:  0.640 | Val_Loss:  0.295 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 379 | Loss:  0.056 | Accuracy:  0.777 | Val_Loss:  0.347 | Accuracy:  0.364\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 380 | Loss:  0.064 | Accuracy:  0.707 | Val_Loss:  0.340 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 381 | Loss:  0.081 | Accuracy:  0.665 | Val_Loss:  0.336 | Accuracy:  0.394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 382 | Loss:  0.066 | Accuracy:  0.731 | Val_Loss:  0.346 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 383 | Loss:  0.079 | Accuracy:  0.620 | Val_Loss:  0.386 | Accuracy:  0.327\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 384 | Loss:  0.069 | Accuracy:  0.679 | Val_Loss:  0.412 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 385 | Loss:  0.088 | Accuracy:  0.617 | Val_Loss:  0.373 | Accuracy:  0.373\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 386 | Loss:  0.069 | Accuracy:  0.633 | Val_Loss:  0.361 | Accuracy:  0.346\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 387 | Loss:  0.080 | Accuracy:  0.541 | Val_Loss:  0.372 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 388 | Loss:  0.067 | Accuracy:  0.624 | Val_Loss:  0.387 | Accuracy:  0.388\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 389 | Loss:  0.073 | Accuracy:  0.667 | Val_Loss:  0.435 | Accuracy:  0.413\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 390 | Loss:  0.074 | Accuracy:  0.629 | Val_Loss:  0.393 | Accuracy:  0.459\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 391 | Loss:  0.097 | Accuracy:  0.599 | Val_Loss:  0.364 | Accuracy:  0.329\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 392 | Loss:  0.066 | Accuracy:  0.716 | Val_Loss:  0.419 | Accuracy:  0.382\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 393 | Loss:  0.064 | Accuracy:  0.572 | Val_Loss:  0.390 | Accuracy:  0.371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 394 | Loss:  0.096 | Accuracy:  0.622 | Val_Loss:  0.300 | Accuracy:  0.422\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 395 | Loss:  0.064 | Accuracy:  0.670 | Val_Loss:  0.336 | Accuracy:  0.368\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 396 | Loss:  0.060 | Accuracy:  0.660 | Val_Loss:  0.361 | Accuracy:  0.373\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 397 | Loss:  0.059 | Accuracy:  0.689 | Val_Loss:  0.314 | Accuracy:  0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 398 | Loss:  0.071 | Accuracy:  0.683 | Val_Loss:  0.339 | Accuracy:  0.363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 399 | Loss:  0.061 | Accuracy:  0.590 | Val_Loss:  0.373 | Accuracy:  0.366\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 400 | Loss:  0.078 | Accuracy:  0.726 | Val_Loss:  0.356 | Accuracy:  0.382\n"]}]},{"cell_type":"markdown","metadata":{"id":"4wQtjsdlxrQH"},"source":["# Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYGHTi-cwPtA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655188124824,"user_tz":-420,"elapsed":2363,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"af2ed5a2-20be-4d32-b093-ee62b9a1fc39"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["input: <s>▁แต่ก่อนสนใจการเมืองเพราะเพื่อนพ่อเป็นสสเวลาฟัวดิเบตได้ความรู้แนวคิดคําคมแต่หลังจากไม่มีการเลือกตั้งไม่ได้ติดตามห่างหายจนปีนี้มีรู้สึกตื่นเต้นที่จะได้ฟังแง่คิดแต่ละคนมุมมอง#พรรคอนาคตใหม่คนรุ่นใหม่อยากหนีจากวงจรอุบาทของการเมือง▁อยากเห็น▁ประเทศไทยเดินหน้ามีกินมีใช้▁#ไทยรัฐเลือกตั้ง62</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","สส\n","ดิ\n","LABELS\n","สส\n","ฟั\n","ว\n","ดิ\n","เบ\n","ต\n","อุ\n","บาท\n","ACC: 0.25\n","-----------------------------------\n","input: <s>▁#จะรักใครก็รักไป▁เป็นนิยายการเมือง▁ปรัชญา▁ใครชอบนอ.ฟาดๆ▁ก็ควรโดนอยู่▁เก่งและฉลาด▁พอ.เหมือนหมารอเจ้าของแต่หมาดันดุนิดๆ▁ไม่เหมาะกับสายนิยายใสมากมีสาระเยอะ▁มีบางประโยคนํามาใช้ได้ในปัจจุบันด้วย▁ไม่ใช่หนังสือที่วางไม่ลง▁โทนเรื่องอ่านเรื่อยๆ▁ให้▁8/10▁พล็อตไม่มีช่วงพีคสุดเลย▁จบสุขนิยมจ้า</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","นอ\n","เรื่อยๆ\n","พีค\n","จ้า\n","LABELS\n","นอ\n",".\n","ฟาด\n","ๆ\n","พอ\n",".\n","นิดๆ\n","เรื่อยๆ\n","พีค\n","ACC: 0.3\n","-----------------------------------\n","input: <s>▁ขอบคุณทุกแรงสนับสนุนจากบ้านตาหวานทุกคนที่ช่วยผลักดันหวานให้ยืนมาถึงจุดๆ▁นี้▁เรายังรักหวานเสมอและจะคอยมองการเติบโตของหวานต่อไป▁อันดับที่▁11▁อาจไม่ใช่อันดับที่ดีที่สุดแต่ก็ไม่สูญเปล่ากับทุกคะแนนที่ทุ่มไป▁#ดีใจด้วยนะหวาน▁#bnk48▁#tarwaanbnk48▁at▁impact▁muang▁thong▁thani▁(อิมแพ็ค▁เมืองทองธานี)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","แพ็ค\n","LABELS\n","จุด\n","ๆ\n","ACC: 0.0\n","-----------------------------------\n","input: <s>▁#ตุ๊ดเข้าครัว▁วันนี้ขอพามาทานร้านห่านในตํานาน▁ฉั่ว▁คิม▁เฮง▁สาขาเลียบมอเตอร์เวย์▁ห่านพะโล้นุ่มๆ▁กับน้ําพะโล้รสเค็ม▁ต้มมะระตามสูตรของที่ร้าน▁ขมนิด▁หวานหน่อย▁ตับผัดต้นกระเทียม▁ตับนุ่มๆ▁ต้นกระเทียมกรอบๆ▁ข้าวสวยนึ่ง▁แข็งนิดๆเหมาะกับการราดน้ําห่านและทาน▁#ตุ๊ดแนะนํา▁#เจ๊คอนเฟิร์ม▁at▁ฉั่ว▁คิม▁เฮง▁ห่านพะโล้</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","มะ\n","นึ่ง\n","LABELS\n","นุ่ม\n","ๆ\n","นุ่ม\n","ๆ\n","กรอบ\n","ๆ\n","นิดๆ\n","ACC: 0.0\n","-----------------------------------\n","input: <s>▁อะโลฮ่า2!!!▁งานจับมือเดือนเมษาที่ผ่านมาเป็นครั้งแรกที่ได้คุยกับหนู▁เป็น8วิที่ฟินพอแล้วสําหรับพี่▁ขอบคุณที่เข้ามาเป็น1ใน▁bnk48▁นะคะ▁สุดท้ายขอให้หนูได้ทําในสิ่งที่รักต่อไปนานๆนะจ๊ะ▁#ขอบคุณทุกโปรเจ็คท์ที่ทําให้น้องด้วยค่ะ▁#jennisbnk48▁#jennishbd18th▁#เต็นเป็นสาวแล้ว▁at▁iberry▁garden▁(ไอเบอร์รี่▁การ์เด้น)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","โล\n","วิ\n","นานๆ\n","โปร\n","เจ็\n","ค\n","ท์\n","การ์\n","LABELS\n","อะ\n","โล\n","ฮ่า\n","เมษ\n","า\n","วิ\n","นานๆ\n","ACC: 0.25\n","-----------------------------------\n","input: <s>▁ส่วนแฟนเก่าเราไม่ได้เสียใจเลย▁อาจจะเหงาๆ▁แต่เราคบกันแค่▁3▁เดือนไม่ได้ผูกพันกันถึงต้องมานั่งเสียน้ําตา▁เพราะคงแค่ชอบ▁คงไม่ได้รักกันขนาดนั้น▁ทวีตไว้เตือนตัวเอง▁ถ้าวันนึงที่ต้องเจอแบบนี้อีก▁ก็ต้องรู้ทันความรู้สึก▁อย่าโง่▁คิดดีๆ▁#ขอบคุณที่เผื่อใจตัวเองไว้▁และวันนึงเราจะไม่เจอแบบนี้อีก</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ๆ\n","ทวีต\n","นึง\n","ดีๆ\n","นึง\n","LABELS\n","เหงา\n","ๆ\n","นึง\n","ดีๆ\n","นึง\n","ACC: 0.6666666666666666\n","-----------------------------------\n","input: <s>▁ก่อนเข้าบ้านไปห้างอีกรอบไปสํารวจมาทุกประตู▁ทุกจุด▁หนังรอบสุดท้ายจบหมด▁พี่รปภ.ปิดประตูแล้ว▁เคลียร์รถทุกชั้นแล้ว▁ถามมาจนสบายใจกลับบ้านมาอาบน้ํา▁นี่กําลังจะเข้านอนแวะมาเลื่อนทวิตสาดด▁ห้างกุคนจะอุปทานลุกไปต่อคิวกันตอนตี2ตี3มั้ยเนี่ย▁กระแสต่อคิวในทวิตโหดมาก▁รู้สึกไม่ปลอดภัย▁#nestival2018</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ชั้น\n","กุ\n","มั้ย\n","เนี่ย\n","LABELS\n","สาด\n","ด\n","กุ\n","มั้ย\n","ACC: 0.3333333333333333\n","-----------------------------------\n","input: <s>▁แล้วที่บอกว่าพ่อค้าแม่ค้าซื้อเอาไปเก็งก็จริงอยู่▁แต่ลองคิดดีๆ▁เรื่องเลือกตั้งนี่มันไม่ใช่เรื่องที่จะปุ้ปปั้ปทําได้เลย▁ของแบบนี้มันแทบจะเทเงินที่มีมาเปย์เลย▁พวกด้อมใหญ่น่าจะเตรียมนานแล้วๆตอนนี้มันถึงเวลา▁ส่วนใหญ่ที่ได้อาจจะไม่ใช่พ่อค้าแม่ค้าก็ได้▁#bnk48▁#bnk485thsingle▁#bnkfestival</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เก็\n","ดีๆ\n","ปุ\n","้\n","ปั\n","้\n","ๆ\n","LABELS\n","ดีๆ\n","ปุ\n","้\n","ป\n","ปั\n","้\n","ป\n","แล้ว\n","ๆ\n","ACC: 0.6\n","-----------------------------------\n","input: <s>▁กระแสดีขนาดนี้▁ดีงามทุกองค์ประกอบ▁ตั้งแต่นิยาย▁บทละคร▁เครื่องแต่งกาย▁เพลงประกอบ▁โลเกชั่น▁ซีจี▁คือดีงามทุกอย่าง▁อยากให้เรตติ้งพุ่งขึ้นทุกตอน▁ให้สมกับความสนุก▁มันส์หยดทุกep▁แบบลุกไปไหนไม่ได้▁ถึงพระเอกนางเอกจะยังเป็นดาวรุ่ง▁ยังไม่แมสมาก▁แต่ก็อยากเป็นกําลังใจให้ปังๆ▁#เพลิงพรางเทียนep5</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เก\n","ชั่น\n","เรตติ้ง\n","มันส์\n","แมส\n","LABELS\n","โล\n","เก\n","ชั่น\n","เรตติ้ง\n","มันส์\n","ปัง\n","ๆ\n","ACC: 0.5\n","-----------------------------------\n","input: <s>▁ตอนปี1เราก็เข้าพิธีบายศรีสู่ขวัญคณะ▁ตอนนั้นไอ้เราก็ดันปวดท้องน้อยๆก็เลยอาศัยช่วงพราหมณ์สวดดังๆตดออกไปดังปู๊ด!ไอ้สัสพราหมณ์หยุดสวดพอดิบพอดีแล้วคือนั่งวงกลมสามวงกูดันอยู่วงแรกทําไงล่ะทีนี่▁แกล้งหลับแม่งงง▁คนเชี้ยไรหลับแต่ตด▁ไอ้เพื่อนที่อยู่ข้างหลังกลั้นขํากันกิกิ▁#เรื่องมันช่างน่าอาย</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","บาย\n","น้อยๆ\n","ดังๆ\n","ู๊ด\n","สัส\n","ี้ย\n","ไร\n","LABELS\n","1\n","น้อยๆ\n","ดังๆ\n","สัส\n","ที\n","นี่\n","แม่ง\n","งง\n","เช\n","ี้ย\n","ไร\n","ACC: 0.38461538461538464\n","-----------------------------------\n","input: <s>▁เอาจริงๆ▁เห็นข่าว▁แต่งงาน▁lgbt▁ต่างชาติ▁แล้วก็คิดว่าในไทยก็ไม่น่ายากนะ▁แต่พอมาเจอพวกสันดานหมาดูถูก▁ส.ส.▁ของพรรคส้มแล้ว▁จริงๆเนี่ย▁การศึกษาไทยมันเหลื่อมล้ําจริงๆ▁เผลอคนในสภาก็ด้วย▁แค่ไม่แสดงออก▁ไม่ให้รู้หรอก▁เก็บคําพูดนี้ไว้▁ฝืนทําในสิ่งที่ยากจริงๆ▁สวนทางหัวใจ▁รักนะแต่ไม่จําเป็นหรอก..</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","LABELS\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","จริงๆ\n","ACC: 1.0\n","-----------------------------------\n","input: <s>▁รีรันจ้าใกล้ถึงเวลาแล้วเริ่มเบรคสุดท้าย▁staff▁ถือเค้กและเริ่มร้องเพลง▁hbdหลังร้องเพลง▁hbdจบทางด้านหลังจะเริ่มชูไวนิลและสุดท้ายให้ร้องเพลง▁rebornส่งรินะหลังไลฟ์จบตอนตั้งแถวส่งน้อง▁เนื่องจากสตาฟบอกว่า▁เพลงเปิดไมไ่ด้และคนที่ตู้ปลาเสนอมาเพราะร้องกันไม่ได้จริงๆอันนี้ไฟนอลแล้วนะ▁#bnk48</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","จ้า\n","เบรค\n","ไม\n","ด้\n","จริงๆ\n","LABELS\n","จ้า\n","เบรค\n","สตาฟ\n","จริงๆ\n","ACC: 0.5\n","-----------------------------------\n","input: <s>▁แต่อยากรีวิวอันนี้มาก▁สั่งจากร้านเป็ดย่างน้ําผึ้ง▁ชื่อเมนูว่าหมูกรอบผัดกระเทียมแต่ว่านี่เพิ่มเป็ดด้วย▁ปกติจะเห็นร้านใช้คําว่าหมูทอดกระเทียมตอนแรกจินตนาการว่ามันคือหมูกระเทียมแบบร้านทั่วไป▁สรุปคือเป็นผัดใส่พริกขี้หนูอะ▁ผัดแห้งๆเค็มๆเผ็ดๆ▁ใส่กระเทียมเยอะๆ▁อร่อยมาก▁ไม่รู้จะชมยังไงละ▁at▁เป็ดย่างน้ําผึ้ง▁หลัง▁มช.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","เยอะๆ\n","ยังไง\n","ละ\n","ม\n","LABELS\n","อะ\n","แห้ง\n","ๆ\n","เค็ม\n","ๆ\n","เผ็ด\n","ๆ\n","เยอะๆ\n","ACC: 0.09090909090909091\n","-----------------------------------\n","input: <s>▁จริง▁มันไม่ใช่เรื่องเหยียดไม่เหยียดผิวอะ▁มันคือเรื่องภาพลักษณ์ตัวละครที่เราจํามันมาแต่เด็ก▁หนังหรือละครที่สร้างมาจากนิยายยังพยายามอิงรูปลักษณ์ให้ตรงตามที่บรรยายในนิยายเลย▁นี่การ์ตูนที่มีภาพโชว์ให้เห็นชัดขนาดนี้มันก็ไม่ได้ปะ▁จะมาว่าคนอื่นเหยียดผิวอะไร▁ตลก▁แอเรียลนังผิวสีเมื่อไหร่อะ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ปะ\n","นัง\n","LABELS\n","ปะ\n","นัง\n","ACC: 1.0\n","-----------------------------------\n","input: <s>▁รีวิว▁#appwar▁by▁ข้ส▁เนื้อหาหนังแปลกดีนะ▁มันเหมาะกับทุกคนเลยแหละแต่คิดว่าคนที่สนใจด้านสตาร์ทอัพหรือกําลังทําอยู่น่าจะได้เข้าไปดู▁ตัวเอกแสดงลื่นดีนะ▁แต่เนื้อเรื่องท้ายๆมันยืดไปหน่อย▁ส่วน▁#ornbnk48▁ของน้อง▁หนังเรื่องแรกยังแอบฝืนไปนิดในฉากพีค▁แต่ตอนอื่นน่ารักจนยิ้มไม่หุบ▁ให้7/10อ่ะจ้า</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ข้\n","ส\n","สตาร์ท\n","อัพ\n","อ่ะ\n","จ้า\n","LABELS\n","ข้\n","ส\n","สตาร์ท\n","อัพ\n","ท้าย\n","ๆ\n","อ่ะ\n","ACC: 0.625\n","-----------------------------------\n","input: <s>▁รีวิว▁#thequake▁วินาศภัยแห่งแผ่นดินไหวในนอร์เวย์▁หนังสําหรับคนชอบสายภัยพิบัติ▁ให้▁6/10▁ที่มาของพล็อตเรื่องเยี่ยม▁ต้นเรื่องแอบเบื่อนิด▁กลางๆตื่นเต้น▁ท้ายๆหายนะ▁ภาพสวยcgระทึก▁ใจตัองแข็งนิดนึงก่อนมาดู▁ไม่ตายแต่ระหว่างทางมีจุดที่เจ็บปวดกับความเสียหายและสิ่งที่เกิดขึ้นโหดไป▁#movietwit▁at▁esplanade▁cineplex▁ratchadapisek▁(เอสพลานาด▁ซีนีเพล็กซ์▁รัชดาภิเษก)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ตั\n","นิดนึง\n","LABELS\n","กลางๆ\n","ท้าย\n","ๆ\n","ตั\n","อง\n","ACC: 0.16666666666666666\n","-----------------------------------\n","input: <s>▁เคยเดิน▁อยู่เจเจกรีน▁มีผญ.ข้างหน้ายื่นมือมาจับเฉย▁นี่ก็งง▁หันมองข้างหลังต่อเลย▁ใช่แน่ๆ▁ผัวนาง▁นี่ก็ยิ้มให้ผัวนาง▁อะแล้วยังไง▁เดินไปงี้ก็ไม่น่าใช่▁นี่ก็เลยตัดสินใจ▁สะบัดออก▁พอนางหันมาเจอเราก็ตกใจ▁แล้วแฟนนางก็คว้าตัวเดินไปต่ออย่างเร็ว▁#เรื่องมันช่างน่าอาย▁#จริงๆคนอายไม่น่าใช่กูด้วย</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ผญ\n","แน่ๆ\n","ยังไง\n","งี้\n","จริงๆ\n","LABELS\n","ผญ\n",".\n","แน่ๆ\n","ACC: 0.3333333333333333\n","-----------------------------------\n","input: <s>▁เราก็ยิ้มรับนะเราคิดว่ายังไงก็คือบ้าน▁ภาษาแรกที่เกิดมาก็ภาษานี้▁ที่แรกที่เกิดก็ที่นี่▁ไม่ว่าจะมีคนกี่คนที่นิสัยยังไง▁โกงเลวยังไง▁เราคิดว่าเรายังมีทัศนคติที่ดีต่อประเทศอ่ะ▁เวลาเราออกความคิดเห็นในด้านการเมืองเราไม่อยากพูดว่าประเทศไทยแม่งล้าหลังไม่มีวันพัฒนาหรอก▁แต่จะพูดถึงคนๆไปต่อ-</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ยังไง\n","ยังไง\n","อ่ะ\n","LABELS\n","อ่ะ\n","คน\n","ๆ\n","ACC: 0.2\n","-----------------------------------\n","input: <s>▁คือผู้บริโภคสมัยนี้ถูกชักจูงกันง่ายเพราะกูรูต่างๆจริงเหรอคะ▁อ่ะยอมรับส่วนนึงก็ได้▁เพราะมาจากรีวิว▁รีวิวเสร็จ▁คนมีความต้องการอยากใช้ตาม▁ไปซื้อมาใช้...สรุปสภาพผิวคนเราไม่เหมือนกัน▁บางคนใช้ดีไม่ดี▁ใช้ครั้งแรกก็รู้แล้วค่ะ▁คนใช่ดีเขาก็อาจกลับไปซื้อซ้ํา▁แต่คนใช้ไม่ถูก..ก็ครั้งเดียวจบป่ะ</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","ต่างๆ\n","อ่ะ\n","ป่ะ\n","LABELS\n","ต่างๆ\n","อ่ะ\n","ส่วนนึง\n","ใช่\n","ป่ะ\n","ACC: 0.6\n","-----------------------------------\n","input: <s>▁don▁don▁donki▁จากญี่ปุ่น▁เปิดแล้วที่ทองหล่อ▁ซ.10▁-22กุมภาที่ผ่านมา▁น้องไปมาวันนี้▁คนเยอะมากๆ▁ไฮไลท์ที่นี่คือเนื้อ▁เนื้อ▁เนื้อ!▁มีทั้งถูกและแพง▁แพงสุดกิโลละ▁5,990.-▁มีเนื้อ▁kobe▁และ▁saga▁คนรักเนื้อไม่ควรพลาด!!▁#bonappetitbkk▁#อร่อยไปแดก▁#อร่อยนะรู้ยัง▁#อร่อยบอกต่อ▁#รีวิว▁aroii▁at▁don▁don▁donki▁(ดอง▁ดอง▁ดองกิ)</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","PREDICTIONS\n","มากๆ\n","ไฮไลท์\n","กิโล\n","LABELS\n","กุมภ\n","า\n","มากๆ\n","ACC: 0.2\n","-----------------------------------\n","Test Accuracy:  0.400\n"]}],"source":["def evaluate(model, df_test):\n","\n","    test_dataset = DataSequence(df_test)\n","\n","    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    total_acc_test = 0.0\n","\n","    cou = 0\n","    for test_data, test_label in test_dataloader:\n","        if cou == 20:\n","            break\n","        cou+=1\n","\n","        test_label = test_label[0].to(device)\n","        mask = test_data['attention_mask'][0].to(device)\n","        input_id = test_data['input_ids'][0].to(device)\n","          \n","        loss, logits = model(input_id, mask, test_label.long())\n","        # print(test_data)\n","        # print(test_label)\n","        # print(loss)\n","        # print(logits)\n","\n","        logits_clean = logits[0][test_label != -100]\n","        label_clean = test_label[test_label != -100]\n","        predictions = logits_clean.argmax(dim=1)\n","        pred_len = len(predictions)\n","        for i in range(pred_len):\n","            if predictions[i] == 0:\n","                predictions[i] = -100\n","        # print(logits_clean)\n","        # print(label_clean)\n","        # print(predictions)\n","\n","  \n","        a = tokenizer_th.convert_ids_to_tokens(input_id.squeeze())\n","        print(f\"input: {''.join(a)}\")\n","        # print(label_clean)\n","        # print(len(input_id[0]), len(label_clean))\n","        # print(\"________________________\")\n","\n","        ids_to_labels = {0:'f', 1:'i', -100:'f'}\n","        prediction_label = [ids_to_labels[i] for i in predictions.tolist()]\n","        print(\"PREDICTIONS\")\n","        for i in range(len(predictions)):\n","          if prediction_label[i] == 'i':\n","            print(a[i])\n","        print(\"LABELS\")\n","        for i in range(len(label_clean)):\n","          if label_clean[i] == 1:\n","            print(a[i])   \n","\n","        # acc = (predictions == label_clean).float().mean()\n","\n","        numer = 0\n","        denom = 0\n","        for i in range(pred_len):\n","            if label_clean[i] == 1:\n","                denom += 1\n","                if predictions[i] == 1:\n","                    numer += 1\n","            elif label_clean[i] == 0 and predictions[i] == 1:\n","                denom += 1\n","        \n","        acc = float(numer)/float(denom)\n","        print(f\"ACC: {acc}\")\n","        print(\"-----------------------------------\")\n","        total_acc_test += acc\n","\n","    val_accuracy = total_acc_test / len(df_test)\n","    # print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n","    print(f'Test Accuracy: {total_acc_test / cou: .3f}')\n","\n","\n","evaluate(model, df_test)"]},{"cell_type":"markdown","metadata":{"id":"EyK8C2_fxvk6"},"source":["# Predict One Sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T99Q2GKQxtzK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655188472122,"user_tz":-420,"elapsed":364,"user":{"displayName":"Idhibhat Pankam","userId":"11974197125920887983"}},"outputId":"7029341a-d823-428f-aff2-b883a207b02f"},"outputs":[{"output_type":"stream","name":"stdout","text":["ids_to_tokens: ['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'i', 'i', 'i']\n","['<s>', '▁', 'ประเทศ', 'เรา', 'ผลิต', 'และ', 'ส่งออก', 'ยา', '▁', 'สูบ', 'เยอะ', 'สุดในโลก', 'จิง', 'ป่าว', 'คับ', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","สุดในโลก จิง ป่าว\n","จิง ป่าว คับ\n","ป่าว คับ </s>\n"]}],"source":["def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer_th(texts, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer_th.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    print(f\"ids_to_tokens: {c}\")\n","\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","\n","        else:\n","            try:\n","              label_ids.append(2)\n","            except:\n","                label_ids.append(-100)\n","\n","        previous_word_idx = word_idx\n","\n","    return label_ids\n","\n","\n","def evaluate_one_text(model, sentence):\n","\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer_th(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n","   \n","    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","   \n","    logits = model(input_id, mask, None)\n","    # print(input_id)\n","    # print(mask)\n","    # print(label_ids)\n","    logits_clean = logits[0][label_ids != -100]\n","    # print(logits_clean)\n","    # print(len(logits[0][0]), len(logits_clean))\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    ids_to_labels = {0:'f', 1:'i'}\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    print(prediction_label)\n","\n","    tokenized_inputs = tokenizer_th(sentence, padding='max_length', max_length=512, truncation=True)\n","    c = tokenizer_th.convert_ids_to_tokens(tokenized_inputs.input_ids)\n","    print(c)\n","    for i, j in enumerate(prediction_label):\n","        if j == 'i':\n","            print(c[i], c[i+1], c[i+2])\n","            \n","evaluate_one_text(model, 'ประเทศเราผลิตและส่งออกยาสูบเยอะสุดในโลกจิงป่าวคับ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-o6XaM5xzLR"},"outputs":[],"source":["FILE = \"tagging.pth\"\n","torch.save(model.state_dict(), FILE)"]},{"cell_type":"code","source":[""],"metadata":{"id":"YhWcAJXUVNU-"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"tagging_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}